# spike_tab.py
import polars as pl
import streamlit as st
import plotly.graph_objects as go
from datetime import datetime
from dateutil.relativedelta import relativedelta
from typing import Optional

from dashboard.utils.analysis import perform_spike_detection, get_spike_time_series
from dashboard.utils.constants import ColumnNames


def show(filters=None, lf: pl.LazyFrame = None):
    """
    Spike Detection íƒ­

    Args:
        filters: SidebarManagerì—ì„œ ìƒì„±ëœ í•„í„° ë”•ì…”ë„ˆë¦¬
            - date_range: (start_date, end_date) íŠœí”Œ
            - as_of_month: ê¸°ì¤€ ì›” (ì˜ˆ: "2025-11")
            - window: ìœˆë„ìš° í¬ê¸° (1 ë˜ëŠ” 3)
            - min_c_recent: ìµœì†Œ ìµœê·¼ ì¼€ì´ìŠ¤ ìˆ˜
            - z_threshold: Z-score ì„ê³„ê°’
            - eps: Epsilon ê°’
            - alpha: ìœ ì˜ìˆ˜ì¤€
            - correction: ë‹¤ì¤‘ê²€ì • ë³´ì • ë°©ë²•
            - min_methods: ì•™ìƒë¸” ìµœì†Œ ë°©ë²• ìˆ˜
        lf: MAUDE ë°ì´í„° LazyFrame
    """
    st.title("ğŸ“ˆ Spike Detection")

    if lf is None:
        st.warning("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # í•„í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    if filters is None:
        filters = {}

    # í•„í„° ê°’ ì¶”ì¶œ
    as_of_month = filters.get('as_of_month', '2025-11')
    window = filters.get('window', 1)
    min_c_recent = filters.get('min_c_recent', 20)
    z_threshold = filters.get('z_threshold', 2.0)
    eps = filters.get('eps', 0.1)
    alpha = filters.get('alpha', 0.05)
    correction = filters.get('correction', 'fdr_bh')
    min_methods = filters.get('min_methods', 2)

    # ìŠ¤íŒŒì´í¬ íƒì§€ ìˆ˜í–‰ (ê¸°ë³¸ê°’ìœ¼ë¡œ ë¯¸ë¦¬ ê³„ì‚°)
    with st.spinner("ìŠ¤íŒŒì´í¬ íƒì§€ ë¶„ì„ ì¤‘..."):
        result_df = outlier_detect_check(
            lf=lf,
            window=window,
            min_c_recent=min_c_recent,
            z_threshold=z_threshold,
            eps=eps,
            alpha=alpha,
            correction=correction,
            min_methods=min_methods,
            month=as_of_month,
        )

    if result_df is None or len(result_df) == 0:
        st.info("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìŠ¤íŒŒì´í¬ í‚¤ì›Œë“œë§Œ í•„í„°ë§ (ì•™ìƒë¸” ê¸°ì¤€)
    spike_df = result_df.filter(pl.col("is_spike_ensemble") == True)

    # ========================================
    # ğŸš¨ SECTION 1: ìŠ¤íŒŒì´í¬ íƒì§€ ìš”ì•½ (Critical ì •ë³´)
    # ========================================
    st.subheader("ğŸš¨ ìŠ¤íŒŒì´í¬ íƒì§€ ìš”ì•½")

    # ì£¼ìš” ë©”íŠ¸ë¦­
    col_main1, col_main2, col_main3 = st.columns([2, 2, 3])

    with col_main1:
        st.metric(
            label="âš ï¸ íƒì§€ëœ ìŠ¤íŒŒì´í¬",
            value=f"{len(spike_df)}ê°œ",
            delta=f"ì „ì²´ {len(result_df)}ê°œ ì¤‘",
            help="ì•™ìƒë¸” ë°©ë²•ìœ¼ë¡œ íƒì§€ëœ ìŠ¤íŒŒì´í¬ í‚¤ì›Œë“œ ìˆ˜"
        )

    with col_main2:
        if len(spike_df) > 0:
            avg_methods = spike_df["n_methods"].mean()
            st.metric(
                label="ğŸ“Š í‰ê·  íƒì§€ ë°©ë²• ìˆ˜",
                value=f"{avg_methods:.1f}ê°œ",
                help="Ratio/Z-score/Poisson ì¤‘ ëª‡ ê°œì˜ ë°©ë²•ì´ ìŠ¤íŒŒì´í¬ë¡œ íŒì •í–ˆëŠ”ì§€"
            )
        else:
            st.metric(label="ğŸ“Š í‰ê·  íƒì§€ ë°©ë²• ìˆ˜", value="N/A")

    with col_main3:
        if len(spike_df) > 0:
            max_ratio_row = spike_df.sort("ratio", descending=True).head(1)
            max_keyword = max_ratio_row["keyword"][0]
            max_ratio = max_ratio_row["ratio"][0]
            st.metric(
                label="ğŸ”¥ ìµœëŒ€ ê¸‰ì¦ í‚¤ì›Œë“œ",
                value=max_keyword,
                delta=f"{max_ratio:.1f}x ì¦ê°€",
                help="ê¸°ì¤€ ê¸°ê°„ ëŒ€ë¹„ ê°€ì¥ ë§ì´ ì¦ê°€í•œ í‚¤ì›Œë“œ"
            )
        else:
            st.metric(label="ğŸ”¥ ìµœëŒ€ ê¸‰ì¦ í‚¤ì›Œë“œ", value="ì—†ìŒ")

    # íŒ¨í„´ë³„ ë¶„í¬
    st.markdown("**íŒ¨í„´ë³„ ë¶„í¬**")
    pattern_counts = result_df.group_by("pattern").agg(pl.len().alias("count")).sort("count", descending=True)

    col1, col2, col3, col4 = st.columns(4)
    pattern_map = {
        "severe": ("ğŸ”´ Severe", col1),
        "alert": ("ğŸŸ  Alert", col2),
        "attention": ("ğŸŸ¡ Attention", col3),
        "general": ("ğŸŸ¢ General", col4)
    }

    for pattern, (label, col) in pattern_map.items():
        count = pattern_counts.filter(pl.col("pattern") == pattern)
        count_val = count["count"][0] if len(count) > 0 else 0
        col.metric(label, count_val)

    st.divider()

    # ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„ (12ê°œì›”)
    end_date = datetime.strptime(as_of_month, "%Y-%m")
    start_date = end_date - relativedelta(months=11)
    start_month = start_date.strftime("%Y-%m")

    # ========================================
    # ğŸ“ˆ SECTION 2: ì‹œê³„ì—´ ì°¨íŠ¸ (ì‹œê°í™”)
    # ========================================
    st.subheader("ğŸ“ˆ í‚¤ì›Œë“œ ë¹„ìœ¨ ì¶”ì´ (Anomaly Detection)")

    # ì „ì²´ í‚¤ì›Œë“œ ëª©ë¡ (ratio ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
    all_keywords = result_df.sort("ratio", descending=True)["keyword"].to_list()
    spike_keywords = spike_df.sort("ratio", descending=True)["keyword"].to_list() if len(spike_df) > 0 else []
    severe_keywords = result_df.filter(pl.col("pattern") == "severe").sort("ratio", descending=True)["keyword"].to_list()
    alert_keywords = result_df.filter(pl.col("pattern") == "alert").sort("ratio", descending=True)["keyword"].to_list()

    # ë¹ ë¥¸ ì„ íƒ ë²„íŠ¼
    st.markdown("**ğŸ”˜ ë¹ ë¥¸ ì„ íƒ**")
    col_btn1, col_btn2, col_btn3, col_btn4, col_btn5 = st.columns(5)

    # ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™” (ì´ˆê¸°ê°’ë§Œ ì„¤ì •, default íŒŒë¼ë¯¸í„° ì‚¬ìš© ì•ˆ í•¨)
    if 'selected_keywords' not in st.session_state:
        st.session_state.selected_keywords = all_keywords[:min(5, len(all_keywords))]

    with col_btn1:
        severe_count = len(severe_keywords)
        if st.button(f"ğŸ”´ Severe ({severe_count})", use_container_width=True, help=f"Severe íŒ¨í„´ í‚¤ì›Œë“œ {severe_count}ê°œ ì¤‘ ìµœëŒ€ 10ê°œ ì„ íƒ"):
            st.session_state.selected_keywords = severe_keywords[:10]
            st.rerun()

    with col_btn2:
        alert_count = len(alert_keywords)
        if st.button(f"ğŸŸ  Alert ({alert_count})", use_container_width=True, help=f"Alert íŒ¨í„´ í‚¤ì›Œë“œ {alert_count}ê°œ ì¤‘ ìµœëŒ€ 10ê°œ ì„ íƒ"):
            st.session_state.selected_keywords = alert_keywords[:10]
            st.rerun()

    with col_btn3:
        spike_count = len(spike_keywords)
        if st.button(f"âš ï¸ ìŠ¤íŒŒì´í¬ ({spike_count})", use_container_width=True, help=f"ìŠ¤íŒŒì´í¬ë¡œ íƒì§€ëœ í‚¤ì›Œë“œ {spike_count}ê°œ ì¤‘ ìµœëŒ€ 10ê°œ ì„ íƒ"):
            st.session_state.selected_keywords = spike_keywords[:10]
            st.rerun()

    with col_btn4:
        if st.button("ğŸ” Top 10", use_container_width=True, help="ë¹„ìœ¨ ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ì„ íƒ"):
            st.session_state.selected_keywords = all_keywords[:10]
            st.rerun()

    with col_btn5:
        if st.button("ğŸ”„ ì´ˆê¸°í™”", use_container_width=True, help="ê¸°ë³¸ê°’(ìƒìœ„ 5ê°œ)ìœ¼ë¡œ ì´ˆê¸°í™”"):
            st.session_state.selected_keywords = all_keywords[:5]
            st.rerun()

    # í‚¤ì›Œë“œ ë©€í‹°ì…€ë ‰íŠ¸ (ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì™€ ì—°ë™, default ì œê±°í•˜ì—¬ ê²½ê³  ë°©ì§€)
    selected_keywords = st.multiselect(
        "ğŸ” í‘œì‹œí•  í‚¤ì›Œë“œ ì„ íƒ",
        options=all_keywords,
        key="selected_keywords",
        help="ì°¨íŠ¸ì— í‘œì‹œí•  í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )

    # ì„ íƒëœ í‚¤ì›Œë“œë¡œ ì‹œê³„ì—´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    if len(selected_keywords) > 0:
        ts_df_filtered = get_spike_time_series(
            _lf=lf,
            keywords=selected_keywords,
            start_month=start_month,
            end_month=as_of_month,
            window=window
        )

        if len(ts_df_filtered) > 0:
            fig = create_spike_chart(ts_df_filtered, z_threshold, as_of_month, window)
            st.plotly_chart(fig, width='stretch')
        else:
            st.info("ì„ íƒí•œ í‚¤ì›Œë“œì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì°¨íŠ¸ë¥¼ í‘œì‹œí•  í‚¤ì›Œë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

    # ========================================
    # ğŸ“‹ SECTION 3: ìƒì„¸ í…Œì´ë¸” (ìƒì„¸ ì •ë³´)
    # ========================================
    st.subheader("ğŸ“‹ ì „ì²´ ë¶„ì„ ê²°ê³¼")

    # í…Œì´ë¸” í•„í„°
    col_pattern, col_spike_only, col_topn = st.columns([3, 1, 1])
    with col_pattern:
        pattern_filter = st.multiselect(
            "ğŸ“Š íŒ¨í„´ í•„í„°",
            options=["severe", "alert", "attention", "general"],
            default=["severe", "alert", "attention"],
            format_func=lambda x: {
                "severe": "ğŸ”´ Severe",
                "alert": "ğŸŸ  Alert",
                "attention": "ğŸŸ¡ Attention",
                "general": "ğŸŸ¢ General"
            }[x],
            key="pattern_filter_table"
        )

    with col_spike_only:
        show_spike_only = st.checkbox(
            "âš ï¸ ìŠ¤íŒŒì´í¬ë§Œ",
            value=False,
            help="ì•™ìƒë¸” ìŠ¤íŒŒì´í¬ë¡œ íŒì •ëœ í‚¤ì›Œë“œë§Œ í‘œì‹œ"
        )

    with col_topn:
        top_n_table = st.number_input(
            "í‘œì‹œ í–‰ ìˆ˜",
            min_value=10,
            max_value=200,
            value=50,
            step=10,
            key="top_n_table"
        )

    # í•„í„°ë§ëœ ê²°ê³¼ í…Œì´ë¸”
    filtered_result = result_df.filter(pl.col("pattern").is_in(pattern_filter))
    if show_spike_only:
        filtered_result = filtered_result.filter(pl.col("is_spike_ensemble") == True)

    display_all_df = prepare_spike_table(filtered_result.head(top_n_table))

    if len(display_all_df) > 0:
        st.dataframe(display_all_df, width='stretch', height=600)
    else:
        st.info("í•„í„° ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ========================================
    # ğŸ“¥ SECTION 4: ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    # ========================================
    st.divider()
    col_download1, col_download2 = st.columns(2)

    with col_download1:
        st.markdown("**ğŸ“¥ ì „ì²´ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ**")
        csv_all = result_df.write_csv()
        st.download_button(
            label="ì „ì²´ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_all,
            file_name=f"spike_detection_all_{as_of_month}_w{window}.csv",
            mime="text/csv"
        )

    with col_download2:
        if len(spike_df) > 0:
            st.markdown("**ğŸ“¥ ìŠ¤íŒŒì´í¬ë§Œ ë‹¤ìš´ë¡œë“œ**")
            csv_spike = spike_df.write_csv()
            st.download_button(
                label="ìŠ¤íŒŒì´í¬ë§Œ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_spike,
                file_name=f"spike_detection_spikes_{as_of_month}_w{window}.csv",
                mime="text/csv"
            )

def outlier_detect_check(
    lf: pl.LazyFrame,
    window: int = 1,
    min_c_recent: int = 20,
    z_threshold: float = 2.0,
    eps: float = 0.1,
    alpha: float = 0.05,
    correction: str = 'fdr_bh',
    min_methods: int = 2,
    month: str = "2025-11",
) -> Optional[pl.DataFrame]:
    """
    ìŠ¤íŒŒì´í¬ íƒì§€ ë¶„ì„ ìˆ˜í–‰

    Args:
        lf: MAUDE ë°ì´í„° LazyFrame
        window: ìœˆë„ìš° í¬ê¸° (1 ë˜ëŠ” 3)
        min_c_recent: ìµœì†Œ ìµœê·¼ ì¼€ì´ìŠ¤ ìˆ˜
        z_threshold: Z-score ì„ê³„ê°’
        eps: Epsilon ê°’ (z_log ê³„ì‚°ìš©)
        alpha: ìœ ì˜ìˆ˜ì¤€ (Poisson ê²€ì •ìš©)
        correction: ë‹¤ì¤‘ê²€ì • ë³´ì • ë°©ë²• ('bonferroni', 'sidak', 'fdr_bh', None)
        min_methods: ì•™ìƒë¸” ìŠ¤íŒŒì´í¬ íŒì • ìµœì†Œ ë°©ë²• ìˆ˜
        month: ê¸°ì¤€ ì›” (ì˜ˆ: "2025-11")

    Returns:
        ìŠ¤íŒŒì´í¬ íƒì§€ ê²°ê³¼ DataFrame
        ì»¬ëŸ¼: keyword, C_recent, C_base, ratio, z_log, score_pois,
              is_spike, is_spike_z, is_spike_p, n_methods, is_spike_ensemble, pattern
    """
    result_df = perform_spike_detection(
        _lf=lf,
        as_of_month=month,
        window=window,
        min_c_recent=min_c_recent,
        z_threshold=z_threshold,
        eps=eps,
        alpha=alpha,
        correction=correction,
        min_methods=min_methods,
    )

    return result_df


def create_spike_chart(
    ts_df: pl.DataFrame,
    z_threshold: float,
    as_of_month: str,
    window: int
) -> go.Figure:
    """
    ìŠ¤íŒŒì´í¬ ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„±

    Args:
        ts_df: ì‹œê³„ì—´ ë°ì´í„° (columns: month, keyword, count, ratio)
        z_threshold: Z-score ì„ê³„ê°’ (í‘œì‹œìš©)
        as_of_month: ê¸°ì¤€ ì›”
        window: ìœˆë„ìš° í¬ê¸°

    Returns:
        Plotly Figure ê°ì²´
    """
    import plotly.express as px
    from src import BaselineAggregator

    fig = go.Figure()

    # í‚¤ì›Œë“œë³„ë¡œ ë¼ì¸ ì¶”ê°€
    keywords = ts_df["keyword"].unique().to_list()

    # ë™ì  ìƒ‰ìƒ ìƒì„± (Plotlyì˜ qualitative ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì‚¬ìš©)
    n_colors = len(keywords)
    if n_colors <= 10:
        colors = px.colors.qualitative.Plotly
    elif n_colors <= 24:
        colors = px.colors.qualitative.Dark24
    else:
        # ë§ì€ í‚¤ì›Œë“œì˜ ê²½ìš° ìƒ‰ìƒ ë°˜ë³µ
        colors = px.colors.qualitative.Dark24 * ((n_colors // 24) + 1)

    for i, keyword in enumerate(keywords):
        keyword_data = ts_df.filter(pl.col("keyword") == keyword).sort("month")

        fig.add_trace(go.Scatter(
            x=keyword_data["month"].to_list(),
            y=keyword_data["ratio"].to_list(),
            mode='lines+markers',
            name=keyword,
            line=dict(color=colors[i], width=2),
            marker=dict(size=6),
            hovertemplate='<b>%{fullData.name}</b><br>' +
                         'Month: %{x}<br>' +
                         'Ratio: %{y:.2f}x<br>' +
                         '<extra></extra>'
        ))

    # yì¶• ë²”ìœ„ ê³„ì‚°
    max_ratio = ts_df["ratio"].max() if len(ts_df) > 0 else z_threshold
    y_max = max(max_ratio, z_threshold) + 0.5

    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title=f"Spike Detection - Keyword Ratio Over Time (Window: {window}M, Threshold: {z_threshold:.1f}Ïƒ)",
        xaxis_title="Month",
        yaxis_title="Ratio (ë°°ìˆ˜) - ê¸°ì¤€ ê¸°ê°„ ëŒ€ë¹„",
        yaxis=dict(range=[0, y_max]),
        hovermode='x unified',
        height=600,
        legend=dict(
            orientation="v",
            yanchor="top",
            y=1,
            xanchor="left",
            x=1.02
        ),
        margin=dict(l=50, r=150, t=80, b=50)
    )

    # z-score ì„ê³„ê°’ í‘œì‹œ
    fig.add_hline(
        y=z_threshold,
        line=dict(color="red", width=2, dash="dash"),
        annotation_text=f"Z-score Threshold ({z_threshold}Ïƒ)",
        annotation_position="right",
        annotation_font=dict(color="red", size=10)
    )

    # ê¸°ì¤€ êµ¬ê°„ê³¼ ë¹„êµ êµ¬ê°„ ì‹œê°ì  í‘œì‹œ
    if len(ts_df) > 0:
        all_months = sorted(ts_df["month"].unique().to_list())

        # BaselineAggregator._calculate_time_windows() ë¡œì§ (src/utils/baseline_aggregator.py ì°¸ì¡°)
        from datetime import datetime
        from dateutil.relativedelta import relativedelta

        as_of_dt = datetime.strptime(as_of_month, "%Y-%m")

        # êµ¬ê°„ ê³„ì‚° (ê³µí†µ ë¡œì§)
        if window == 1:
            # Window=1: recent=[as_of_month], base=[as_of_month - 1ê°œì›”]
            recent_months = [as_of_month]
            baseline_months = [(as_of_dt - relativedelta(months=1)).strftime("%Y-%m")]
        else:  # window == 3
            # Window=3: recent=[M, M-1, M-2], base=[M-1, M-2, M-3]
            recent_months = [(as_of_dt - relativedelta(months=i)).strftime("%Y-%m") for i in range(3)]
            baseline_months = [(as_of_dt - relativedelta(months=i)).strftime("%Y-%m") for i in range(1, 4)]

        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        st.sidebar.markdown("---")
        st.sidebar.markdown(f"**ğŸ” êµ¬ê°„ ë””ë²„ê¹… (Window={window})**")
        st.sidebar.caption(f"ê¸°ì¤€ì›”: {as_of_month}")
        st.sidebar.caption(f"ë¹„êµ êµ¬ê°„: {recent_months}")
        st.sidebar.caption(f"ê¸°ì¤€ êµ¬ê°„: {baseline_months}")
        st.sidebar.caption(f"ì „ì²´ ë°ì´í„° ì›”: {all_months[:3]}...{all_months[-3:]}")

        # ì‹¤ì œ ë°ì´í„°ì— ìˆëŠ” ì›”ë§Œ í•„í„°ë§
        baseline_months_in_data = [m for m in baseline_months if m in all_months]
        comparison_months_in_data = [m for m in recent_months if m in all_months]

        # ê¸°ì¤€ êµ¬ê°„ (íŒŒë€ìƒ‰) - vrect ì‚¬ìš©, ì‹œì‘/ë ì›” ë¬¸ìì—´ë¡œ ì§ì ‘ ì§€ì •
        if baseline_months_in_data:
            baseline_sorted = sorted(baseline_months_in_data)

            # Window=1: ë‹¨ì¼ ì›”ì´ë¯€ë¡œ ì•ë’¤ ì—¬ë°± í•„ìš” (ì´ì „ ì›” ì¤‘ê°„ ~ ë‹¤ìŒ ì›” ì¤‘ê°„)
            # Window=3: ë²”ìœ„ì´ë¯€ë¡œ ì²« ì›” ~ ë§ˆì§€ë§‰ ì›”
            if len(baseline_sorted) == 1:
                # ë‹¨ì¼ ì›”: í•´ë‹¹ ì›”ì˜ ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì•ë’¤ 0.5ì”©
                base_idx = all_months.index(baseline_sorted[0])
                # ì´ì „ ì›”ê³¼ ë‹¤ìŒ ì›” ì°¾ê¸°
                x0_month = all_months[base_idx - 1] if base_idx > 0 else baseline_sorted[0]
                x1_month = all_months[base_idx + 1] if base_idx < len(all_months) - 1 else baseline_sorted[0]
            else:
                # ë‹¤ì¤‘ ì›”: ì²« ì›” ~ ë§ˆì§€ë§‰ ì›”
                x0_month = baseline_sorted[0]
                x1_month = baseline_sorted[-1]

            fig.add_vrect(
                x0=x0_month,
                x1=x1_month,
                fillcolor="lightblue",
                opacity=0.3,
                layer="below",
                line_width=0,
                annotation_text="ê¸°ì¤€" if window == 1 else "ê¸°ì¤€ êµ¬ê°„",
                annotation_position="top left",
                annotation_font=dict(size=10, color="blue")
            )

        # ë¹„êµ êµ¬ê°„ (ì£¼í™©ìƒ‰) - vrect ì‚¬ìš©
        if comparison_months_in_data:
            comparison_sorted = sorted(comparison_months_in_data)

            if len(comparison_sorted) == 1:
                # ë‹¨ì¼ ì›”: í•´ë‹¹ ì›”ì˜ ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì•ë’¤ 0.5ì”©
                comp_idx = all_months.index(comparison_sorted[0])
                x0_month = all_months[comp_idx - 1] if comp_idx > 0 else comparison_sorted[0]
                x1_month = all_months[comp_idx + 1] if comp_idx < len(all_months) - 1 else comparison_sorted[0]
            else:
                # ë‹¤ì¤‘ ì›”: ì²« ì›” ~ ë§ˆì§€ë§‰ ì›”
                x0_month = comparison_sorted[0]
                x1_month = comparison_sorted[-1]

            fig.add_vrect(
                x0=x0_month,
                x1=x1_month,
                fillcolor="orange",
                opacity=0.3,
                layer="below",
                line_width=0,
                annotation_text="ë¹„êµ" if window == 1 else "ë¹„êµ êµ¬ê°„",
                annotation_position="top right",
                annotation_font=dict(size=10, color="darkorange")
            )

    return fig


def prepare_spike_table(spike_df: pl.DataFrame) -> pl.DataFrame:
    """
    ìŠ¤íŒŒì´í¬ í…Œì´ë¸” í‘œì‹œìš© ë°ì´í„° ì¤€ë¹„ (ì¤‘ìš” ì»¬ëŸ¼ ìš°ì„  ë°°ì¹˜)

    Args:
        spike_df: ìŠ¤íŒŒì´í¬ íƒì§€ ê²°ê³¼ DataFrame

    Returns:
        í‘œì‹œìš© DataFrame
    """
    # íŒ¨í„´ì— ì´ëª¨ì§€ ì¶”ê°€
    pattern_emoji = (
        pl.when(pl.col("pattern") == "severe").then(pl.lit("ğŸ”´ Severe"))
        .when(pl.col("pattern") == "alert").then(pl.lit("ğŸŸ  Alert"))
        .when(pl.col("pattern") == "attention").then(pl.lit("ğŸŸ¡ Attention"))
        .otherwise(pl.lit("ğŸŸ¢ General"))
    )

    # ì¦ê° ê³„ì‚°
    increase = pl.col("C_recent") - pl.col("C_base")

    # ì»¬ëŸ¼ ìˆœì„œ: ì¤‘ìš”í•œ ì •ë³´ ìš°ì„  (í‚¤ì›Œë“œ â†’ íŒ¨í„´ â†’ ë¹„ìœ¨ â†’ ì¦ê° â†’ ë°©ë²• ìˆ˜ â†’ ìƒì„¸)
    display_df = spike_df.select([
        pl.col("keyword").alias("í‚¤ì›Œë“œ"),
        pattern_emoji.alias("íŒ¨í„´"),
        pl.col("ratio").round(2).alias("ë¹„ìœ¨ (ë°°ìˆ˜)"),
        pl.col("C_recent").alias("ìµœê·¼ ë³´ê³ ìˆ˜"),
        increase.alias("ì¦ê°"),
        pl.col("C_base").alias("ê¸°ì¤€ ë³´ê³ ìˆ˜"),
        pl.col("n_methods").alias("íƒì§€ë°©ë²•ìˆ˜"),
        pl.col("is_spike").alias("âœ“Ratio"),
        pl.col("is_spike_z").alias("âœ“Z-score"),
        pl.col("is_spike_p").alias("âœ“Poisson"),
    ])

    return display_df