import re
import sys
import psutil
from typing import List, Dict, Tuple, Union
import polars as pl
import plotly.graph_objects as go
from IPython.display import display
from tqdm import tqdm

from code.utils import is_running_in_notebook

if not is_running_in_notebook():
    display = print

def get_pattern_cols(
    lf: pl.LazyFrame,
    pattern: List[str],
) -> List[str]:
    """ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ì— ë§¤ì¹­ë˜ëŠ” ì»¬ëŸ¼ëª… ì¶”ì¶œ
    
    Args:
        lf (pl.LazyFrame): ëŒ€ìƒ LazyFrame
        pattern (List[str]): ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        List[str]: íŒ¨í„´ì— ë§¤ì¹­ë˜ëŠ” ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
    
    Examples:
        >>> get_pattern_cols(lf, [r'^device_\d+', r'.*_date$'])
        ['device_0_name', 'device_1_name', 'report_date', 'event_date']
    """
    # ëª¨ë“  ì»¬ëŸ¼ëª… ê°€ì ¸ì˜¤ê¸°
    cols = lf.collect_schema().names()
    
    # íŒ¨í„´ ë¬¸ìì—´ì„ ì •ê·œí‘œí˜„ì‹ ê°ì²´ë¡œ ì»´íŒŒì¼
    regexes = [re.compile(p) for p in pattern]
    
    # ê° ì»¬ëŸ¼ëª…ì´ íŒ¨í„´ ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ë©´ í¬í•¨
    return [c for c in cols if any(r.search(c) for r in regexes)]


def get_use_cols(
    lf: pl.LazyFrame,
    patterns: Dict[str, List[str]],
    base_cols: List[str],
) -> Tuple[List[str], List[str], List[str], List[str]]:
    """ê¸°ë³¸ ì»¬ëŸ¼ê³¼ íŒ¨í„´ë³„ ì»¬ëŸ¼ì„ í•©ì³ ë¶„ì„ìš© ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    
    Args:
        lf (pl.LazyFrame): ëŒ€ìƒ LazyFrame
        patterns (Dict[str, List[str]]): ì¹´í…Œê³ ë¦¬ë³„ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬
            ì˜ˆ: {'device': [r'^device_'], 'patient': [r'^patient_']}
        base_cols (List[str]): ê¸°ë³¸ì ìœ¼ë¡œ í¬í•¨í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        Tuple[List[str], Dict[str, List[str]]]: 
            - ì „ì²´ ë¶„ì„ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°, ì—­ìˆœ ì •ë ¬)
            - ì¹´í…Œê³ ë¦¬ë³„ ì»¬ëŸ¼ ë”•ì…”ë„ˆë¦¬
    
    Examples:
        >>> patterns = {'device': [r'^device_'], 'event': [r'event_']}
        >>> base_cols = ['report_id', 'date_received']
        >>> all_cols, pattern_cols = get_use_cols(lf, patterns, base_cols)
    """
    # ê¸°ë³¸ ì»¬ëŸ¼ìœ¼ë¡œ ì‹œì‘
    analysis_cols = base_cols
    
    # íŒ¨í„´ë³„ë¡œ ì»¬ëŸ¼ ì¶”ì¶œ ë° ì €ì¥
    pattern_cols = {}
    for k, pattern in patterns.items():
        pattern_cols[k] = get_pattern_cols(lf, pattern)
        analysis_cols += pattern_cols[k]
    
    # ì¤‘ë³µ ì œê±° í›„ ì—­ìˆœ ì •ë ¬
    analysis_cols = sorted(list(set(analysis_cols)), reverse=True)
    
    # ìš”ì•½ ì •ë³´ ì¶œë ¥
    print(f"ì´ ì»¬ëŸ¼: {len(analysis_cols)}ê°œ")
    for k, pattern in pattern_cols.items():
        print(f"{k} ì»¬ëŸ¼: {len(pattern)}ê°œ")
    
    return analysis_cols, pattern_cols


def draw_donut_chart(count_df: pl.DataFrame, col: str, top_n: int = 5) -> None:
    """ë°ì´í„°í”„ë ˆì„ì„ ê¸°ë°˜ìœ¼ë¡œ ë„ë„› ì°¨íŠ¸ ìƒì„±
    
    ìƒìœ„ Nê°œ í•­ëª©ì„ í‘œì‹œí•˜ê³  ë‚˜ë¨¸ì§€ëŠ” 'Minor Group'ìœ¼ë¡œ ë¬¶ì–´ì„œ í‘œì‹œ
    
    Args:
        count_df (pl.DataFrame): 'count'ì™€ 'percentage' ì»¬ëŸ¼ì„ í¬í•¨í•œ DataFrame
        col (str): ë ˆì´ë¸”ë¡œ ì‚¬ìš©í•  ì»¬ëŸ¼ëª…
        top_n (int, optional): ê°œë³„ í‘œì‹œí•  ìƒìœ„ í•­ëª© ê°œìˆ˜. Defaults to 5.
    
    Returns:
        None: Plotly ì°¨íŠ¸ë¥¼ í™”ë©´ì— í‘œì‹œ
    
    Examples:
        >>> count_df = pl.DataFrame({
        ...     'category': ['A', 'B', 'C', 'D', 'E', 'F'],
        ...     'count': [100, 80, 60, 40, 20, 10]
        ... })
        >>> draw_donut_chart(count_df, 'category', top_n=3)
    """
    # top_nì´ ì§€ì •ë˜ê³  ë°ì´í„°ê°€ ê·¸ë³´ë‹¤ ë§ìœ¼ë©´ ì²˜ë¦¬
    if top_n and len(count_df) > top_n:
        # ìƒìœ„ Nê°œ ì¶”ì¶œ
        top = count_df.head(top_n)
        
        # ë‚˜ë¨¸ì§€ í•©ê³„ ê³„ì‚°
        rest_sum = count_df[top_n:].select(pl.col('count').sum()).item()
        
        if rest_sum > 0:
            # ë‚˜ë¨¸ì§€ ë¹„ìœ¨ ê³„ì‚°
            rest_percentage = round(rest_sum / count_df.select(pl.col('count').sum()).item() * 100, 2)
            
            # 'Minor Group' í–‰ ìƒì„±
            other_row = pl.DataFrame({
                col: ['Minor Group'],
                'count': [rest_sum],
                'percentage': [rest_percentage]
            }).with_columns(
                pl.col('count').cast(count_df['count'].dtype)  # íƒ€ì… ë§ì¶”ê¸°
            )
            
            # ìƒìœ„ Nê°œì™€ Minor Group í•©ì¹˜ê¸°
            count_df = pl.concat([top, other_row])
        else:
            count_df = top
    
    # Plotly ë„ë„› ì°¨íŠ¸ ìƒì„±
    fig = go.Figure(data=[go.Pie(
        labels=count_df[col],
        values=count_df['count'],
        hole=.4,  # ê°€ìš´ë° êµ¬ë© í¬ê¸° (ë„ë„› ëª¨ì–‘)
        hoverinfo="label+percent",  # í˜¸ë²„ ì‹œ í‘œì‹œ ì •ë³´
        textinfo='label+percent',  # ì°¨íŠ¸ì— í‘œì‹œí•  ì •ë³´
        textposition='outside'  # í…ìŠ¤íŠ¸ ìœ„ì¹˜
    )])
    
    # ì»¬ëŸ¼ëª…ì„ ì œëª©ìœ¼ë¡œ ë³€í™˜ (ì¤‘ê°„ì— ì¤„ë°”ê¿ˆ ì¶”ê°€)
    title = col.title().split('_')
    text = ' '.join(title[:len(title)//2]) + '<br>' + ' '.join(title[len(title)//2:])
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title_text=f"{col.title()} Distribution",
        annotations=[dict(
            text=text,  # ë„ë„› ì¤‘ì•™ì— í‘œì‹œí•  í…ìŠ¤íŠ¸
            x=0.5, 
            y=0.5,
            font_size=20, 
            showarrow=False
        )]
    )
    
    fig.show()
    

def eda_proportion(lf: pl.LazyFrame, col: str, n_rows: int = 100, top_n: int = 5) -> None:
    """íŠ¹ì • ì»¬ëŸ¼ì˜ ê°’ ë¶„í¬ë¥¼ í…Œì´ë¸”ê³¼ ë„ë„› ì°¨íŠ¸ë¡œ ì‹œê°í™”
    
    ê°’ì˜ ë¹ˆë„ì™€ ë¹„ìœ¨ì„ ê³„ì‚°í•˜ì—¬ í…Œì´ë¸”ë¡œ í‘œì‹œí•˜ê³ , ë„ë„› ì°¨íŠ¸ë¡œ ì‹œê°í™”
    
    Args:
        lf (pl.LazyFrame): ë¶„ì„í•  LazyFrame
        col (str): ë¶„ì„í•  ì»¬ëŸ¼ëª…
        n_rows (int, optional): í…Œì´ë¸”ì— í‘œì‹œí•  ìµœëŒ€ í–‰ ìˆ˜. Defaults to 100.
        top_n (int, optional): ì°¨íŠ¸ì— ê°œë³„ í‘œì‹œí•  ìƒìœ„ í•­ëª© ê°œìˆ˜. Defaults to 5.
    
    Returns:
        None: í…Œì´ë¸”ê³¼ ì°¨íŠ¸ë¥¼ í™”ë©´ì— í‘œì‹œ
    
    Examples:
        >>> eda_proportion(lf, 'device_class', n_rows=50, top_n=3)
    """
    # ê°’ë³„ ì¹´ìš´íŠ¸ ë° ë¹„ìœ¨ ê³„ì‚°
    count_lf = lf.select(
        pl.col(col).value_counts(sort=True)  # ë¹ˆë„ìˆ˜ ê³„ì‚° ë° ì •ë ¬
    ).unnest(col).with_columns(
        (pl.col('count') / pl.col('count').sum() * 100).round(2).alias('percentage')  # ë°±ë¶„ìœ¨ ê³„ì‚°
    ).sort(by='count', descending=True).head(n_rows)
    
    # í…Œì´ë¸” í‘œì‹œ
    display(count_lf.collect().to_pandas())
    
    # ë„ë„› ì°¨íŠ¸ í‘œì‹œ
    draw_donut_chart(count_lf.collect(), col, top_n)


def overview_col(lf: pl.LazyFrame, col: str, n_rows: int = 100) -> None:
    """íŠ¹ì • ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ê°œìˆ˜ì™€ ìƒ˜í”Œ ê°’ë“¤ì„ í‘œì‹œ
    
    ì»¬ëŸ¼ì˜ ê³ ìœ ê°’(unique) ê°œìˆ˜ë¥¼ ì¶œë ¥í•˜ê³ , ìƒìœ„/í•˜ìœ„ ìƒ˜í”Œ ê°’ë“¤ì„ í…Œì´ë¸”ë¡œ í‘œì‹œ
    
    Args:
        lf (pl.LazyFrame): ë¶„ì„í•  LazyFrame
        col (str): ë¶„ì„í•  ì»¬ëŸ¼ëª…
        n_rows (int, optional): í‘œì‹œí•  ìƒ˜í”Œ ê°œìˆ˜. Defaults to 100.
    
    Returns:
        None: ê³ ìœ ê°’ ê°œìˆ˜ì™€ ìƒ˜í”Œ í…Œì´ë¸”ì„ í™”ë©´ì— í‘œì‹œ
    
    Examples:
        >>> overview_col(lf, 'manufacturer_name', n_rows=50)
        manufacturer_nameì˜ ê³ ìœ  ê°œìˆ˜: 1234
        [head/tail ìƒ˜í”Œ í…Œì´ë¸” í‘œì‹œ]
    """
    # ê³ ìœ ê°’ ê°œìˆ˜ ê³„ì‚°
    nunique = lf.select(
        pl.col(col).n_unique().alias(f'unique_{col}')
    ).collect().item()
    
    print(f'{col}ì˜ ê³ ìœ  ê°œìˆ˜: {nunique}')
    
    # ê³ ìœ ê°’ì„ ì •ë ¬í•˜ì—¬ ìƒìœ„/í•˜ìœ„ ìƒ˜í”Œ ì¶”ì¶œ
    unique_lf = lf.select(
        pl.col(col).unique().sort().head(n_rows).alias(f'head_{col}'),  # ìƒìœ„ nê°œ
        pl.col(col).unique().sort().tail(n_rows).alias(f'tail_{col}'),  # í•˜ìœ„ nê°œ
    )
    
    # í…Œì´ë¸” í‘œì‹œ
    display(unique_lf.collect().to_pandas())
    

def analyze_null_values(lf: pl.LazyFrame, analysis_cols=None, verbose=True) -> pl.DataFrame:
    """ì „ì²´ ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜(null) ê°œìˆ˜ì™€ ë¹„ìœ¨ì„ ë¶„ì„
    
    ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜ì™€ ë¹„ìœ¨ì„ ê³„ì‚°í•˜ì—¬ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ëœ DataFrame ë°˜í™˜
    
    Args:
        lf (pl.LazyFrame): ë¶„ì„í•  LazyFrame
        analysis_cols (List[str], optional): ë¶„ì„í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸. Noneì´ë©´ ì „ì²´ ì»¬ëŸ¼. Defaults to None.
        verbose (bool, optional): ê²°ê³¼ë¥¼ ì¶œë ¥í• ì§€ ì—¬ë¶€. Defaults to True.
    
    Returns:
        pl.DataFrame: 'column', 'null_count', 'null_pct' ì»¬ëŸ¼ì„ í¬í•¨í•œ ê²°ì¸¡ì¹˜ ë¶„ì„ ê²°ê³¼
            - column: ì»¬ëŸ¼ëª…
            - null_count: ê²°ì¸¡ì¹˜ ê°œìˆ˜
            - null_pct: ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)
    
    Examples:
        >>> null_df = analyze_null_values(lf, verbose=True)
        === ê²°ì¸¡ì¹˜ ë¶„ì„ ===
        ì „ì²´ í–‰ ìˆ˜: 1,000,000
        
        patient_age                                  :    500,000ê°œ ( 50.00%)
        device_model                                 :    300,000ê°œ ( 30.00%)
        ...
    """
    # ë¶„ì„í•  ì»¬ëŸ¼ ê²°ì • (Noneì´ë©´ ì „ì²´ ì»¬ëŸ¼)
    if analysis_cols is None:
        analysis_cols = lf.collect_schema().names()
    
    # ì „ì²´ í–‰ ìˆ˜ ê³„ì‚°
    total_rows = lf.select(pl.len()).collect().item()
    
    # ê° ì»¬ëŸ¼ì˜ null countë¥¼ í•œ ë²ˆì— ê³„ì‚°
    null_df = (
        lf.select([pl.col(col).null_count().alias(col) for col in analysis_cols])
        .collect()
        .transpose(include_header=True, header_name='column', column_names=['null_count'])  # ì „ì¹˜
        .with_columns(
            (pl.col('null_count') / total_rows * 100).round(2).alias('null_pct')  # ë°±ë¶„ìœ¨ ê³„ì‚°
        )
        .sort('null_pct', descending=True)  # ê²°ì¸¡ì¹˜ ë¹„ìœ¨ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    )
    
    # verbose ëª¨ë“œì¼ ê²½ìš° ê²°ê³¼ ì¶œë ¥
    if verbose:
        print("\n=== ê²°ì¸¡ì¹˜ ë¶„ì„ ===")
        print(f"ì „ì²´ í–‰ ìˆ˜: {total_rows:,}\n")
        for row in null_df.iter_rows(named=True):
            print(f"{row['column']:45s}: {row['null_count']:>10,}ê°œ ({row['null_pct']:>6.2f}%)")
    
    return null_df

def estimate_string_size_stats(lf: pl.LazyFrame, cols: List[str], sample_size: int = 10000) -> Dict[str, float]:
    """ì»¬ëŸ¼ë“¤ì˜ ë¬¸ìì—´ ê¸¸ì´ í†µê³„ë¥¼ ìƒ˜í”Œ ë°ì´í„°ë¡œ ì¶”ì •
    
    Parameters:
    -----------
    lf : pl.LazyFrame
        ìƒ˜í”Œë§í•  LazyFrame
    cols : List[str]
        ì¸¡ì •í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    sample_size : int, default=10000
        ìƒ˜í”Œë§í•  í–‰ ìˆ˜
    
    Returns:
    --------
    Dict[str, float]
        ë¬¸ìì—´ ê¸¸ì´ í†µê³„
        - 'mean': í‰ê· 
        - 'median': ì¤‘ì•™ê°’ (50th percentile)
        - 'p75': 75th percentile
        - 'p90': 90th percentile
        - 'max': ìµœëŒ“ê°’
    
    Examples:
    ---------
    >>> stats = estimate_string_size_stats(lf, ['device_0_name', 'device_1_name'])
    >>> print(f"í‰ê· : {stats['mean']:.1f}ì")
    >>> print(f"ì¤‘ì•™ê°’: {stats['median']:.1f}ì")
    >>> print(f"75%: {stats['p75']:.1f}ì")
    """
    try:
        # ìƒ˜í”Œ ë°ì´í„° ì¶”ì¶œ
        sample = (
            lf.select(cols)
            .head(sample_size)
            .collect(engine='streaming')
        )
        
        # ëª¨ë“  ê°’ì˜ ê¸¸ì´ ìˆ˜ì§‘
        lengths = []
        for col in cols:
            values = sample[col].drop_nulls().to_list()
            lengths.extend([len(str(v)) for v in values])
        
        if not lengths:
            return {
                'mean': 50.0,
                'median': 50.0,
                'p75': 50.0,
                'p90': 50.0,
                'max': 50.0
            }
        
        # Polarsë¡œ í†µê³„ ê³„ì‚°
        lengths_series = pl.Series(lengths)
        
        stats = {
            'mean': lengths_series.mean(),
            'median': lengths_series.median(),
            'p75': lengths_series.quantile(0.75),
            'p90': lengths_series.quantile(0.90),
            'max': lengths_series.max()
        }
        
        return stats
    
    except Exception as e:
        print(f"  âš ï¸ ë¬¸ìì—´ ê¸¸ì´ í†µê³„ ì¶”ì • ì‹¤íŒ¨: {e}")
        return {
            'mean': 50.0,
            'median': 50.0,
            'p75': 50.0,
            'p90': 50.0,
            'max': 50.0
        }

def get_unique(lf: pl.LazyFrame, cols: List[str]) -> set:
    """ì—¬ëŸ¬ ì»¬ëŸ¼ì˜ ëª¨ë“  ê³ ìœ ê°’ì„ í•˜ë‚˜ì˜ setìœ¼ë¡œ ë°˜í™˜
    
    ì—¬ëŸ¬ ì»¬ëŸ¼ì— ê±¸ì³ ë‚˜íƒ€ë‚˜ëŠ” ëª¨ë“  ê³ ìœ í•œ ê°’ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì˜ˆë¥¼ ë“¤ì–´, device_0_name, device_1_name, device_2_name ì»¬ëŸ¼ë“¤ì˜
    ëª¨ë“  ê³ ìœ í•œ ë””ë°”ì´ìŠ¤ ì´ë¦„ì„ í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    lf : pl.LazyFrame
        ë°ì´í„°ë¥¼ ì¶”ì¶œí•  LazyFrame
    cols : List[str]
        ê³ ìœ ê°’ì„ ì¶”ì¶œí•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
    
    Returns:
    --------
    set
        ëª¨ë“  ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ì„ í•©ì¹œ set (ì¤‘ë³µ ì œê±°ë¨)
    
    Examples:
    ---------
    >>> # ì—¬ëŸ¬ device ì»¬ëŸ¼ì˜ ëª¨ë“  ê³ ìœ í•œ ë””ë°”ì´ìŠ¤ ì´ë¦„
    >>> device_cols = ['device_0_name', 'device_1_name', 'device_2_name']
    >>> all_devices = get_unique(lf, device_cols)
    >>> print(f"ì´ ê³ ìœ  ë””ë°”ì´ìŠ¤: {len(all_devices)}ê°œ")
    
    >>> # ì—¬ëŸ¬ ë‚ ì§œ ì»¬ëŸ¼ì˜ ëª¨ë“  ê³ ìœ  ë‚ ì§œ
    >>> date_cols = ['event_date', 'report_date', 'received_date']
    >>> all_dates = get_unique(lf, date_cols)
    
    Notes:
    ------
    - unpivotìœ¼ë¡œ ëª¨ë“  ì»¬ëŸ¼ì„ í•˜ë‚˜ì˜ ì»¬ëŸ¼ìœ¼ë¡œ í•©ì¹œ í›„ unique ì¶”ì¶œ
    - streaming ì—”ì§„ ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
    - ê²°ê³¼ê°€ ë©”ëª¨ë¦¬ì— ì™„ì „íˆ ë¡œë“œë˜ë¯€ë¡œ ê³ ìœ ê°’ì´ ë§¤ìš° ë§ìœ¼ë©´ ì£¼ì˜ í•„ìš”
    """
    unique_set = set(
        lf.select(cols)  # ì§€ì •ëœ ì»¬ëŸ¼ë§Œ ì„ íƒ
        .unpivot(on=cols)  # ëª¨ë“  ì»¬ëŸ¼ì„ 'value' ì»¬ëŸ¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        .select('value')  # value ì»¬ëŸ¼ë§Œ ì„ íƒ
        .unique()  # ì¤‘ë³µ ì œê±°
        .drop_nulls() # ê²°ì¸¡ì¹˜ ì œê±°
        .collect(engine='streaming')  # streaming ì—”ì§„ìœ¼ë¡œ ì‹¤í–‰ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
        ['value']  # value ì»¬ëŸ¼ ì¶”ì¶œ
    )
    return unique_set


def get_unique_by_cols(lf: pl.LazyFrame, cols_group: Dict[str, List[str]]) -> Dict[str, set]:
    """ì»¬ëŸ¼ ê·¸ë£¹ë³„ë¡œ ê³ ìœ ê°’ì„ ì¶”ì¶œí•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
    
    ì—¬ëŸ¬ ì»¬ëŸ¼ ê·¸ë£¹ì— ëŒ€í•´ ê°ê° ê³ ìœ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì˜ˆë¥¼ ë“¤ì–´, device ê´€ë ¨ ì»¬ëŸ¼ë“¤, patient ê´€ë ¨ ì»¬ëŸ¼ë“¤ì˜ ê³ ìœ ê°’ì„
    ê°ê° ë³„ë„ë¡œ ì¶”ì¶œí•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    lf : pl.LazyFrame
        ë°ì´í„°ë¥¼ ì¶”ì¶œí•  LazyFrame
    cols_group : Dict[str, List[str]]
        ê·¸ë£¹ëª…ì„ í‚¤ë¡œ, ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
        ì˜ˆ: {
            'devices': ['device_0_name', 'device_1_name'],
            'manufacturers': ['device_0_manufacturer', 'device_1_manufacturer']
        }
    
    Returns:
    --------
    Dict[str, set]
        ê° ê·¸ë£¹ì˜ ê³ ìœ ê°’ setì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
        ì˜ˆ: {
            'devices': {'Device A', 'Device B', ...},
            'manufacturers': {'Company X', 'Company Y', ...}
        }
    
    Examples:
    ---------
    >>> # ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ë³„ ê³ ìœ ê°’ ì¶”ì¶œ
    >>> cols_group = {
    ...     'devices': ['device_0_name', 'device_1_name', 'device_2_name'],
    ...     'manufacturers': ['device_0_manufacturer', 'device_1_manufacturer'],
    ...     'models': ['device_0_model', 'device_1_model']
    ... }
    >>> unique_values = get_unique_by_cols(lf, cols_group)
    >>> 
    >>> # ê²°ê³¼ í™•ì¸
    >>> for group, values in unique_values.items():
    ...     print(f"{group}: {len(values)}ê°œì˜ ê³ ìœ ê°’")
    
    >>> # íŠ¹ì • ê·¸ë£¹ì˜ ê°’ ì ‘ê·¼
    >>> all_devices = unique_values['devices']
    >>> all_manufacturers = unique_values['manufacturers']
    
    WARNINGS:
    ---------
    âš ï¸ **ë©”ëª¨ë¦¬ ì‚¬ìš© ì£¼ì˜ì‚¬í•­**:
    - ì´ í•¨ìˆ˜ëŠ” ê° ê·¸ë£¹ë³„ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ê³ ìœ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤
    - ê° ê·¸ë£¹ì˜ ê³ ìœ ê°’ì´ ë©”ëª¨ë¦¬ì— ì™„ì „íˆ ë¡œë“œë©ë‹ˆë‹¤
    - ê³ ìœ ê°’ì´ ë§¤ìš° ë§ì€ ê²½ìš°(ìˆ˜ì‹­ë§Œ~ìˆ˜ë°±ë§Œ ê°œ) ë©”ëª¨ë¦¬ ë¶€ì¡± ë°œìƒ ê°€ëŠ¥
    
    **ë©”ëª¨ë¦¬ ì ˆì•½ ëŒ€ì•ˆ**:
    - ê³ ìœ ê°’ ê°œìˆ˜ë§Œ í•„ìš”í•œ ê²½ìš°: n_unique() ì‚¬ìš©
    - ìƒ˜í”Œë§Œ í•„ìš”í•œ ê²½ìš°: .unique().limit(n) ì‚¬ìš©
    - ë§¤ìš° í° ë°ì´í„°: ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ ë””ìŠ¤í¬ ê¸°ë°˜ ì²˜ë¦¬ ê³ ë ¤
    
    Example (ì•ˆì „í•œ ì‚¬ìš©):
    >>> # ê³ ìœ ê°’ ê°œìˆ˜ë§Œ í™•ì¸ (ë©”ëª¨ë¦¬ ì•ˆì „)
    >>> for group, cols in cols_group.items():
    ...     n_unique = lf.select(cols).unpivot(on=cols).select('value').n_unique().collect().item()
    ...     print(f"{group}: {n_unique}ê°œ")
    ...     if n_unique > 100000:  # ì„ê³„ê°’ ì²´í¬
    ...         print(f"âš ï¸ {group}ì€ ê³ ìœ ê°’ì´ ë„ˆë¬´ ë§ì•„ ê±´ë„ˆëœë‹ˆë‹¤")
    """
    unique_by_cols = {}
    
    # ê° ê·¸ë£¹ë³„ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ê³ ìœ ê°’ ì¶”ì¶œ
    for group, cols in cols_group.items():
        unique_by_cols[group] = get_unique(lf, cols)
    
    return unique_by_cols

def get_unique_by_cols_safe(
    lf: pl.LazyFrame, 
    cols_group: Dict[str, List[str]],
    max_unique: int = None,
    memory_safety_ratio: float = 0.1,
    check_first: bool = True,
    estimate_string_size: bool = True,
    sample_size: int = 10000,
    size_metric: str = 'p75',
    calibration_factor: float = 1.0
) -> Dict[str, set]:
    """ë©”ëª¨ë¦¬ ì•ˆì „í•˜ê²Œ ì»¬ëŸ¼ ê·¸ë£¹ë³„ ê³ ìœ ê°’ ì¶”ì¶œ (ìë™ ì„ê³„ê°’ ê³„ì‚°)
    
    ì‹œìŠ¤í…œì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ì™€ ì‹¤ì œ ë°ì´í„°ì˜ ë¬¸ìì—´ ê¸¸ì´ í†µê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    ì•ˆì „í•œ ìµœëŒ€ ê³ ìœ ê°’ ê°œìˆ˜ë¥¼ ìë™ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    lf : pl.LazyFrame
        ë°ì´í„°ë¥¼ ì¶”ì¶œí•  LazyFrame
    cols_group : Dict[str, List[str]]
        ê·¸ë£¹ëª…: ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬
        ì˜ˆ: {'devices': ['device_0_name', 'device_1_name']}
    max_unique : int, optional
        ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•  ìµœëŒ€ ê³ ìœ ê°’ ê°œìˆ˜. Noneì´ë©´ ìë™ ê³„ì‚°. Defaults to None.
    memory_safety_ratio : float, default=0.1
        ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ì˜ ëª‡ %ê¹Œì§€ ì‚¬ìš©í• ì§€ (0.1 = 10%)
        ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì • ê¶Œì¥ (0.05 ~ 0.15)
    check_first : bool, default=True
        ì¶”ì¶œ ì „ì— ê³ ìœ ê°’ ê°œìˆ˜ë¥¼ ë¨¼ì € ì²´í¬í• ì§€ ì—¬ë¶€
    estimate_string_size : bool, default=True
        ì‹¤ì œ ë°ì´í„°ë¡œë¶€í„° ë¬¸ìì—´ ê¸¸ì´ë¥¼ ì¶”ì •í• ì§€ ì—¬ë¶€
        True ê¶Œì¥ (ë” ì •í™•í•œ ì˜ˆì¸¡)
    sample_size : int, default=10000
        ë¬¸ìì—´ ê¸¸ì´ ì¶”ì • ì‹œ ìƒ˜í”Œë§í•  í–‰ ìˆ˜
    size_metric : str, default='p75'
        ì‚¬ìš©í•  í¬ê¸° ì¸¡ì • ê¸°ì¤€
        - 'mean': í‰ê·  (ê·¹ë‹¨ê°’ì— ë¯¼ê°, ë¹„ì¶”ì²œ)
        - 'median': ì¤‘ì•™ê°’ (50th percentile, ì•ˆì •ì )
        - 'p75': 75th percentile (ê¶Œì¥, ëŒ€ë¶€ë¶„ ì»¤ë²„í•˜ë©´ì„œ ì•ˆì „)
        - 'p90': 90th percentile (ë§¤ìš° ë³´ìˆ˜ì )
    calibration_factor : float, default=1.0
        ë©”ëª¨ë¦¬ ì¶”ì • ë³´ì • ê³„ìˆ˜
        - 1.0ë³´ë‹¤ í¬ë©´ ë” ë³´ìˆ˜ì  (ë©”ëª¨ë¦¬ë¥¼ ë” ë§ì´ ì˜ˆìƒ)
        - 1.0ë³´ë‹¤ ì‘ìœ¼ë©´ ëœ ë³´ìˆ˜ì 
        í•¨ìˆ˜ ì‹¤í–‰ í›„ í”¼ë“œë°±ì„ ë³´ê³  ì¡°ì • ê°€ëŠ¥
    
    Returns:
    --------
    Dict[str, set or None]
        ì•ˆì „í•˜ê²Œ ì¶”ì¶œëœ ê³ ìœ ê°’ ë”•ì…”ë„ˆë¦¬
        - ì„±ê³µ: set of unique values
        - ì‹¤íŒ¨ ë˜ëŠ” ìŠ¤í‚µ: None
    
    Examples:
    ---------
    >>> # ê¸°ë³¸ ì„¤ì • (75th percentile ì‚¬ìš©)
    >>> cols_group = {
    ...     'devices': ['device_0_name', 'device_1_name'],
    ...     'manufacturers': ['device_0_manufacturer', 'device_1_manufacturer']
    ... }
    >>> unique_values = get_unique_by_cols_safe(lf, cols_group)
    
    >>> # ì¤‘ì•™ê°’ ì‚¬ìš© (ëœ ë³´ìˆ˜ì )
    >>> unique_values = get_unique_by_cols_safe(
    ...     lf, 
    ...     cols_group,
    ...     size_metric='median',
    ...     memory_safety_ratio=0.15
    ... )
    
    >>> # 90th percentile ì‚¬ìš© (ë” ë³´ìˆ˜ì )
    >>> unique_values = get_unique_by_cols_safe(
    ...     lf, 
    ...     cols_group,
    ...     size_metric='p90',
    ...     memory_safety_ratio=0.05
    ... )
    
    >>> # ë³´ì • ê³„ìˆ˜ ì ìš© (ì´ì „ ì‹¤í–‰ì—ì„œ í”¼ë“œë°± ë°›ì€ ê²½ìš°)
    >>> unique_values = get_unique_by_cols_safe(
    ...     lf,
    ...     cols_group,
    ...     calibration_factor=0.8  # ë©”ëª¨ë¦¬ë¥¼ ê³¼ëŒ€í‰ê°€í–ˆë‹¤ë©´
    ... )
    
    Notes:
    ------
    - **ê¶Œì¥ ì„¤ì •**: size_metric='p75', memory_safety_ratio=0.1 (ê¸°ë³¸ê°’)
    - í‰ê· (mean)ì€ ê·¹ë‹¨ê°’ì— ë¯¼ê°í•˜ë¯€ë¡œ ë¹„ì¶”ì²œ
    - ì¤‘ì•™ê°’(median)ì€ ì•ˆì •ì ì´ì§€ë§Œ í° ê°’ë“¤ì„ ê³¼ì†Œí‰ê°€í•  ìˆ˜ ìˆìŒ
    - calibration_factorëŠ” ì‹¤í–‰ í›„ í”¼ë“œë°±ì„ ë³´ê³  ì¡°ì •
    - ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì€ ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
    """
    # max_uniqueê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìë™ ê³„ì‚°
    if max_unique is None:
        # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (bytes) í™•ì¸
        available_memory = psutil.virtual_memory().available
        
        # 2. ì•ˆì „ ë§ˆì§„ì„ ê³ ë ¤í•œ ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬
        safe_memory = available_memory * memory_safety_ratio
        
        # 3. ë¬¸ìì—´ ê¸¸ì´ í†µê³„ ì¶”ì •
        if estimate_string_size:
            print("ë¬¸ìì—´ ê¸¸ì´ í†µê³„ë¥¼ ì‹¤ì œ ë°ì´í„°ë¡œë¶€í„° ì¶”ì • ì¤‘...")
            # ëª¨ë“  ì»¬ëŸ¼ ìˆ˜ì§‘
            all_cols = [col for cols in cols_group.values() for col in cols]
            # í†µê³„ ê³„ì‚°
            stats = estimate_string_size_stats(lf, all_cols, sample_size)
            
            # ì„ íƒëœ ë©”íŠ¸ë¦­ ì‚¬ìš©
            avg_string_size = stats[size_metric]
            
            # í†µê³„ ì¶œë ¥
            print(f"  ë¬¸ìì—´ ê¸¸ì´ í†µê³„:")
            print(f"    - í‰ê· (mean): {stats['mean']:.1f}ì")
            print(f"    - ì¤‘ì•™ê°’(median): {stats['median']:.1f}ì")
            print(f"    - 75%ile: {stats['p75']:.1f}ì")
            print(f"    - 90%ile: {stats['p90']:.1f}ì")
            print(f"    - ìµœëŒ“ê°’: {stats['max']:.0f}ì")
            print(f"  â†’ ì‚¬ìš©í•  í¬ê¸°({size_metric}): {avg_string_size:.1f}ì\n")
        else:
            # ì¶”ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            avg_string_size = 50  # ê¸°ë³¸ê°’: 50ì
        
        # 4. Python stringì˜ ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
        # Python 3.3+ì—ì„œ:
        # - ASCIIëŠ” 1byte/char
        # - UnicodeëŠ” 2-4bytes/char
        # - í‰ê· ì ìœ¼ë¡œ 2bytes/charë¡œ ê°€ì • (ì˜ë¬¸+ìˆ«ì í˜¼í•©)
        bytes_per_char = 2
        
        # 5. Python ê°ì²´ ì˜¤ë²„í—¤ë“œ
        str_overhead = 50   # str ê°ì²´ í—¤ë”: ~50 bytes
        set_overhead = 28   # set entry ì˜¤ë²„í—¤ë“œ: ~28 bytes (hash table)
        
        # 6. ì´ ì˜ˆìƒ ë°”ì´íŠ¸ ìˆ˜ ê³„ì‚°
        estimated_bytes_per_unique = (
            (avg_string_size * bytes_per_char) +  # ì‹¤ì œ ë¬¸ìì—´ ë°ì´í„°
            str_overhead +                         # str ê°ì²´ ì˜¤ë²„í—¤ë“œ
            set_overhead                           # set ìë£Œêµ¬ì¡° ì˜¤ë²„í—¤ë“œ
        ) * calibration_factor  # ë³´ì • ê³„ìˆ˜ ì ìš©
        
        # 7. ì•ˆì „í•œ ìµœëŒ€ ê³ ìœ ê°’ ê°œìˆ˜ ê³„ì‚°
        max_unique = int(safe_memory / estimated_bytes_per_unique)
        
        # 8. ê³„ì‚° ê²°ê³¼ ì¶œë ¥
        print(f"=== ë©”ëª¨ë¦¬ ê¸°ë°˜ ìë™ ì„ê³„ê°’ ê³„ì‚° ===")
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {available_memory / (1024**3):.2f} GB")
        print(f"ì•ˆì „ ì‚¬ìš© ë©”ëª¨ë¦¬ ({memory_safety_ratio*100:.0f}%): {safe_memory / (1024**3):.2f} GB")
        print(f"ì˜ˆìƒ ë°”ì´íŠ¸/ê³ ìœ ê°’: {estimated_bytes_per_unique:.0f} bytes")
        print(f"  - ë¬¸ìì—´ ë°ì´í„°: {avg_string_size * bytes_per_char:.0f} bytes")
        print(f"  - str ì˜¤ë²„í—¤ë“œ: {str_overhead} bytes")
        print(f"  - set ì˜¤ë²„í—¤ë“œ: {set_overhead} bytes")
        if calibration_factor != 1.0:
            print(f"  - ë³´ì • ê³„ìˆ˜: {calibration_factor}x")
        print(f"ê³„ì‚°ëœ ìµœëŒ€ ê³ ìœ ê°’: {max_unique:,}ê°œ")
        print(f"{'='*40}\n")
    else:
        # ìˆ˜ë™ ì§€ì •ëœ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì˜ˆìƒ ë©”ëª¨ë¦¬ ê³„ì‚°
        avg_string_size = 50
        bytes_per_char = 2
        str_overhead = 50
        set_overhead = 28
        estimated_bytes_per_unique = (
            (avg_string_size * bytes_per_char) + str_overhead + set_overhead
        ) * calibration_factor
    
    # ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    unique_by_cols = {}
    
    # ê° ê·¸ë£¹ë³„ë¡œ ì²˜ë¦¬
    for group, cols in tqdm(cols_group.items(), desc="Extracting unique values"):
        # ì‚¬ì „ ì²´í¬: ê³ ìœ ê°’ ê°œìˆ˜ í™•ì¸
        if check_first:
            # ê³ ìœ ê°’ ê°œìˆ˜ ê³„ì‚° (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
            n_unique = (
                lf.select(cols)
                .unpivot(on=cols)  # ëª¨ë“  ì»¬ëŸ¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
                .select(pl.col('value').n_unique())  # ê³ ìœ ê°’ ê°œìˆ˜ë§Œ ê³„ì‚°
                .collect(engine='streaming')  # streaming ì—”ì§„ ì‚¬ìš©
                .item()  # ë‹¨ì¼ ê°’ ì¶”ì¶œ
            )
            
            # ì˜ˆìƒ ë©”ëª¨ë¦¬ ê³„ì‚°
            estimated_mem_mb = (n_unique * estimated_bytes_per_unique) / (1024**2)
            print(f"{group}: {n_unique:,}ê°œì˜ ê³ ìœ ê°’ (ì˜ˆìƒ ë©”ëª¨ë¦¬: {estimated_mem_mb:.1f} MB)")
            
            # ì„ê³„ê°’ ì´ˆê³¼ ì²´í¬
            if n_unique > max_unique:
                print(f"  âš ï¸ {group}ì€ ê³ ìœ ê°’ì´ {max_unique:,}ê°œë¥¼ ì´ˆê³¼í•˜ì—¬ ê±´ë„ˆëœë‹ˆë‹¤\n")
                unique_by_cols[group] = None
                continue
        
        # ì•ˆì „í•˜ë©´ ì‹¤ì œ ì¶”ì¶œ ì‹œë„
        try:
            # get_unique í•¨ìˆ˜ë¡œ ê³ ìœ ê°’ ì¶”ì¶œ
            unique_by_cols[group] = get_unique(lf, cols)
            
            # ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (ë” ì •í™•í•œ ë°©ë²•)
            # ê° ë¬¸ìì—´ì˜ í¬ê¸° í•©ê³„
            actual_bytes = sum(sys.getsizeof(s) for s in unique_by_cols[group])
            # set ê°ì²´ ìì²´ì˜ í¬ê¸° ì¶”ê°€
            actual_bytes += sys.getsizeof(unique_by_cols[group])
            actual_mb = actual_bytes / (1024**2)
            
            # ì˜ˆì¸¡ ì •í™•ë„ ê³„ì‚°
            accuracy_pct = (estimated_mem_mb / actual_mb) * 100 if actual_mb > 0 else 0
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"  âœ“ {group} ì¶”ì¶œ ì™„ë£Œ (ì‹¤ì œ ë©”ëª¨ë¦¬: {actual_mb:.2f} MB)")
            print(f"    â†’ ì˜ˆìƒì¹˜ ì •í™•ë„: {accuracy_pct:.1f}% (ì˜ˆìƒ/ì‹¤ì œ ë¹„ìœ¨)")
            
            # ë³´ì • ê³„ìˆ˜ í”¼ë“œë°±
            # ì˜ˆì¸¡ê°’ì´ ì‹¤ì œê°’ì˜ 150% ì´ìƒì´ë©´ (ê³¼ëŒ€í‰ê°€)
            if accuracy_pct > 150:
                suggested_factor = calibration_factor * 0.8
                print(f"    ğŸ’¡ Tip: calibration_factorë¥¼ {suggested_factor:.2f}ë¡œ ë‚®ì¶”ë©´ ë” ì •í™•í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤")
            # ì˜ˆì¸¡ê°’ì´ ì‹¤ì œê°’ì˜ 80% ë¯¸ë§Œì´ë©´ (ê³¼ì†Œí‰ê°€)
            elif accuracy_pct < 80:
                suggested_factor = calibration_factor * 1.2
                print(f"    ğŸ’¡ Tip: calibration_factorë¥¼ {suggested_factor:.2f}ë¡œ ë†’ì´ë©´ ë” ì •í™•í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤")
            print()
            
        except MemoryError:
            # ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì‹¤íŒ¨
            print(f"  âŒ {group} ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì‹¤íŒ¨\n")
            unique_by_cols[group] = None
    
    # 2. ê²°ê³¼ ìš”ì•½
    print("\n=== ì¶”ì¶œ ìš”ì•½ ===")
    success = sum(1 for v in unique_by_cols.values() if v is not None)
    print(f"ì„±ê³µ: {success}/{len(cols_group)}")
    print(f"ì‹¤íŒ¨/ìŠ¤í‚µ: {len(cols_group) - success}/{len(cols_group)}")
    return unique_by_cols




def groupby_nunique_safe(
    lf: pl.LazyFrame, 
    group_cols: List[str],
    agg_cols: List[str] = None,
    top_n: int = 100,
    streaming: bool = True
) -> pl.DataFrame:
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ group by í›„ ê° ê·¸ë£¹ì˜ í–‰ ê°œìˆ˜ì™€ unique ê°œìˆ˜ ê³„ì‚°
    
    ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ë©”ëª¨ë¦¬ ì˜¤ë²„í”Œë¡œìš° ì—†ì´ ê·¸ë£¹ë³„ ì§‘ê³„ë¥¼ ìˆ˜í–‰
    streaming ì˜µì…˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì†Œí™”
    
    Parameters:
    -----------
    lf : pl.LazyFrame
        ë¶„ì„í•  LazyFrame
    group_cols : List[str]
        ê·¸ë£¹í™”í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    agg_cols : List[str], optional
        unique ê°œìˆ˜ë¥¼ ì…€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸. Noneì´ë©´ countë§Œ ê³„ì‚°. Defaults to None.
    top_n : int, optional
        ìƒìœ„ ëª‡ ê°œ ê·¸ë£¹ë§Œ ë°˜í™˜í• ì§€. Defaults to 100.
    streaming : bool, optional
        streaming ì—”ì§„ ì‚¬ìš© ì—¬ë¶€ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ). Defaults to True.
    
    Returns:
    --------
    pl.DataFrame: ê·¸ë£¹ë³„ ì§‘ê³„ ê²°ê³¼ DataFrame
        - group_cols: ê·¸ë£¹í™” ì»¬ëŸ¼ë“¤
        - count: ê° ê·¸ë£¹ì˜ í–‰ ê°œìˆ˜
        - {col}_unique: ê° ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ê°œìˆ˜ (agg_cols ì§€ì • ì‹œ)
    
    Examples:
    ---------
    >>> # ë‹¨ìˆœ ì¹´ìš´íŠ¸ë§Œ
    >>> result = safe_groupby_unique(
    ...     lf, 
    ...     group_cols=['device_model', 'brand_name'],
    ...     top_n=50
    ... )
    
    >>> # unique ê°œìˆ˜ë„ í•¨ê»˜ ê³„ì‚°
    >>> result = safe_groupby_unique(
    ...     lf,
    ...     group_cols=['device_model', 'brand_name'],
    ...     agg_cols=['report_id', 'event_type'],
    ...     top_n=100,
    ...     streaming=True
    ... )
    """
    # ì§‘ê³„ í‘œí˜„ì‹ êµ¬ì„±
    if agg_cols is None:
        # countë§Œ ê³„ì‚°
        agg_exprs = [pl.len().alias('count')]
    else:
        # count + ê° ì»¬ëŸ¼ì˜ unique ê°œìˆ˜ ê³„ì‚°
        agg_exprs = [
            pl.len().alias('count')
        ] + [
            pl.col(col).n_unique().alias(f'{col}_unique')
            for col in agg_cols
        ]
    
    # streaming ì—¬ë¶€ì— ë”°ë¼ ì—”ì§„ ì„ íƒ
    engine = 'streaming' if streaming else 'auto'
    
    # group by í›„ ì§‘ê³„, ì •ë ¬, ìƒìœ„ Nê°œë§Œ ë°˜í™˜
    return (
        lf.group_by(group_cols)
        .agg(agg_exprs)
        .sort('count', descending=True)  # count ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
        .head(top_n)  # ìƒìœ„ Nê°œë§Œ
        .collect(engine=engine)  # ì§€ì •ëœ ì—”ì§„ìœ¼ë¡œ ì‹¤í–‰
        .to_pandas()  # pandas DataFrameìœ¼ë¡œ ë³€í™˜
    )
    

def replace_pattern_with_null(lf: pl.LazyFrame, cols: Union[str, List[str]], na_pattern: str) -> pl.LazyFrame:
    """ì§€ì •ëœ ì»¬ëŸ¼ë“¤ì—ì„œ ì •ê·œì‹ íŒ¨í„´ê³¼ ë§¤ì¹­ë˜ëŠ” ê°’ì„ nullë¡œ ë³€ê²½
    
    ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ íŒ¨í„´ê³¼ ë§¤ì¹­ë˜ëŠ” ëª¨ë“  ê°’ì„ nullë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.
    ê²°ì¸¡ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë‹¤ì–‘í•œ í‘œí˜„('N/A', 'UNKNOWN', 'NONE' ë“±)ì„ í†µì¼ëœ nullë¡œ ë³€í™˜í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    lf : pl.LazyFrame
        ì²˜ë¦¬í•  LazyFrame
    cols : str or List[str]
        ì²˜ë¦¬í•  ì»¬ëŸ¼ëª… (ë‹¨ì¼ ì»¬ëŸ¼ ë¬¸ìì—´ ë˜ëŠ” ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸)
    na_pattern : str
        nullë¡œ ë³€ê²½í•  ì •ê·œì‹ íŒ¨í„´
        ì˜ˆ: r'^(N/A|UNKNOWN|NONE|NA)$' - ì •í™•íˆ ì´ ê°’ë“¤ë§Œ ë§¤ì¹­
            r'UNKNOWN' - UNKNOWNì´ í¬í•¨ëœ ëª¨ë“  ê°’ ë§¤ì¹­
    
    Returns:
    --------
    pl.LazyFrame
        íŒ¨í„´ì— ë§¤ì¹­ëœ ê°’ì´ nullë¡œ ë³€ê²½ëœ LazyFrame
    
    Examples:
    ---------
    >>> # ë‹¨ì¼ ì»¬ëŸ¼ ì²˜ë¦¬
    >>> lf = replace_pattern_with_null(lf, 'device_name', r'^(N/A|UNKNOWN)$')
    
    >>> # ì—¬ëŸ¬ ì»¬ëŸ¼ ë™ì‹œ ì²˜ë¦¬
    >>> lf = replace_pattern_with_null(
    ...     lf, 
    ...     ['device_name', 'manufacturer', 'model'], 
    ...     r'^(N/A|UNKNOWN|NONE|NA|-|NULL)$'
    ... )
    
    Notes:
    ------
    - ëŒ€ì†Œë¬¸ìë¥¼ êµ¬ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ìë™ìœ¼ë¡œ ëŒ€ë¬¸ìë¡œ ë³€í™˜ í›„ ë¹„êµ)
    - ì›ë³¸ ì»¬ëŸ¼ëª…ì„ ìœ ì§€í•©ë‹ˆë‹¤ (.name.keep())
    """
    # ë‹¨ì¼ ì»¬ëŸ¼ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(cols, str):
        cols = [cols]
    
    # íŒ¨í„´ ë§¤ì¹­ëœ ê°’ì„ nullë¡œ ë³€ê²½
    replace_null_lf = lf.with_columns(
        pl.when(pl.col(cols).str.to_uppercase().str.contains(na_pattern))  # ëŒ€ë¬¸ì ë³€í™˜ í›„ íŒ¨í„´ ê²€ì‚¬
        .then(None)  # ë§¤ì¹­ë˜ë©´ null
        .otherwise(pl.col(cols))  # ë§¤ì¹­ ì•ˆ ë˜ë©´ ì›ë³¸ ìœ ì§€
        .name.keep()  # ì›ë³¸ ì»¬ëŸ¼ëª… ìœ ì§€
    )
    return replace_null_lf


def yn_to_bool(lf: pl.LazyFrame, cols: List[str]) -> pl.LazyFrame:
    """Y/N ë¬¸ìì—´ ê°’ì„ boolean íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    
    'Y'ëŠ” Trueë¡œ, 'N'ì€ Falseë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ëŒ€ì†Œë¬¸ìë¥¼ êµ¬ë¶„í•˜ì§€ ì•Šìœ¼ë©°, Y/Nì´ ì•„ë‹Œ ê°’ì€ nullì´ ë©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    lf : pl.LazyFrame
        ë³€í™˜í•  LazyFrame
    cols : List[str]
        ë³€í™˜í•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
    
    Returns:
    --------
    pl.LazyFrame
        Y/N ê°’ì´ booleanìœ¼ë¡œ ë³€í™˜ëœ LazyFrame
    
    Examples:
    ---------
    >>> # ë‹¨ì¼ ì»¬ëŸ¼ ë³€í™˜
    >>> lf = yn_to_bool(lf, ['report_to_fda'])
    
    >>> # ì—¬ëŸ¬ ì»¬ëŸ¼ ë™ì‹œ ë³€í™˜
    >>> lf = yn_to_bool(lf, [
    ...     'report_to_fda', 
    ...     'report_to_manufacturer',
    ...     'device_operator_known'
    ... ])
    
    Notes:
    ------
    - 'Y', 'y' â†’ True
    - 'N', 'n' â†’ False  
    - ê·¸ ì™¸ ê°’ â†’ None (null)
    - ì›ë³¸ì´ ì´ë¯¸ nullì¸ ê²½ìš° null ìœ ì§€
    """
    bool_lf = lf.with_columns([
        pl.col(col)
        .str.to_uppercase()  # ëŒ€ì†Œë¬¸ì í†µì¼ (Y/Nìœ¼ë¡œ ë³€í™˜)
        .replace({'Y': True, 'N': False})  # Yâ†’True, Nâ†’False, ë‚˜ë¨¸ì§€â†’null
        .alias(col)  # ë™ì¼í•œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë®ì–´ì“°ê¸°
        for col in cols
    ])
    return bool_lf


def str_to_categorical(lf: pl.LazyFrame, cols: List[str]) -> pl.LazyFrame:
    """String íƒ€ì… ì»¬ëŸ¼ì„ Categorical íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    
    ê³ ìœ ê°’(unique value)ì´ ì ì€ ì»¬ëŸ¼ì„ Categoricalë¡œ ë³€í™˜í•˜ë©´:
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ (ë¬¸ìì—´ì„ ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ì €ì¥)
    - groupby, join ë“±ì˜ ì—°ì‚° ì†ë„ í–¥ìƒ
    - ì •ë ¬ ë° í•„í„°ë§ ì„±ëŠ¥ ê°œì„ 
    
    Parameters:
    -----------
    lf : pl.LazyFrame
        ë³€í™˜í•  LazyFrame
    cols : List[str]
        Categoricalë¡œ ë³€í™˜í•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
    
    Returns:
    --------
    pl.LazyFrame
        ì§€ì •ëœ ì»¬ëŸ¼ì´ Categorical íƒ€ì…ìœ¼ë¡œ ë³€í™˜ëœ LazyFrame
    
    Examples:
    ---------
    >>> # ë‹¨ì¼ ì»¬ëŸ¼ ë³€í™˜
    >>> lf = str_to_categorical(lf, ['device_class'])
    
    >>> # ì—¬ëŸ¬ ì»¬ëŸ¼ ë™ì‹œ ë³€í™˜ (ê³ ìœ ê°’ì´ ì ì€ ì»¬ëŸ¼ë“¤)
    >>> lf = str_to_categorical(lf, [
    ...     'device_class',      # ì˜ˆ: 1, 2, 3
    ...     'event_type',        # ì˜ˆ: Injury, Malfunction, Death
    ...     'report_source',     # ì˜ˆ: Manufacturer, User Facility, Distributor
    ...     'country'            # ì˜ˆ: US, CA, UK, JP, ...
    ... ])
    
    >>> # íƒ€ì… í™•ì¸
    >>> lf.collect().schema
    
    Notes:
    ------
    - ê³ ìœ ê°’ì´ ë§ì€ ì»¬ëŸ¼(ì˜ˆ: ID, ì´ë¦„)ì€ ë³€í™˜í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤
    - ì¼ë°˜ì ìœ¼ë¡œ ê³ ìœ ê°’ì´ ì „ì²´ í–‰ì˜ 5% ë¯¸ë§Œì¼ ë•Œ íš¨ê³¼ì ì…ë‹ˆë‹¤
    - Categorical íƒ€ì…ì€ ê¸°ë³¸ì ìœ¼ë¡œ "physical" ìˆœì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤
    """
    # ì§€ì •ëœ ì»¬ëŸ¼ë“¤ì„ Categorical íƒ€ì…ìœ¼ë¡œ ìºìŠ¤íŒ…
    categorical_lf = lf.with_columns(
        pl.col(cols).cast(pl.Categorical)
    )
    return categorical_lf