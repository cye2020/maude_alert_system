"""
UDI ì²˜ë¦¬ ë©”ì¸ í´ë˜ìŠ¤ (Score ê¸°ë°˜ ë§¤ì¹­, Path ê¸°ë°˜ ì„¤ê³„)
"""
from uuid import uuid4
import polars as pl
from pathlib import Path
from tqdm import tqdm

from src.preprocess.config import Config
from src.preprocess.preprocess import (
    extract_di_from_public,
    fuzzy_match_dict,
    collect_unique_safe
)
from src.utils.chunk import process_lazyframe_in_chunks
from src.utils import uuid5_from_str


class UDIProcessor:
    """
    UDI-DI ê²°ì¸¡ ì²˜ë¦¬ í´ë˜ìŠ¤
    
    í•µì‹¬ ì›ì¹™: í•¨ìˆ˜ ê²½ê³„ = ì‹¤í–‰ ê²½ê³„
    - ëª¨ë“  ë‚´ë¶€ í•¨ìˆ˜ëŠ” Pathë¥¼ ë°˜í™˜ (LazyFrame âŒ)
    - ìƒìœ„ ë ˆë²¨ì—ì„œë§Œ scan_parquet
    - temp ì‚­ì œëŠ” ìµœìƒìœ„ finallyì—ì„œë§Œ
    """

    def __init__(self, config: Config = None):
        self.config = config or Config()
        self.udi_di_lookup = None  # Primary ì§ì ‘ ë§¤ì¹­ìš© (collectë¨)
        self.udi_full_lookup_lf = None  # Score ë§¤ì¹­ìš© (LazyFrame, í° ë°ì´í„°)
        self.mfr_mapping = None

        self._temp_paths: list[Path] = []
        self.config.TEMP_DIR.mkdir(parents=True, exist_ok=True)

    # ==================== Temp ê´€ë¦¬ ====================
    
    def _new_temp_path(self, name: str) -> Path:
        """temp íŒŒì¼ ê²½ë¡œ ìƒì„± ë° ì¶”ì """
        path = self.config.TEMP_DIR / name
        self._temp_paths.append(path)
        return path

    def _cleanup_temps(self):
        """ëª¨ë“  temp íŒŒì¼ ì‚­ì œ"""
        for p in self._temp_paths:
            try:
                p.unlink()
            except FileNotFoundError:
                pass

    # ==================== 1ë‹¨ê³„: ì „ì²˜ë¦¬ ====================
    
    def preprocess_maude(self, lf: pl.LazyFrame) -> pl.LazyFrame:
        """MAUDE ì „ì²˜ë¦¬ (LazyFrame ìœ ì§€)"""
        print("ğŸ”§ MAUDE ì „ì²˜ë¦¬...")
        
        cols = lf.collect_schema().names()
        
        lf = lf.with_columns([
            pl.col("udi_public")
              .map_elements(extract_di_from_public, return_dtype=pl.Utf8)
              .alias("extracted_di"),
            
            pl.coalesce([pl.col(c) for c in self.config.MAUDE_DATES if c in cols])
              .alias("report_date"),
        ])
        
        lf = lf.with_columns([
            pl.coalesce(["udi_di", "extracted_di"]).alias("udi_combined"),
            
            pl.when(pl.col("udi_di").is_not_null())
              .then(pl.lit("original"))
              .when(pl.col("extracted_di").is_not_null())
              .then(pl.lit("extracted"))
              .otherwise(pl.lit("missing"))
              .alias("udi_source"),
        ])
        
        print("   âœ“ ì „ì²˜ë¦¬ ì™„ë£Œ")
        return lf

    def preprocess_udi_db(self, lf: pl.LazyFrame) -> pl.LazyFrame:
        """UDI DB ì „ì²˜ë¦¬ (LazyFrame ìœ ì§€)"""
        print("ğŸ”§ UDI DB ì „ì²˜ë¦¬...")
        
        cols = lf.collect_schema().names()
        return lf.with_columns([
            pl.coalesce([pl.col(c) for c in self.config.UDI_DATES if c in cols])
              .alias("publish_date")
        ])

    # ==================== 2ë‹¨ê³„: ì œì¡°ì‚¬ ì •ê·œí™” ====================
    
    def normalize_manufacturers(self, maude_lf: pl.LazyFrame, udi_lf: pl.LazyFrame):
        """ì œì¡°ì‚¬ëª… í¼ì§€ ë§¤ì¹­"""
        print("ğŸ”§ ì œì¡°ì‚¬ëª… í¼ì§€ ë§¤ì¹­...")
        
        maude_mfrs = collect_unique_safe(maude_lf, "manufacturer")
        udi_mfrs = collect_unique_safe(udi_lf, "manufacturer")
        
        self.mfr_mapping = fuzzy_match_dict(
            maude_mfrs, udi_mfrs, self.config.FUZZY_THRESHOLD
        )
        
        print(f"   ë§¤ì¹­: {sum(k!=v for k,v in self.mfr_mapping.items())}/{len(maude_mfrs)} ê±´")

    def apply_normalization(self, lf: pl.LazyFrame) -> pl.LazyFrame:
        """ì œì¡°ì‚¬ëª… ì •ê·œí™” ì ìš©"""
        return lf.with_columns(
            pl.col("manufacturer").replace(self.mfr_mapping).alias("mfr_std")
        )

    # ==================== 3ë‹¨ê³„: Lookup ìƒì„± ====================
    
    def build_lookup(self, udi_lf: pl.LazyFrame):
        """Lookup í…Œì´ë¸” ìƒì„±"""
        print("ğŸ”§ Lookup í…Œì´ë¸” ìƒì„±...")
        
        # Primary ì§ì ‘ ë§¤ì¹­ìš© (collect - ì‘ìŒ)
        self.udi_di_lookup = (
            udi_lf
            .select([
                "udi_di", "manufacturer", "brand",
                "model_number", "catalog_number", "publish_date"
            ])
            .unique(subset=["udi_di"])
            .collect()
        )
        
        print(f"   Primary UDI Lookup: {len(self.udi_di_lookup):,} ê±´")
        
        # Full info + Secondary list (LazyFrame - í¼)
        schema = udi_lf.collect_schema()
        sec_cols = [c for c in schema.names()
                   if c.startswith("identifiers_") and c.endswith("_id")]
        
        if sec_cols:
            print(f"   Secondary ì»¬ëŸ¼: {len(sec_cols)}ê°œ")
            self.udi_full_lookup_lf = udi_lf.select([
                "udi_di", "manufacturer", "brand",
                "model_number", "catalog_number", "publish_date",
                pl.concat_list(sec_cols).alias("secondary_list")
            ])
        else:
            print("   âš ï¸  Secondary ì»¬ëŸ¼ ì—†ìŒ")
            self.udi_full_lookup_lf = udi_lf.select([
                "udi_di", "manufacturer", "brand",
                "model_number", "catalog_number", "publish_date",
                pl.lit(None).cast(pl.List(pl.Utf8)).alias("secondary_list")
            ])
        
        print("   Full UDI Lookup: LazyFrame")

    # ==================== 4ë‹¨ê³„: Secondary ë§¤ì¹­ (Path ë°˜í™˜!) ====================
    
    def _match_secondary_with_score(
        self,
        candidates: pl.LazyFrame,
        chunk_size: int
    ) -> Path:
        """
        Secondary UDI ë§¤ì¹­ (Path ë°˜í™˜)
        
        Returns:
            ë§¤ì¹­ ê²°ê³¼ê°€ ì €ì¥ëœ parquet ê²½ë¡œ
        """
        print("      Secondary ë§¤ì¹­ (Path ê¸°ë°˜)...")
        
        output_path = self._new_temp_path(f"secondary_matched_{uuid4().hex}.parquet")
        
        # ë¹ˆ ê²½ìš° ë¹ˆ parquet ìƒì„±
        if candidates.select(pl.len()).collect().item() == 0:
            pl.DataFrame(schema={
                'mfr_std': pl.Utf8,
                'brand': pl.Utf8,
                'model_number': pl.Utf8,
                'catalog_number': pl.Utf8,
                'udi_combined': pl.Utf8,
                'mapped_primary_udi': pl.Utf8,
                'mapped_manufacturer': pl.Utf8,
                'mapped_brand': pl.Utf8,
                'mapped_model_number': pl.Utf8,
                'mapped_catalog_number': pl.Utf8,
                'udi_match_type': pl.Utf8,
                'match_score': pl.Int32
            }).write_parquet(output_path)
            return output_path
        
        # ========== Step 1: Secondary key parquet ==========
        key_path = self._new_temp_path(f"secondary_keys_{uuid4().hex}.parquet")
        candidates.select(
            pl.col("udi_combined").alias("secondary_key")
        ).unique().sink_parquet(key_path)
        
        keys_lf = pl.scan_parquet(key_path)
        
        # ========== Step 2: UDI DB explode + filter ==========
        lookup_path = self._new_temp_path(f"secondary_lookup_{uuid4().hex}.parquet")
        
        def explode_filter(chunk_lf: pl.LazyFrame) -> pl.LazyFrame:
            return (
                chunk_lf
                .select([
                    "udi_di", "manufacturer", "brand",
                    "model_number", "catalog_number",
                    "publish_date", "secondary_list"
                ])
                .explode("secondary_list")
                .join(
                    keys_lf,
                    left_on="secondary_list",
                    right_on="secondary_key",
                    how="inner"
                )
            )
        
        process_lazyframe_in_chunks(
            lf=self.udi_full_lookup_lf,
            transform_func=explode_filter,
            output_path=lookup_path,
            chunk_size=chunk_size,
            desc="Secondary explode"
        )
        
        lookup_lf = pl.scan_parquet(lookup_path)
        
        # ========== Step 3: Score ë§¤ì¹­ (chunk ë‹¨ìœ„) ==========
        def match_chunk(chunk_lf: pl.LazyFrame) -> pl.LazyFrame:
            return self._match_secondary_chunk_with_score(chunk_lf, lookup_lf)
        
        process_lazyframe_in_chunks(
            lf=candidates,
            transform_func=match_chunk,
            output_path=output_path,
            chunk_size=chunk_size,
            desc="Secondary score match"
        )
        
        return output_path  # âœ… Path ë°˜í™˜!

    def _match_secondary_chunk_with_score(
        self,
        candidates_chunk: pl.LazyFrame,
        lookup_lf: pl.LazyFrame
    ) -> pl.LazyFrame:
        """Secondary chunkë³„ score ë§¤ì¹­ - ì¼ê´€ì„± ìˆê²Œ ìˆ˜ì •"""
        remaining = candidates_chunk
        results = []
        
        for min_score in [3, 2, 1]:
            if remaining.select(pl.len()).collect().item() == 0:
                break
            
            matched = (
                remaining
                .join(
                    lookup_lf,
                    left_on=["udi_combined", "mfr_std"],
                    right_on=["secondary_list", "manufacturer"],
                    how="inner"
                )
                .filter(pl.col("publish_date") < pl.col("report_date"))
                .with_columns([
                    (
                        (pl.col("brand") == pl.col("brand_right")).cast(pl.Int32) +
                        (
                            pl.when(
                                pl.col("model_number").is_not_null() &
                                pl.col("model_number_right").is_not_null()
                            )
                            .then(pl.col("model_number") == pl.col("model_number_right"))
                            .otherwise(False)
                        ).cast(pl.Int32) +
                        (
                            pl.when(
                                pl.col("catalog_number").is_not_null() &
                                pl.col("catalog_number_right").is_not_null()
                            )
                            .then(pl.col("catalog_number") == pl.col("catalog_number_right"))
                            .otherwise(False)
                        ).cast(pl.Int32)
                    ).alias("match_score")
                ])
                .filter(pl.col("match_score") >= min_score)
                .group_by([
                    "udi_combined", "mfr_std", "brand",
                    "model_number", "catalog_number"
                ])
                .agg([
                    pl.col("udi_di").n_unique().alias("n_primary"),
                    pl.col("udi_di").first().alias("mapped_primary_udi"),
                    pl.col("brand_right").first().alias("mapped_brand"),
                    pl.col("model_number_right").first().alias("mapped_model_number"),
                    pl.col("catalog_number_right").first().alias("mapped_catalog_number"),
                    pl.col("match_score").max().alias("match_score")
                ])
                .filter(pl.col("n_primary") == 1)
                .select([
                    'mfr_std',
                    'brand',
                    'model_number',
                    'catalog_number',
                    'udi_combined',
                    "mapped_primary_udi",
                    pl.col("mfr_std").alias("mapped_manufacturer"),
                    "mapped_brand",
                    "mapped_model_number",
                    "mapped_catalog_number",
                    pl.lit("udi_secondary").alias("udi_match_type"),
                    "match_score"
                ])
            )
            
            len_matched = matched.select(pl.len()).collect().item()
            if len_matched > 0:
                results.append(matched)
                
                # âœ… udi_combinedìœ¼ë¡œ anti join (ì´ê±´ ê´œì°®ìŒ, null ì•„ë‹˜)
                matched_keys = matched.select("udi_combined")
                remaining = remaining.join(matched_keys, on="udi_combined", how="anti")
        
        return pl.concat(results) if results else pl.LazyFrame()

    # ==================== 5ë‹¨ê³„: No UDI ë§¤ì¹­ (Path ë°˜í™˜!) ====================
    
    def _match_no_udi_with_score(
        self,
        candidates: pl.LazyFrame,
        chunk_size: int
    ) -> Path:
        """
        No UDI ë§¤ì¹­ (Path ë°˜í™˜)
        
        Returns:
            ë§¤ì¹­ ê²°ê³¼ê°€ ì €ì¥ëœ parquet ê²½ë¡œ
        """
        print("      No UDI ë§¤ì¹­ (Path ê¸°ë°˜)...")
        
        output_path = self._new_temp_path(f"no_udi_matched_{uuid4().hex}.parquet")
        
        if candidates.select(pl.len()).collect().item() == 0:
            pl.DataFrame(schema={
                'mfr_std': pl.Utf8,
                'brand': pl.Utf8,
                'model_number': pl.Utf8,
                'catalog_number': pl.Utf8,
                'udi_combined': pl.Utf8,
                'mapped_primary_udi': pl.Utf8,
                'mapped_manufacturer': pl.Utf8,
                'mapped_brand': pl.Utf8,
                'mapped_model_number': pl.Utf8,
                'mapped_catalog_number': pl.Utf8,
                'udi_match_type': pl.Utf8,
                'match_score': pl.Int32
            }).write_parquet(output_path)
            return output_path
        
        # ========== Step 1: ì œì¡°ì‚¬ key parquet ==========
        mfr_key_path = self._new_temp_path(f"no_udi_mfr_keys_{uuid4().hex}.parquet")
        candidates.select(
            pl.col("mfr_std").alias("manufacturer")
        ).unique().sink_parquet(mfr_key_path)
        
        mfr_keys_lf = pl.scan_parquet(mfr_key_path)
        
        # ========== Step 2: UDI DB ì œì¡°ì‚¬ í•„í„°ë§ ==========
        lookup_path = self._new_temp_path(f"no_udi_lookup_{uuid4().hex}.parquet")
        
        def filter_by_mfr(chunk_lf: pl.LazyFrame) -> pl.LazyFrame:
            return (
                chunk_lf
                .select([
                    "udi_di", "manufacturer", "brand",
                    "model_number", "catalog_number", "publish_date"
                ])
                .join(mfr_keys_lf, on="manufacturer", how="inner")
            )
        
        process_lazyframe_in_chunks(
            lf=self.udi_full_lookup_lf,
            transform_func=filter_by_mfr,
            output_path=lookup_path,
            chunk_size=chunk_size,
            desc="No-UDI ì œì¡°ì‚¬ í•„í„°"
        )
        
        lookup_lf = pl.scan_parquet(lookup_path)
        
        # ========== Step 3: Score ë§¤ì¹­ ==========
        def match_chunk(chunk_lf: pl.LazyFrame) -> pl.LazyFrame:
            return self._match_no_udi_chunk_with_score(chunk_lf, lookup_lf)
        
        process_lazyframe_in_chunks(
            lf=candidates,
            transform_func=match_chunk,
            output_path=output_path,
            chunk_size=chunk_size,
            desc="No-UDI score match"
        )
        
        return output_path  # âœ… Path ë°˜í™˜!

    def _match_no_udi_chunk_with_score(
        self,
        candidates_chunk: pl.LazyFrame,
        lookup_lf: pl.LazyFrame
    ) -> pl.LazyFrame:
        """No-UDI chunkë³„ score ë§¤ì¹­ - anti join ìˆ˜ì •"""
        remaining = candidates_chunk
        results = []
        
        for min_score in [3, 2, 1]:
            if remaining.select(pl.len()).collect().item() == 0:
                break
            
            matched = (
                remaining
                .join(
                    lookup_lf,
                    left_on="mfr_std",
                    right_on="manufacturer",
                    how="inner"
                )
                .filter(pl.col("publish_date") < pl.col("report_date"))
                .with_columns([
                    (
                        (pl.col("brand") == pl.col("brand_right")).cast(pl.Int32) +
                        (
                            pl.when(
                                pl.col("model_number").is_not_null() &
                                pl.col("model_number_right").is_not_null()
                            )
                            .then(pl.col("model_number") == pl.col("model_number_right"))
                            .otherwise(False)
                        ).cast(pl.Int32) +
                        (
                            pl.when(
                                pl.col("catalog_number").is_not_null() &
                                pl.col("catalog_number_right").is_not_null()
                            )
                            .then(pl.col("catalog_number") == pl.col("catalog_number_right"))
                            .otherwise(False)
                        ).cast(pl.Int32)
                    ).alias("match_score")
                ])
                .filter(pl.col("match_score") >= min_score)
                .group_by([
                    "udi_combined", "mfr_std", "brand",
                    "model_number", "catalog_number"
                ])
                .agg([
                    pl.col("udi_di").n_unique().alias("n_primary"),
                    pl.col("udi_di").first().alias("mapped_primary_udi"),
                    pl.col("brand_right").first().alias("mapped_brand"),
                    pl.col("model_number_right").first().alias("mapped_model_number"),
                    pl.col("catalog_number_right").first().alias("mapped_catalog_number"),
                    pl.col("match_score").max().alias("match_score")
                ])
                .filter(pl.col("n_primary") == 1)
                .select([
                    'mfr_std',
                    'brand',
                    'model_number',
                    'catalog_number',
                    'udi_combined',
                    "mapped_primary_udi",
                    pl.col("mfr_std").alias("mapped_manufacturer"),
                    "mapped_brand",
                    "mapped_model_number",
                    "mapped_catalog_number",
                    pl.lit("meta_match").alias("udi_match_type"),
                    "match_score"
                ])
            )
            
            len_matched = matched.select(pl.len()).collect().item()
            if len_matched > 0:
                print(f"Score >= {min_score} â†’ {len_matched:,} ê±´ ì„±ê³µ")
                results.append(matched)
                
                # âœ… ìˆ˜ì •: 4ê°œ í‚¤ë¡œ anti join
                matched_keys = matched.select([
                    "mfr_std", "brand", "model_number", "catalog_number"
                ])
                remaining = remaining.join(
                    matched_keys,
                    on=["mfr_std", "brand", "model_number", "catalog_number"],
                    how="anti"
                )
        
        return pl.concat(results) if results else pl.LazyFrame()

    # ==================== 6ë‹¨ê³„: UDI ë§¤í•‘ ìƒì„± (Path ë°˜í™˜!) ====================
    
    def build_udi_mapping(
        self,
        maude_lf: pl.LazyFrame,
        chunk_size: int
    ) -> Path:
        """
        UDI ë§¤í•‘ í…Œì´ë¸” ìƒì„± (Path ë°˜í™˜)
        
        Returns:
            ìµœì¢… ë§¤í•‘ í…Œì´ë¸”ì´ ì €ì¥ëœ parquet ê²½ë¡œ
        """
        print("ğŸ”§ UDI ë§¤í•‘ í…Œì´ë¸” ìƒì„± (Score ê¸°ë°˜)...")
        
        # ========== Unique UDI ì¶”ì¶œ ==========
        unique_udi = maude_lf.select([
            "udi_combined", "mfr_std", "brand",
            "model_number", "catalog_number", "report_date"
        ]).unique(subset=["udi_combined"])
        
        print(f"   Unique UDI: {unique_udi.select(pl.len()).collect().item():,} ê±´")
        
        # ========== Case A: Primary ì§ì ‘ ë§¤ì¹­ ==========
        primary_success = unique_udi.join(
            self.udi_di_lookup.lazy(),
            left_on="udi_combined",
            right_on="udi_di",
            how="inner",  # âœ… ë³€ê²½!
            suffix="_matched"
        ).select([
            'mfr_std',
            'brand',
            'model_number',
            'catalog_number',
            'udi_combined',
            pl.col("udi_combined").alias("mapped_primary_udi"),
            pl.col("manufacturer").alias("mapped_manufacturer"),
            pl.col("brand_matched").alias("mapped_brand"),
            pl.col("model_number_matched").alias("mapped_model_number"),
            pl.col("catalog_number_matched").alias("mapped_catalog_number"),
            pl.lit("udi_direct").alias("udi_match_type"),
            pl.lit(3).alias("match_score")
        ])

        primary_failed = unique_udi.join(
            primary_success.select("udi_combined"),
            on="udi_combined",
            how="anti"
        )

        # Primary â†’ parquet
        primary_path = self._new_temp_path("primary_matched.parquet")
        primary_success.sink_parquet(primary_path)

        len_primary = pl.scan_parquet(primary_path).select(pl.len()).collect().item()
        print(f"   - Primary ì§ì ‘ ë§¤ì¹­: {len_primary:,} ê±´")

        # ========== Case B: Secondary ë§¤ì¹­ ==========
        secondary_candidates = primary_failed.filter(
            pl.col("udi_combined").is_not_null()
        )
        
        len_secondary_candidates = secondary_candidates.select(pl.len()).collect().item()
        print(f"   - Secondary ë§¤ì¹­ ì‹œë„: {len_secondary_candidates:,} ê±´")
        
        if len_secondary_candidates > 0:
            secondary_path = self._match_secondary_with_score(
                secondary_candidates, chunk_size
            )  # âœ… Path ë°›ìŒ!
        else:
            # ë¹ˆ parquet
            secondary_path = self._new_temp_path("secondary_empty.parquet")
            pl.DataFrame(schema={
                'mfr_std': pl.Utf8,
                'brand': pl.Utf8,
                'model_number': pl.Utf8,
                'catalog_number': pl.Utf8,
                'udi_combined': pl.Utf8,
                'mapped_primary_udi': pl.Utf8,
                'mapped_manufacturer': pl.Utf8,
                'mapped_brand': pl.Utf8,
                'mapped_model_number': pl.Utf8,
                'mapped_catalog_number': pl.Utf8,
                'udi_match_type': pl.Utf8,
                'match_score': pl.Int32
            }).write_parquet(secondary_path)
        
        len_secondary = pl.scan_parquet(secondary_path).select(pl.len()).collect().item()
        print(f"   - Secondary ë§¤ì¹­ ì„±ê³µ: {len_secondary:,} ê±´")
        
        # ========== Case C: No UDI ë§¤ì¹­ ==========
        no_udi_candidates = maude_lf.select([
            "udi_combined", "mfr_std", "brand",
            "model_number", "catalog_number", "report_date"
        ]).filter(
            pl.col("udi_combined").is_null()
        ).unique(subset=["mfr_std", "brand", "model_number", "catalog_number"])  # âœ… unique key ì¶”ê°€
        
        len_no_udi_candidates = no_udi_candidates.select(pl.len()).collect().item()
        print(f"   - No UDI ë§¤ì¹­ ì‹œë„: {len_no_udi_candidates:,} ê±´")
        
        if len_no_udi_candidates > 0:
            no_udi_path = self._match_no_udi_with_score(
                no_udi_candidates, chunk_size
            )
        else:
            no_udi_path = self._new_temp_path("no_udi_empty.parquet")
            pl.DataFrame(schema={
                'mfr_std': pl.Utf8,
                'brand': pl.Utf8,
                'model_number': pl.Utf8,
                'catalog_number': pl.Utf8,
                'udi_combined': pl.Utf8,
                'mapped_primary_udi': pl.Utf8,
                'mapped_manufacturer': pl.Utf8,
                'mapped_brand': pl.Utf8,
                'mapped_model_number': pl.Utf8,
                'mapped_catalog_number': pl.Utf8,
                'udi_match_type': pl.Utf8,
                'match_score': pl.Int32
            }).write_parquet(no_udi_path)
        
        len_no_udi = pl.scan_parquet(no_udi_path).select(pl.len()).collect().item()
        print(f"   - No UDI ë§¤ì¹­ ì„±ê³µ: {len_no_udi:,} ê±´")
        
        # ========== ë§¤ì¹­ ì‹¤íŒ¨ ì²˜ë¦¬ ==========
        # Secondary ì‹¤íŒ¨
        if len_secondary > 0:
            secondary_matched_udi = pl.scan_parquet(secondary_path).select(
                "udi_combined"
            ).collect().to_series().to_list()
            
            secondary_failed = secondary_candidates.filter(
                ~pl.col("udi_combined").is_in(secondary_matched_udi)
            )
        else:
            secondary_failed = secondary_candidates
        
        secondary_failed_path = self._new_temp_path("secondary_failed.parquet")
        secondary_failed.select([
            'mfr_std',
            'brand',
            'model_number',
            'catalog_number',
            'udi_combined',
            pl.col("udi_combined").alias("mapped_primary_udi"),
            pl.lit(None).cast(pl.Utf8).alias("mapped_manufacturer"),
            pl.lit(None).cast(pl.Utf8).alias("mapped_brand"),
            pl.lit(None).cast(pl.Utf8).alias("mapped_model_number"),
            pl.lit(None).cast(pl.Utf8).alias("mapped_catalog_number"),
            pl.lit("udi_no_match").alias("udi_match_type"),
            pl.lit(0).alias("match_score")
        ]).sink_parquet(secondary_failed_path)
        
        # ========== No UDI ì‹¤íŒ¨ ì²˜ë¦¬ (ìˆ˜ì •!) ==========
        no_udi_failed_path = self._new_temp_path("no_udi_failed.parquet")
        
        if len_no_udi > 0:
            # no_udi_pathì—ì„œ ë§¤ì¹­ ì„±ê³µí•œ í‚¤ ì¶”ì¶œ
            matched_keys = pl.scan_parquet(no_udi_path).select([
                "mapped_manufacturer",
                "mapped_brand", 
                "mapped_model_number",
                "mapped_catalog_number"
            ]).unique()
            
            # ì‹¤íŒ¨í•œ ê²ƒë§Œ í•„í„°ë§ (ì›ë³¸ í‚¤ë¡œ ë¹„êµ)
            no_udi_candidates.join(
                matched_keys,
                left_on=["mfr_std", "brand", "model_number", "catalog_number"],
                right_on=["mapped_manufacturer", "mapped_brand", "mapped_model_number", "mapped_catalog_number"],
                how="anti"
            ).select([
                'mfr_std',
                'brand',
                'model_number',
                'catalog_number',
                'udi_combined',
                pl.lit(None).cast(pl.Utf8).alias("mapped_primary_udi"),
                pl.lit(None).cast(pl.Utf8).alias("mapped_manufacturer"),
                pl.lit(None).cast(pl.Utf8).alias("mapped_brand"),
                pl.lit(None).cast(pl.Utf8).alias("mapped_model_number"),
                pl.lit(None).cast(pl.Utf8).alias("mapped_catalog_number"),
                pl.lit("no_match").alias("udi_match_type"),
                pl.lit(0).alias("match_score")
            ]).sink_parquet(no_udi_failed_path)
        else:
            # ì „ì²´ê°€ ì‹¤íŒ¨
            no_udi_candidates.select([
                'mfr_std',
                'brand',
                'model_number',
                'catalog_number',
                'udi_combined',
                pl.lit(None).cast(pl.Utf8).alias("mapped_primary_udi"),
                pl.lit(None).cast(pl.Utf8).alias("mapped_manufacturer"),
                pl.lit(None).cast(pl.Utf8).alias("mapped_brand"),
                pl.lit(None).cast(pl.Utf8).alias("mapped_model_number"),
                pl.lit(None).cast(pl.Utf8).alias("mapped_catalog_number"),
                pl.lit("no_match").alias("udi_match_type"),
                pl.lit(0).alias("match_score")
            ]).sink_parquet(no_udi_failed_path)
        
        # ========== í†µí•© ==========
        final_path = self._new_temp_path("udi_mapping_final.parquet")
        
        pl.concat([
            pl.scan_parquet(primary_path),
            pl.scan_parquet(secondary_path),
            pl.scan_parquet(secondary_failed_path),
            pl.scan_parquet(no_udi_path),
            pl.scan_parquet(no_udi_failed_path)
        ]).sink_parquet(final_path)
        
        total = pl.scan_parquet(final_path).select(pl.len()).collect().item()
        print(f"   âœ… ìµœì¢… UDI ë§¤í•‘: {total:,} ê±´")
        
        # í†µê³„
        stats = pl.scan_parquet(final_path).group_by("udi_match_type").agg([
            pl.len().alias("count")
        ]).sort("count", descending=True).collect()
        
        print(stats)
        
        return final_path

    # ==================== 7ë‹¨ê³„: ë§¤ì¹­ ì ìš© ====================
    def process_all(
        self,
        maude_lf: pl.LazyFrame,
        mapping_path: Path,
        output_path: Path,
        chunk_size: int
    ):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ (ë§¤í•‘ ì ìš©) - ìŠ¤í‚¤ë§ˆ í†µì¼ ë²„ì „"""
        print("\nğŸ”§ ë§¤ì¹­ ì ìš© ì¤‘...")
        
        mapping_lf = pl.scan_parquet(mapping_path)
        
        # ë§¤í•‘ í…Œì´ë¸”ì„ UDI ìˆìŒ/ì—†ìŒìœ¼ë¡œ ë¶„ë¦¬
        mapping_with_udi = mapping_lf.filter(pl.col("udi_combined").is_not_null())
        mapping_no_udi = mapping_lf.filter(pl.col("udi_combined").is_null())
        
        def transform_chunk(chunk_lf: pl.LazyFrame) -> pl.LazyFrame:
            # ì›ë³¸ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
            original_cols = chunk_lf.collect_schema().names()
            
            # UDI ìˆëŠ” í–‰ê³¼ ì—†ëŠ” í–‰ ë¶„ë¦¬
            chunk_with_udi = chunk_lf.filter(pl.col("udi_combined").is_not_null())
            chunk_no_udi = chunk_lf.filter(pl.col("udi_combined").is_null())
            
            results = []
            
            # ========== Case 1: UDI ìˆëŠ” ê²½ìš° ==========
            if chunk_with_udi.select(pl.len()).collect().item() > 0:
                matched_with_udi = (
                    chunk_with_udi
                    .join(
                        mapping_with_udi,
                        on="udi_combined",
                        how="left",
                        suffix="_mapping"
                    )
                    .with_columns([
                        pl.coalesce(["mapped_primary_udi", "udi_combined"]).alias("device_version_id"),
                        pl.coalesce(["mapped_manufacturer", "manufacturer"]).alias("manufacturer_final"),
                        pl.coalesce(["mapped_brand", "brand"]).alias("brand_final"),
                        pl.coalesce(["mapped_model_number", "model_number"]).alias("model_number_final"),
                        pl.coalesce(["mapped_catalog_number", "catalog_number"]).alias("catalog_number_final"),
                        pl.coalesce(["udi_match_type", pl.lit("not_in_mapping")]).alias("match_source")
                    ])
                    .select([
                        *original_cols,  # ì›ë³¸ ì»¬ëŸ¼ ìœ ì§€
                        "device_version_id",
                        "manufacturer_final",
                        "brand_final",
                        "model_number_final",
                        "catalog_number_final",
                        "match_source",
                        "match_score"
                    ])
                )
                results.append(matched_with_udi)
            
            # ========== Case 2: UDI ì—†ëŠ” ê²½ìš° ==========
            if chunk_no_udi.select(pl.len()).collect().item() > 0:
                matched_no_udi = (
                    chunk_no_udi
                    .join(
                        mapping_no_udi,
                        on=["mfr_std", "brand", "model_number", "catalog_number"],
                        how="left",
                        suffix="_mapping"
                    )
                    .with_columns([
                        pl.coalesce(["mapped_primary_udi"]).alias("device_version_id"),
                        pl.coalesce(["mapped_manufacturer", "manufacturer"]).alias("manufacturer_final"),
                        pl.coalesce(["mapped_brand", "brand"]).alias("brand_final"),
                        pl.coalesce(["mapped_model_number", "model_number"]).alias("model_number_final"),
                        pl.coalesce(["mapped_catalog_number", "catalog_number"]).alias("catalog_number_final"),
                        pl.coalesce(["udi_match_type", pl.lit("not_in_mapping")]).alias("match_source")
                    ])
                    .select([
                        *original_cols,  # âœ… ê°™ì€ ì›ë³¸ ì»¬ëŸ¼
                        "device_version_id",
                        "manufacturer_final",
                        "brand_final",
                        "model_number_final",
                        "catalog_number_final",
                        "match_source",
                        "match_score"
                    ])
                )
                results.append(matched_no_udi)
            
            # ========== í†µí•© (ìŠ¤í‚¤ë§ˆ ë™ì¼!) ==========
            return pl.concat(results) if results else chunk_lf
        
        process_lazyframe_in_chunks(
            lf=maude_lf,
            transform_func=transform_chunk,
            output_path=output_path,
            chunk_size=chunk_size,
            desc="UDI ë§¤í•‘ ì ìš©"
        )

    # ==================== 8ë‹¨ê³„: í›„ì²˜ë¦¬ ====================
    
    def _post_process_complex_cases(self, input_path: Path, chunk_size: int) -> Path:
        """í›„ì²˜ë¦¬ - Tier 3 ìƒì„± (Path ë°˜í™˜)"""
        print("\nğŸ”§ í›„ì²˜ë¦¬ (Tier 3)...")
        
        lf = pl.scan_parquet(input_path)
        
        compliance = lf.group_by("mfr_std").agg([
            (pl.col("udi_combined").is_null().sum() / pl.len()).alias("missing_rate")
        ]).collect()
        
        low_compliance_mfrs = compliance.filter(
            pl.col("missing_rate") > self.config.LOW_COMPLIANCE_THRESHOLD
        )["mfr_std"].to_list()
        
        def resolve_chunk(chunk_lf: pl.LazyFrame) -> pl.LazyFrame:
            chunk_lf = chunk_lf.with_columns([
                # âœ… ë§¤ì¹­ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ëª¨ë‘ ì²˜ë¦¬
                pl.when(
                    pl.col("match_source").is_in([
                        "no_match", 
                        "not_in_mapping", 
                        # "udi_no_match"
                    ])
                )
                .then(
                    pl.when(pl.col("mfr_std").is_in(low_compliance_mfrs))
                    .then(pl.concat_str([
                        pl.lit("LOW_"), 
                        pl.col("mfr_std"), 
                        pl.lit("_"), 
                        pl.coalesce(["brand_final", pl.lit("UNKNOWN")])
                    ])
                    # .map_elements(uuid5_from_str)
                    )
                    .otherwise(pl.concat_str([
                        pl.lit("UNK_"), 
                        pl.col("mfr_std"), 
                        pl.lit("_"),
                        pl.coalesce(["brand_final", pl.lit("UNKNOWN")]), 
                        pl.lit("_"), 
                        pl.coalesce(["catalog_number_final", pl.lit("NA")])
                    ])
                    # .map_elements(uuid5_from_str)
                    )
                )
                .otherwise(pl.col("device_version_id"))
                .alias("device_version_id"),
                
                # ì‹ ë¢°ë„ ë§¤í•‘
                pl.coalesce([
                    pl.col("match_source").replace(self.config.CONFIDENCE_MAP),
                    pl.lit("VERY_LOW")
                ]).alias("udi_confidence"),
                
                pl.col("match_source").alias("final_source")
            ])
            
            return chunk_lf
        
        output_path = self._new_temp_path("resolved_final.parquet")
        
        process_lazyframe_in_chunks(
            lf=lf,
            transform_func=resolve_chunk,
            output_path=output_path,
            chunk_size=chunk_size,
            desc="Tier 3 ì²˜ë¦¬"
        )
        
        print(f"âœ… ìµœì¢… ê²°ê³¼: {output_path}")
        return output_path  # âœ… Path ë°˜í™˜!

    # ==================== 9ë‹¨ê³„: ì „ì²´ ì‹¤í–‰ ====================
    
    def process(
        self,
        maude_lf: pl.LazyFrame,
        udi_lf: pl.LazyFrame,
        output_path: Path,
        chunk_size: int = 50_000
    ) -> Path:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("=" * 60)
        print("UDI ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘ (Path ê¸°ë°˜)")
        print("=" * 60)
        
        try:
            # 1. ì „ì²˜ë¦¬
            maude_lf = self.preprocess_maude(maude_lf)
            udi_lf = self.preprocess_udi_db(udi_lf)
            
            # 2. ì œì¡°ì‚¬ëª… ì •ê·œí™”
            self.normalize_manufacturers(maude_lf, udi_lf)
            maude_lf = self.apply_normalization(maude_lf)
            
            # 3. Lookup ìƒì„±
            self.build_lookup(udi_lf)
            
            # 4. UDI ë§¤í•‘ ìƒì„± (Path ë°›ìŒ!)
            mapping_path = self.build_udi_mapping(maude_lf, chunk_size)
            
            # 5. ë§¤ì¹­ ì ìš©
            temp_matched_path = self._new_temp_path("maude_matched.parquet")
            self.process_all(maude_lf, mapping_path, temp_matched_path, chunk_size)
            
            # 6. í›„ì²˜ë¦¬ (Path ë°›ìŒ!)
            final_temp_path = self._post_process_complex_cases(temp_matched_path, chunk_size)
            
            # joinìœ¼ë¡œ ëŠ˜ì–´ë‚œ ì¤‘ë³µ ì œê±°
            final_lf = pl.scan_parquet(final_temp_path).unique(subset=['mdr_report_key'],keep='first')
            
            # 7. ìµœì¢… íŒŒì¼ ì´ë™
            final_lf.sink_parquet(output_path)
            
            # í†µê³„
            print("\n" + "=" * 60)
            print("ğŸ“Š ìµœì¢… ê²°ê³¼")
            print("=" * 60)
            
            result_lf = pl.scan_parquet(output_path)
            total = result_lf.select(pl.len()).collect().item()
            
            match_stats = result_lf.group_by("match_source").agg([
                pl.len().alias("count"),
                (pl.len() / total * 100).round(2).alias("percent")
            ]).collect().sort("count", descending=True)
            
            print("\në§¤ì¹­ ì¶œì²˜ ë¶„í¬:")
            print(match_stats)
            
            conf_stats = result_lf.group_by("udi_confidence").agg([
                pl.len().alias("count"),
                (pl.len() / total * 100).round(2).alias("percent")
            ]).collect().sort("count", descending=True)
            
            print("\nì‹ ë¢°ë„ ë¶„í¬:")
            print(conf_stats)
            
            score_stats = result_lf.group_by("match_score").agg([
                pl.len().alias("count"),
                (pl.len() / total * 100).round(2).alias("percent")
            ]).collect().sort("match_score", descending=True)
            
            print("\nScore ë¶„í¬:")
            print(score_stats)
            
            print(f"\nâœ… ì´ {total:,} ê±´ ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"ğŸ“ ê²°ê³¼: {output_path}")
            
            return output_path
        
        finally:
            # âœ… temp ì‚­ì œëŠ” ì—¬ê¸°ì„œë§Œ!
            if self.config.CLEANUP_TEMP_ON_SUCCESS:
                self._cleanup_temps()