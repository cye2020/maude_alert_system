{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "import polars as pl\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ad9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_parquet(\"data/scan_preprocess.parquet\")  # LazyFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d089774",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = df.select(pl.len()).collect().item()\n",
    "total_cols = len(df.collect_schema().names())\n",
    "print(f\"전체 행: {total_rows:,}개, 전체 컬럼: {total_cols}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_cols = [\n",
    "    'report_number',\n",
    "    'date_of_event', \n",
    "    'device_0_manufacturer_d_name',\n",
    "    'device_0_udi_di',\n",
    "    'device_0_lot_number',\n",
    "    'device_0_udi_public'\n",
    "]\n",
    "\n",
    "# Unknown / N/A 패턴 리스트\n",
    "na_patterns = r'^None$|^UNK|NOT APPLICABLE|NOT REPORTED|^N/A$|^NA$|^$|\\s+$|^UNKNOWN$|^NI$|^NULL$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 중복된 행들만 확인\n",
    "# 조합 (6개 컬럼)의 개수\n",
    "df_with_cnt = df.with_columns(\n",
    "    pl.len().over(dedup_cols).alias('duplicate_cnt')\n",
    ")\n",
    "\n",
    "# cnt가 2 이상이 경우에만 \n",
    "# cnt가 1인 경우에는 삭제할 필요가 없으므로\n",
    "df_duplicates_only = df_with_cnt.filter(\n",
    "    pl.col('duplicate_cnt') >= 2\n",
    ")\n",
    "\n",
    "duplicate_cnt = df_duplicates_only.select(pl.len()).collect().item()\n",
    "print(f\"중복된 행의 개수: {duplicate_cnt:,}개\")\n",
    "\n",
    "unique_cnt = df.unique(subset=dedup_cols, maintain_order=True).select(pl.len()).collect().item()\n",
    "print(f\"유일한 행의 개수: {unique_cnt:,}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_duplicates_only.select(\n",
    "    dedup_cols + ['duplicate_cnt']\n",
    ").head(10).collect()\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f3204",
   "metadata": {},
   "source": [
    "# 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_na_values(df, dedup_cols, na_patterns, verbose=True):\n",
    "    \"\"\"\n",
    "    Na / Unknwon 값이 있는 행을 제거하는 함수\n",
    "    \n",
    "    작동방식 :\n",
    "    1. 각 컬럼에 대해 유효한 값인지 체크\n",
    "    2. 모든 조건은 포함한(모두 만족하는) 행으로 필터링\n",
    "    3. 필터 적용\n",
    "\n",
    "    Parameters:\n",
    "    df : polars.DataFrame\n",
    "        원본 DF\n",
    "    dedup_cols : list\n",
    "        -> 모두 유효해야 함\n",
    "    na_patterns : str\n",
    "        NA / Unknown 패턴 정규식\n",
    "    verbose : bool\n",
    "        -> 현재 진행상황 출력해서 확인할 수 있게\n",
    "\n",
    "    Returns: \n",
    "    polars.LazyFrame\n",
    "        비어진 값이나 모르는 값이 없는 DF\n",
    "    \"\"\"\n",
    "\n",
    "    # 진행상확 확인\n",
    "    if verbose:\n",
    "        print(\"na 값 제거\")\n",
    "        print(f\"패턴: {na_patterns}\")\n",
    "\n",
    "    # 제거 되기 전 개수 확인\n",
    "    before_cnt = df.select(pl.len()).collect().item()\n",
    "    if verbose:\n",
    "        print(f\"제거 전 행 개수 : {before_cnt:,}개\")\n",
    "    \n",
    "    # ===\n",
    "    # 각 컬럼별로 필터 조건\n",
    "    # ===\n",
    "    conditions = []\n",
    "\n",
    "    for col in dedup_cols:\n",
    "        # 컬럼이 존재하는지 확인\n",
    "        if col in df.collect_schema().names():\n",
    "            # 유효한 값의 조건\n",
    "            # null / na_patterns 패턴에 매칭되지 않는 값\n",
    "            cond = (\n",
    "                pl.col(col).is_not_null()\n",
    "                &\n",
    "                ~ pl.col(col).cast(pl.Utf8).str.to_uppercase().str.contains(na_patterns)\n",
    "                # ~ 은 not 연산자\n",
    "            )\n",
    "            conditions.append(cond)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"컬럼 '{col}'에 대해 na/unknown 값 제거 조건 추가\")\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"컬럼 '{col}'이(가) 존재하지 않음. 건너뜀\")\n",
    "        \n",
    "# 예외처리\n",
    "    if not conditions:\n",
    "        if verbose:\n",
    "            print(\"제거할 조건이 없음. 원본 DF 반환\")\n",
    "        return df\n",
    "\n",
    "# ===\n",
    "# 모든 조건을 and 조건으로 결합\n",
    "# (모든 조건을 만족해야 함)\n",
    "# ===\n",
    "    final_condition = conditions[0]\n",
    "    for cond in conditions[1:]:\n",
    "        final_condition = final_condition & cond\n",
    "\n",
    "# 필터 적용\n",
    "    df_cleaned = df.filter(final_condition)\n",
    "\n",
    "# 결과\n",
    "    after_cnt = df_cleaned.select(pl.len()).collect().item()\n",
    "    removed_cnt = before_cnt - after_cnt\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"제거 후 행 개수 : {after_cnt:,}개\")\n",
    "        print(f\"제거된 행 개수 : {removed_cnt:,}개\")\n",
    "\n",
    "        return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6efa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_duplicates(df, group_cols, verbose = True):\n",
    "    \"\"\"\n",
    "    중복 데이터 분석 함수들\n",
    "\n",
    "    작동 방식 \n",
    "    1. 전체 개수 확인\n",
    "    2. 고유(unique) 개수 확인\n",
    "    3. 전체 - 고유 = 중복 개수 확인\n",
    "\n",
    "    Parameters:\n",
    "    df : polars.DataFrame -> 원본\n",
    "    dedup_cols : list -> 중복 확인 컬럼\n",
    "    verbose : bool -> 진행상황 출력 여부\n",
    "\n",
    "    returns:\n",
    "\n",
    "    tuple : (전체 개수, 고유 개수, 중복 개수)\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print(f\" 중복 확인\")\n",
    "\n",
    "    # 전체 개수\n",
    "    total_cnt = df.select(pl.len()).collect().item()\n",
    "\n",
    "    # 고유 개수\n",
    "    unique_cnt = df.unique(\n",
    "        subset = group_cols, # 중복 ㅎ판단\n",
    "        maintain_order = True\n",
    "    ).select(pl.len()).collect().item()\n",
    "\n",
    "    # 중복 개수\n",
    "    duplicate_cnt = total_cnt - unique_cnt\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"전체 개수 : {total_cnt:,}개\")\n",
    "        print(f\"고유 개수 : {unique_cnt:,}개\")\n",
    "        print(f\"중복 개수 : {duplicate_cnt:,}개\")\n",
    "        for i, col in enumerate(dedup_cols, start=1):\n",
    "            print(f\"{i}. {col}\")\n",
    "\n",
    "    return total_cnt, unique_cnt, duplicate_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6bdff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df, dedup_cols, keep = 'first', verbose = True):\n",
    "    \"\"\"\n",
    "    중복 데이터 제거 함수\n",
    "\n",
    "    작동 방식\n",
    "    1. dedup_cols 기준으로 중복 판단\n",
    "    2. keep 옵션에 따라 첫번째/마지막 행 유지\n",
    "    3. 중복 제거된 DF 반환\n",
    "\n",
    "    Parameters:\n",
    "    df : polars.DataFrame -> 원본 DF\n",
    "    dedup_cols : list -> 중복 판단 컬럼 리스트\n",
    "    keep : str -> 'first' or 'last'\n",
    "        'first' : 첫번째 행 유지\n",
    "        'last' : 마지막 행 유지\n",
    "    verbose : bool -> 진행상황 출력 여부\n",
    "\n",
    "    Returns:\n",
    "    polars.DataFrame -> 중복 제거된 DF\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"중복 제거 시작\")\n",
    "        print(f\"중복 판단 컬럼: {dedup_cols}\")\n",
    "        print(f\"유지 옵션: {keep}\")\n",
    "\n",
    "    # 중복 제거\n",
    "    df_deduped = df.unique(\n",
    "        subset = dedup_cols,\n",
    "        maintain_order = True,\n",
    "        keep = 'first'\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        before_cnt = df.select(pl.len()).collect().item()\n",
    "        after_cnt = df_deduped.select(pl.len()).collect().item()\n",
    "        removed_cnt = before_cnt - after_cnt\n",
    "\n",
    "        print(f\"제거 전 행 개수 : {before_cnt:,}개\")\n",
    "        print(f\"제거 후 행 개수 : {after_cnt:,}개\")\n",
    "        print(f\"제거된 행 개수 : {removed_cnt:,}개\")\n",
    "\n",
    "    return df_deduped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b345a",
   "metadata": {},
   "source": [
    "## 함수 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655db5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cleaned = remove_na_values(df_duplicates_only, dedup_cols, na_patterns)\n",
    "#df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total, unique, duplicate = analyze_duplicates(df_cleaned, dedup_cols)\n",
    "#pprint((total, unique, duplicate))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d06daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final = remove_duplicates(df_cleaned, dedup_cols, keep='first')\n",
    "#df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ca720",
   "metadata": {},
   "source": [
    "# 중복 잡은 최종 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f483bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전한 파이프라인\n",
    "df_all_cleaned = remove_na_values(df, dedup_cols, na_patterns)\n",
    "total, unique, dup = analyze_duplicates(df_all_cleaned, dedup_cols)\n",
    "df_all_final = remove_duplicates(df_all_cleaned, dedup_cols, keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = df_all_final.select(pl.len()).collect().item()\n",
    "print(f\"행 수: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae63285",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_count = len(df_all_final.columns)\n",
    "print(f\"열 수: {col_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8237bb4e",
   "metadata": {},
   "source": [
    "# device_class3인 것만 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b18ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_class가 3인 컬럼 찾기\n",
    "device_class_cols = [\n",
    "    col for col in df_all_final.columns \n",
    "    if 'device_' in col and 'openfda_device_class' in col\n",
    "]\n",
    "\n",
    "print(f\"찾은 컬럼들: {device_class_cols}\")\n",
    "# ['device_0_openfda_device_class', 'device_1_openfda_device_class', ...]\n",
    "\n",
    "# 하나라도 3이면 필터링\n",
    "condition = pl.lit(False)  # 초기값 False\n",
    "for col in device_class_cols:\n",
    "    condition = condition | (pl.col(col) == \"3\")\n",
    "\n",
    "df_class3 = df_all_final.filter(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82242c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Class 3 기기와 관련된 모든 사건\"\n",
    "# df_class3 = df_all_final.filter(\n",
    "#    (pl.col('device_0_openfda_device_class') == \"3\") |\n",
    "#    (pl.col('device_1_openfda_device_class') == \"3\")\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b686d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = df_class3.select(pl.len()).collect().item()\n",
    "print(f\"행 수: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9121a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_count = len(df_class3.columns)\n",
    "print(f\"열 수: {col_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f30daa",
   "metadata": {},
   "source": [
    "## device_class3인 것 event_type 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NULL 포함 확인\n",
    "event_dist = df_class3.group_by('event_type').agg([\n",
    "    pl.len().alias('count')\n",
    "]).with_columns([\n",
    "    (pl.col('count') / pl.col('count').sum() * 100).round(2).alias('percentage')\n",
    "]).sort('count', descending=True).collect()\n",
    "\n",
    "# NULL 개수 별도 확인\n",
    "null_count = df_class3.filter(\n",
    "    pl.col('event_type').is_null()\n",
    ").select(pl.len()).collect().item()\n",
    "\n",
    "print(event_dist)\n",
    "print(f\"\\nNULL 값: {null_count:,}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c8608",
   "metadata": {},
   "source": [
    "## 이상기기 topN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a077ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_class3.select(pl.len()).collect().item()\n",
    "\n",
    "top_n = 20  # 원하는 개수\n",
    "\n",
    "top_devices = df_class3.group_by('device_0_generic_name').agg([\n",
    "    pl.len().alias('count')\n",
    "]).with_columns([\n",
    "    (pl.col('count') / total * 100).round(2).alias('percentage')\n",
    "]).sort('count', descending=True).head(top_n).collect()\n",
    "\n",
    "print(f\"=== Class 3 기기 사건 수 Top {top_n} (전체: {total:,}건) ===\\n\")\n",
    "\n",
    "for i, row in enumerate(top_devices.iter_rows(named=True), 1):\n",
    "    device = row['device_0_generic_name'] if row['device_0_generic_name'] else \"(NULL)\"\n",
    "    count = row['count']\n",
    "    pct = row['percentage']\n",
    "    print(f\"{i:2d}. {device[:70]:70s} {count:>8,}건 ({pct:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e04d7b",
   "metadata": {},
   "source": [
    "## top3 기기의 event_type 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top3 = df_class3.group_by('device_0_generic_name').len()\\\n",
    "    .sort('len', descending=True).head(3).collect()\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"Top 3 기기별 Event Type 분포\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for rank, row in enumerate(top3.iter_rows(named=True), 1):\n",
    "    device = row['device_0_generic_name']\n",
    "    total = row['len']\n",
    "    \n",
    "    print(f\"\\n[{rank}위] {device}\")\n",
    "    print(f\"총 사건 수: {total:,}건\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    dist = df_class3.filter(\n",
    "        pl.col('device_0_generic_name') == device\n",
    "    ).group_by('event_type').agg([\n",
    "        pl.len().alias('count')\n",
    "    ]).with_columns([\n",
    "        (pl.col('count') / total * 100).round(2).alias('percentage')\n",
    "    ]).sort('count', descending=True).collect()\n",
    "    \n",
    "    print(f\"{'Event Type':<15} {'건수':>10} {'비율':>10}\")\n",
    "    print(\"-\" * 90)\n",
    "    for event_row in dist.iter_rows(named=True):\n",
    "        event = event_row['event_type']\n",
    "        count = event_row['count']\n",
    "        pct = event_row['percentage']\n",
    "        print(f\"{event:<15} {count:>10,} {pct:>9.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca4e62",
   "metadata": {},
   "source": [
    "## 일회용/재활용의 피해확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b42cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 개수\n",
    "total = df_class3.select(pl.len()).collect().item()\n",
    "\n",
    "# 분포 계산\n",
    "reuse_dist = df_class3.group_by('reprocessed_and_reused_flag').agg([\n",
    "    pl.len().alias('count')\n",
    "]).with_columns([\n",
    "    (pl.col('count') / total * 100).round(2).alias('percentage')\n",
    "]).sort('count', descending=True).collect()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Reprocessed and Reused Flag 분포 (전체: {total:,}건)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Flag':<10} {'사건 수':>15} {'비율':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for row in reuse_dist.iter_rows(named=True):\n",
    "    flag = row['reprocessed_and_reused_flag'] if row['reprocessed_and_reused_flag'] else \"(NULL)\"\n",
    "    count = row['count']\n",
    "    pct = row['percentage']\n",
    "    print(f\"{flag:<10} {count:>15,} {pct:>14.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee10532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse Flag × Event Type 크로스탭\n",
    "crosstab = df_class3.group_by(['reprocessed_and_reused_flag', 'event_type']).agg([\n",
    "    pl.len().alias('count')\n",
    "]).sort(['reprocessed_and_reused_flag', 'count'], descending=[False, True]).collect()\n",
    "\n",
    "print(\"=== Reuse Flag × Event Type ===\")\n",
    "print(crosstab)\n",
    "\n",
    "# 또는 각 Flag별로 Event Type 분포\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "for flag in ['Y', 'N', None]:\n",
    "    flag_display = flag if flag else \"(NULL)\"\n",
    "    \n",
    "    flag_total = df_class3.filter(\n",
    "        pl.col('reprocessed_and_reused_flag') == flag if flag else pl.col('reprocessed_and_reused_flag').is_null()\n",
    "    ).select(pl.len()).collect().item()\n",
    "    \n",
    "    if flag_total == 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n[{flag_display}] 총 {flag_total:,}건\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    event_dist = df_class3.filter(\n",
    "        pl.col('reprocessed_and_reused_flag') == flag if flag else pl.col('reprocessed_and_reused_flag').is_null()\n",
    "    ).group_by('event_type').len().sort('len', descending=True).collect()\n",
    "    \n",
    "    print(event_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d07b82",
   "metadata": {},
   "source": [
    "# 함수화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b88ce",
   "metadata": {},
   "source": [
    "event_type 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b407e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_column_distribution(df, column_name, top_n=None, show_null=True, verbose=True):\n",
    "    \"\"\"\n",
    "    특정 컬럼의 값 분포와 비율을 분석하는 함수\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    column_name : str\n",
    "        분석할 컬럼명\n",
    "    top_n : int, optional\n",
    "        상위 N개만 표시 (None이면 전체 표시)\n",
    "    show_null : bool, default=True\n",
    "        NULL 값 개수를 별도로 표시할지 여부\n",
    "    verbose : bool, default=True\n",
    "        결과를 출력할지 여부\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    polars.DataFrame\n",
    "        분포 결과 (컬럼명, count, percentage 포함)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # 기본 사용\n",
    "    >>> result = analyze_column_distribution(df_class3, 'event_type')\n",
    "    \n",
    "    >>> # 상위 10개만\n",
    "    >>> result = analyze_column_distribution(df_class3, 'device_0_generic_name', top_n=10)\n",
    "    \n",
    "    >>> # 출력 없이 결과만\n",
    "    >>> result = analyze_column_distribution(df_class3, 'event_type', verbose=False)\n",
    "    \"\"\"\n",
    "    # 전체 개수\n",
    "    total = df.select(pl.len()).collect().item()\n",
    "    \n",
    "    # 분포 계산\n",
    "    dist = df.group_by(column_name).agg([\n",
    "        pl.len().alias('count')\n",
    "    ]).with_columns([\n",
    "        (pl.col('count') / total * 100).round(2).alias('percentage')\n",
    "    ]).sort('count', descending=True)\n",
    "    \n",
    "    # 상위 N개만\n",
    "    if top_n is not None:\n",
    "        dist = dist.head(top_n)\n",
    "    \n",
    "    result = dist.collect()\n",
    "    \n",
    "    # NULL 개수 확인\n",
    "    null_count = df.filter(pl.col(column_name).is_null()).select(pl.len()).collect().item()\n",
    "    \n",
    "    # 출력\n",
    "    if verbose:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"{column_name} 분포 (전체: {total:,}건)\")\n",
    "        if top_n:\n",
    "            print(f\"(상위 {top_n}개만 표시)\")\n",
    "        print(\"=\" * 80)\n",
    "        print(result)\n",
    "        \n",
    "        if show_null:\n",
    "            print(f\"\\nNULL 값: {null_count:,}개 ({null_count/total*100:.2f}%)\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92920f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_type 분포 확인\n",
    "event_dist = analyze_column_distribution(df_class3, 'event_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31396d29",
   "metadata": {},
   "source": [
    "이상 기기 topn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15635bd",
   "metadata": {},
   "source": [
    "특정 컬럼 기준 상위 n개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_by_column(df, group_column, top_n=10, column_display_name=None, verbose=True):\n",
    "    \"\"\"\n",
    "    특정 컬럼을 기준으로 상위 N개 항목을 추출하고 비율과 함께 출력하는 함수\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    group_column : str\n",
    "        그룹화할 컬럼명 (예: 'device_0_generic_name')\n",
    "    top_n : int, default=10\n",
    "        상위 N개 항목 추출\n",
    "    column_display_name : str, optional\n",
    "        출력 시 표시할 컬럼 이름 (None이면 group_column 사용)\n",
    "    verbose : bool, default=True\n",
    "        결과를 출력할지 여부\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    polars.DataFrame\n",
    "        상위 N개 항목 (컬럼명, count, percentage 포함)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # 기본 사용 - 상위 20개 기기\n",
    "    >>> top_devices = get_top_n_by_column(df_class3, 'device_0_generic_name', top_n=20)\n",
    "    \n",
    "    >>> # 제조사 상위 10개\n",
    "    >>> top_manufacturers = get_top_n_by_column(\n",
    "    ...     df_class3, \n",
    "    ...     'device_0_manufacturer_d_name', \n",
    "    ...     top_n=10,\n",
    "    ...     column_display_name='제조사'\n",
    "    ... )\n",
    "    \n",
    "    >>> # 출력 없이 결과만\n",
    "    >>> result = get_top_n_by_column(df_class3, 'device_0_generic_name', top_n=5, verbose=False)\n",
    "    \"\"\"\n",
    "    # 전체 개수\n",
    "    total = df.select(pl.len()).collect().item()\n",
    "    \n",
    "    # 상위 N개 추출\n",
    "    top_items = df.group_by(group_column).agg([\n",
    "        pl.len().alias('count')\n",
    "    ]).with_columns([\n",
    "        (pl.col('count') / total * 100).round(2).alias('percentage')\n",
    "    ]).sort('count', descending=True).head(top_n).collect()\n",
    "    \n",
    "    # 출력\n",
    "    if verbose:\n",
    "        display_name = column_display_name if column_display_name else group_column\n",
    "        \n",
    "        print(\"=\" * 90)\n",
    "        print(f\"{display_name} 사건 수 Top {top_n} (전체: {total:,}건)\")\n",
    "        print(\"=\" * 90)\n",
    "        print()\n",
    "        \n",
    "        for i, row in enumerate(top_items.iter_rows(named=True), 1):\n",
    "            value = row[group_column] if row[group_column] else \"(NULL)\"\n",
    "            count = row['count']\n",
    "            pct = row['percentage']\n",
    "            \n",
    "            # 긴 값은 70자로 자르기\n",
    "            display_value = value[:70] if len(value) > 70 else value\n",
    "            \n",
    "            print(f\"{i:2d}. {display_value:70s} {count:>8,}건 ({pct:>5.1f}%)\")\n",
    "    \n",
    "    return top_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed970bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_devices = get_top_n_by_column(\n",
    "    df_class3, \n",
    "    'device_0_generic_name', \n",
    "    top_n=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6109d58",
   "metadata": {},
   "source": [
    "topn 기기 event_type 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_top_n_by_category(df, group_column, category_column, top_n=3, \n",
    "                               group_display_name=None, category_display_name=None, \n",
    "                               verbose=True):\n",
    "    \"\"\"\n",
    "    상위 N개 항목에 대해 카테고리별 분포를 분석하는 함수\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    group_column : str\n",
    "        그룹화할 주요 컬럼 (예: 'device_0_generic_name')\n",
    "    category_column : str\n",
    "        분포를 확인할 카테고리 컬럼 (예: 'event_type')\n",
    "    top_n : int, default=3\n",
    "        상위 N개 항목 분석\n",
    "    group_display_name : str, optional\n",
    "        그룹 컬럼의 표시 이름 (None이면 group_column 사용)\n",
    "    category_display_name : str, optional\n",
    "        카테고리 컬럼의 표시 이름 (None이면 category_column 사용)\n",
    "    verbose : bool, default=True\n",
    "        결과를 출력할지 여부\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        각 상위 항목별 카테고리 분포 딕셔너리\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Top 3 기기별 Event Type 분포\n",
    "    >>> result = analyze_top_n_by_category(\n",
    "    ...     df_class3, \n",
    "    ...     'device_0_generic_name', \n",
    "    ...     'event_type',\n",
    "    ...     top_n=3\n",
    "    ... )\n",
    "    \n",
    "    >>> # Top 5 제조사별 Event Type 분포\n",
    "    >>> result = analyze_top_n_by_category(\n",
    "    ...     df_class3,\n",
    "    ...     'device_0_manufacturer_d_name',\n",
    "    ...     'event_type',\n",
    "    ...     top_n=5,\n",
    "    ...     group_display_name='제조사',\n",
    "    ...     category_display_name='사건 유형'\n",
    "    ... )\n",
    "    \n",
    "    >>> # Top 10 기기별 재처리 여부 분포\n",
    "    >>> result = analyze_top_n_by_category(\n",
    "    ...     df_class3,\n",
    "    ...     'device_0_generic_name',\n",
    "    ...     'reprocessed_and_reused_flag',\n",
    "    ...     top_n=10,\n",
    "    ...     category_display_name='재처리 여부'\n",
    "    ... )\n",
    "    \"\"\"\n",
    "    # 상위 N개 항목 추출\n",
    "    top_items = df.group_by(group_column).len()\\\n",
    "        .sort('len', descending=True).head(top_n).collect()\n",
    "    \n",
    "    # 결과 저장용 딕셔너리\n",
    "    results = {}\n",
    "    \n",
    "    # 표시 이름 설정\n",
    "    group_name = group_display_name if group_display_name else group_column\n",
    "    category_name = category_display_name if category_display_name else category_column\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\" * 90)\n",
    "        print(f\"Top {top_n} {group_name}별 {category_name} 분포\")\n",
    "        print(\"=\" * 90)\n",
    "    \n",
    "    # 각 항목에 대해 카테고리 분포 계산\n",
    "    for rank, row in enumerate(top_items.iter_rows(named=True), 1):\n",
    "        item_value = row[group_column]\n",
    "        total_count = row['len']\n",
    "        \n",
    "        # 해당 항목의 카테고리 분포\n",
    "        dist = df.filter(\n",
    "            pl.col(group_column) == item_value\n",
    "        ).group_by(category_column).agg([\n",
    "            pl.len().alias('count')\n",
    "        ]).with_columns([\n",
    "            (pl.col('count') / total_count * 100).round(2).alias('percentage')\n",
    "        ]).sort('count', descending=True).collect()\n",
    "        \n",
    "        # 결과 저장\n",
    "        results[item_value] = dist\n",
    "        \n",
    "        # 출력\n",
    "        if verbose:\n",
    "            print(f\"\\n[{rank}위] {item_value}\")\n",
    "            print(f\"총 사건 수: {total_count:,}건\")\n",
    "            print(\"-\" * 90)\n",
    "            print(f\"{category_name:<20} {'건수':>15} {'비율':>15}\")\n",
    "            print(\"-\" * 90)\n",
    "            \n",
    "            for cat_row in dist.iter_rows(named=True):\n",
    "                category = cat_row[category_column] if cat_row[category_column] else \"(NULL)\"\n",
    "                count = cat_row['count']\n",
    "                pct = cat_row['percentage']\n",
    "                print(f\"{category:<20} {count:>15,} {pct:>14.1f}%\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\" * 90)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff74869",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = analyze_top_n_by_category(\n",
    "    df_class3,\n",
    "    'device_0_generic_name',\n",
    "    'event_type',\n",
    "    top_n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e55448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 제조사의 Event Type 분포\n",
    "result = analyze_top_n_by_category(\n",
    "    df_class3,\n",
    "    'device_0_manufacturer_d_name',\n",
    "    'event_type',\n",
    "    top_n=5,\n",
    "    group_display_name='제조사',\n",
    "    category_display_name='사건 유형'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 기기의 재처리 여부 분포\n",
    "result = analyze_top_n_by_category(\n",
    "    df_class3,\n",
    "    'device_0_generic_name',\n",
    "    'reprocessed_and_reused_flag',\n",
    "    top_n=10,\n",
    "    group_display_name='기기',\n",
    "    category_display_name='재처리 여부'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c927742b",
   "metadata": {},
   "source": [
    "일회용/재사용 기기의 피해 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638809c",
   "metadata": {},
   "source": [
    "단일 컬럼 분포 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da8ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_single_column_pretty(df, column_name, column_display_name=None):\n",
    "    \"\"\"\n",
    "    단일 컬럼의 분포를 예쁘게 출력하는 함수\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    column_name : str\n",
    "        분석할 컬럼명\n",
    "    column_display_name : str, optional\n",
    "        출력 시 표시할 컬럼 이름 (None이면 column_name 사용)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    polars.DataFrame\n",
    "        분포 결과 (컬럼값, count, percentage 포함)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Reprocessed Flag 분포\n",
    "    >>> analyze_single_column_pretty(df_class3, 'reprocessed_and_reused_flag')\n",
    "    \n",
    "    >>> # Event Type 분포\n",
    "    >>> analyze_single_column_pretty(\n",
    "    ...     df_class3, \n",
    "    ...     'event_type',\n",
    "    ...     column_display_name='사건 유형'\n",
    "    ... )\n",
    "    \"\"\"\n",
    "    # 전체 개수\n",
    "    total = df.select(pl.len()).collect().item()\n",
    "    \n",
    "    # 분포 계산\n",
    "    dist = df.group_by(column_name).agg([\n",
    "        pl.len().alias('count')\n",
    "    ]).with_columns([\n",
    "        (pl.col('count') / total * 100).round(2).alias('percentage')\n",
    "    ]).sort('count', descending=True).collect()\n",
    "    \n",
    "    # 표시 이름\n",
    "    display_name = column_display_name if column_display_name else column_name\n",
    "    \n",
    "    # 출력\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{display_name} 분포 (전체: {total:,}건)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'값':<20} {'사건 수':>15} {'비율':>15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for row in dist.iter_rows(named=True):\n",
    "        value = row[column_name] if row[column_name] else \"(NULL)\"\n",
    "        count = row['count']\n",
    "        pct = row['percentage']\n",
    "        \n",
    "        # 긴 값은 자르기\n",
    "        display_value = value[:18] if len(str(value)) > 18 else value\n",
    "        print(f\"{display_value:<20} {count:>15,} {pct:>14.2f}%\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46804986",
   "metadata": {},
   "source": [
    "두 컬럼 크로스탭 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363702eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_crosstab(df, column1, column2, \n",
    "                     column1_display_name=None, \n",
    "                     column2_display_name=None,\n",
    "                     show_detail=True):\n",
    "    \"\"\"\n",
    "    두 컬럼의 크로스탭(교차 분석)을 수행하는 함수\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    column1 : str\n",
    "        첫 번째 컬럼 (예: 'reprocessed_and_reused_flag')\n",
    "    column2 : str\n",
    "        두 번째 컬럼 (예: 'event_type')\n",
    "    column1_display_name : str, optional\n",
    "        첫 번째 컬럼의 표시 이름\n",
    "    column2_display_name : str, optional\n",
    "        두 번째 컬럼의 표시 이름\n",
    "    show_detail : bool, default=True\n",
    "        각 column1 값별로 상세 분포를 출력할지 여부\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    polars.DataFrame\n",
    "        크로스탭 결과\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Reuse Flag × Event Type\n",
    "    >>> analyze_crosstab(\n",
    "    ...     df_class3, \n",
    "    ...     'reprocessed_and_reused_flag', \n",
    "    ...     'event_type'\n",
    "    ... )\n",
    "    \n",
    "    >>> # 제조사 × Event Type\n",
    "    >>> analyze_crosstab(\n",
    "    ...     df_class3,\n",
    "    ...     'device_0_manufacturer_d_name',\n",
    "    ...     'event_type',\n",
    "    ...     column1_display_name='제조사',\n",
    "    ...     column2_display_name='사건 유형'\n",
    "    ... )\n",
    "    \n",
    "    >>> # 크로스탭만 보기 (상세 분포 제외)\n",
    "    >>> analyze_crosstab(\n",
    "    ...     df_class3,\n",
    "    ...     'reprocessed_and_reused_flag',\n",
    "    ...     'event_type',\n",
    "    ...     show_detail=False\n",
    "    ... )\n",
    "    \"\"\"\n",
    "    # 표시 이름 설정\n",
    "    col1_name = column1_display_name if column1_display_name else column1\n",
    "    col2_name = column2_display_name if column2_display_name else column2\n",
    "    \n",
    "    # 크로스탭 생성\n",
    "    crosstab = df.group_by([column1, column2]).agg([\n",
    "        pl.len().alias('count')\n",
    "    ]).sort([column1, 'count'], descending=[False, True]).collect()\n",
    "    \n",
    "    print(\"=\" * 90)\n",
    "    print(f\"{col1_name} × {col2_name} 크로스탭\")\n",
    "    print(\"=\" * 90)\n",
    "    print(crosstab)\n",
    "    \n",
    "    # 상세 분포 출력\n",
    "    if show_detail:\n",
    "        print(\"\\n\" + \"=\" * 90)\n",
    "        print(f\"{col1_name}별 {col2_name} 상세 분포\")\n",
    "        print(\"=\" * 90)\n",
    "        \n",
    "        # column1의 고유값 추출 (NULL 포함)\n",
    "        unique_values = df.select(column1).unique().collect()[column1].to_list()\n",
    "        \n",
    "        # NULL도 포함\n",
    "        if None not in unique_values and df.filter(pl.col(column1).is_null()).select(pl.len()).collect().item() > 0:\n",
    "            unique_values.append(None)\n",
    "        \n",
    "        for value in unique_values:\n",
    "            value_display = value if value else \"(NULL)\"\n",
    "            \n",
    "            # 해당 값의 총 개수\n",
    "            value_total = df.filter(\n",
    "                pl.col(column1) == value if value else pl.col(column1).is_null()\n",
    "            ).select(pl.len()).collect().item()\n",
    "            \n",
    "            if value_total == 0:\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n[{value_display}] 총 {value_total:,}건\")\n",
    "            print(\"-\" * 90)\n",
    "            \n",
    "            # 해당 값의 column2 분포\n",
    "            dist = df.filter(\n",
    "                pl.col(column1) == value if value else pl.col(column1).is_null()\n",
    "            ).group_by(column2).agg([\n",
    "                pl.len().alias('count')\n",
    "            ]).with_columns([\n",
    "                (pl.col('count') / value_total * 100).round(2).alias('percentage')\n",
    "            ]).sort('count', descending=True).collect()\n",
    "            \n",
    "            print(f\"{col2_name:<25} {'건수':>15} {'비율':>15}\")\n",
    "            print(\"-\" * 90)\n",
    "            \n",
    "            for row in dist.iter_rows(named=True):\n",
    "                cat = row[column2] if row[column2] else \"(NULL)\"\n",
    "                count = row['count']\n",
    "                pct = row['percentage']\n",
    "                \n",
    "                cat_display = cat[:23] if len(str(cat)) > 23 else cat\n",
    "                print(f\"{cat_display:<25} {count:>15,} {pct:>14.2f}%\")\n",
    "        \n",
    "        print(\"=\" * 90)\n",
    "    \n",
    "    return crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c17a50",
   "metadata": {},
   "source": [
    "일회용/재사용의 사건 분포 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed3df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_dist = analyze_single_column_pretty(\n",
    "    df_class3, \n",
    "    'reprocessed_and_reused_flag',\n",
    "    column_display_name='재처리/재사용 여부'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7f2607",
   "metadata": {},
   "source": [
    "reuse flag X event_type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_result = analyze_crosstab(\n",
    "    df_class3,\n",
    "    'reprocessed_and_reused_flag',\n",
    "    'event_type',\n",
    "    column1_display_name='재처리 여부',\n",
    "    column2_display_name='사건 유형'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c90857",
   "metadata": {},
   "source": [
    "## 치명률 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4100dc8",
   "metadata": {},
   "source": [
    "함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cfr_by_device(df, device_column='device_0_generic_name', \n",
    "                            event_column='event_type',\n",
    "                            top_n=None, min_cases=10):\n",
    "    \"\"\"\n",
    "    기기별 치명률(Case Fatality Rate)을 계산하는 함수\n",
    "    \n",
    "    치명률(CFR) = (사망 건수 / 해당 기기 총 보고 건수) × 100\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    device_column : str, default='device_0_generic_name'\n",
    "        기기 컬럼명\n",
    "    event_column : str, default='event_type'\n",
    "        사건 유형 컬럼명\n",
    "    top_n : int, optional\n",
    "        상위 N개 기기만 분석 (None이면 전체)\n",
    "    min_cases : int, default=10\n",
    "        최소 보고 건수 (이보다 적은 기기는 제외, 통계적 신뢰도 확보)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    polars.DataFrame\n",
    "        기기별 치명률 결과 (기기명, 총건수, 사망건수, 부상건수, 오작동건수, CFR)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # 전체 기기 CFR\n",
    "    >>> cfr_result = calculate_cfr_by_device(df_class3)\n",
    "    \n",
    "    >>> # 상위 20개 기기만\n",
    "    >>> cfr_top20 = calculate_cfr_by_device(df_class3, top_n=20)\n",
    "    \n",
    "    >>> # 최소 100건 이상 보고된 기기만\n",
    "    >>> cfr_reliable = calculate_cfr_by_device(df_class3, min_cases=100)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 기기별 전체 건수와 사건 유형별 건수\n",
    "    device_stats = df.group_by(device_column).agg([\n",
    "        pl.len().alias('total_cases'),\n",
    "        (pl.col(event_column) == 'Death').sum().alias('death_count'),\n",
    "        (pl.col(event_column) == 'Injury').sum().alias('injury_count'),\n",
    "        (pl.col(event_column) == 'Malfunction').sum().alias('malfunction_count')\n",
    "    ]).filter(\n",
    "        pl.col('total_cases') >= min_cases  # 최소 건수 필터\n",
    "    ).with_columns([\n",
    "        # CFR 계산\n",
    "        (pl.col('death_count') / pl.col('total_cases') * 100).round(2).alias('cfr'),\n",
    "        # 부상률\n",
    "        (pl.col('injury_count') / pl.col('total_cases') * 100).round(2).alias('injury_rate'),\n",
    "        # 오작동률\n",
    "        (pl.col('malfunction_count') / pl.col('total_cases') * 100).round(2).alias('malfunction_rate')\n",
    "    ]).sort('cfr', descending=True)\n",
    "    \n",
    "    # Top N만\n",
    "    if top_n:\n",
    "        device_stats = device_stats.head(top_n)\n",
    "    \n",
    "    result = device_stats.collect()\n",
    "    \n",
    "    # 출력\n",
    "    print(\"=\" * 120)\n",
    "    print(f\"기기별 치명률(CFR) 분석 (최소 {min_cases}건 이상)\")\n",
    "    print(\"=\" * 120)\n",
    "    print(f\"{'순위':>4} {'기기명':<50} {'총건수':>10} {'사망':>8} {'부상':>8} {'오작동':>10} {'CFR(%)':>10}\")\n",
    "    print(\"-\" * 120)\n",
    "    \n",
    "    for i, row in enumerate(result.iter_rows(named=True), 1):\n",
    "        device = row[device_column] if row[device_column] else \"(NULL)\"\n",
    "        total = row['total_cases']\n",
    "        death = row['death_count']\n",
    "        injury = row['injury_count']\n",
    "        mal = row['malfunction_count']\n",
    "        cfr = row['cfr']\n",
    "        \n",
    "        device_short = device[:48] if len(device) > 48 else device\n",
    "        \n",
    "        print(f\"{i:4d} {device_short:<50} {total:>10,} {death:>8,} {injury:>8,} {mal:>10,} {cfr:>10.2f}%\")\n",
    "    \n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    # 요약 통계\n",
    "    print(f\"\\n◼️ 요약 통계:\")\n",
    "    print(f\"  - 분석 기기 수: {len(result):,}개\")\n",
    "    print(f\"  - 평균 CFR: {result['cfr'].mean():.2f}%\")\n",
    "    print(f\"  - 최대 CFR: {result['cfr'].max():.2f}%\")\n",
    "    print(f\"  - 최소 CFR: {result['cfr'].min():.2f}%\")\n",
    "    print(f\"  - CFR 중앙값: {result['cfr'].median():.2f}%\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8049ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최소 10건 이상 보고된 기기의 CFR\n",
    "cfr_all = calculate_cfr_by_device(df_class3, top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d3be3",
   "metadata": {},
   "source": [
    "제조사별 CFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91551856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제조사별 치명률\n",
    "cfr_by_manufacturer = calculate_cfr_by_device(\n",
    "    df_class3, \n",
    "    device_column='device_0_manufacturer_d_name',\n",
    "    min_cases=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae631265",
   "metadata": {},
   "source": [
    "## CFR 구간별 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cfr_distribution(df, device_column='device_0_generic_name', min_cases=10):\n",
    "    \"\"\"\n",
    "    CFR 구간별 기기 분포를 분석하는 함수\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    device_column : str\n",
    "        기기 컬럼명\n",
    "    min_cases : int\n",
    "        최소 보고 건수\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> analyze_cfr_distribution(df_class3)\n",
    "    \"\"\"\n",
    "    # CFR 계산\n",
    "    cfr_data = df.group_by(device_column).agg([\n",
    "        pl.len().alias('total_cases'),\n",
    "        (pl.col('event_type') == 'Death').sum().alias('death_count')\n",
    "    ]).filter(\n",
    "        pl.col('total_cases') >= min_cases\n",
    "    ).with_columns([\n",
    "        (pl.col('death_count') / pl.col('total_cases') * 100).alias('cfr')\n",
    "    ]).collect()\n",
    "    \n",
    "    # CFR 구간별 분류\n",
    "    cfr_ranges = [\n",
    "        (0, 1, \"매우 낮음 (0-1%)\"),\n",
    "        (1, 3, \"낮음 (1-3%)\"),\n",
    "        (3, 5, \"보통 (3-5%)\"),\n",
    "        (5, 10, \"높음 (5-10%)\"),\n",
    "        (10, 100, \"매우 높음 (10%+)\")\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"CFR 구간별 기기 분포\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'CFR 구간':<25} {'기기 수':>15} {'비율':>15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    total_devices = len(cfr_data)\n",
    "    \n",
    "    for min_cfr, max_cfr, label in cfr_ranges:\n",
    "        count = cfr_data.filter(\n",
    "            (pl.col('cfr') >= min_cfr) & (pl.col('cfr') < max_cfr)\n",
    "        ).shape[0]\n",
    "        \n",
    "        pct = (count / total_devices * 100) if total_devices > 0 else 0\n",
    "        print(f\"{label:<25} {count:>15,} {pct:>14.1f}%\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'총 기기 수':<25} {total_devices:>15,} {100.0:>14.1f}%\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced93217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFR 구간별 기기 분포\n",
    "analyze_cfr_distribution(df_class3, min_cases=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff86026",
   "metadata": {},
   "source": [
    "특정 기기의 상세 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_device_detail(df, device_name, device_column='device_0_generic_name'):\n",
    "    \"\"\"\n",
    "    특정 기기의 상세 통계 분석\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    device_name : str\n",
    "        분석할 기기명\n",
    "    device_column : str\n",
    "        기기 컬럼명\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> analyze_device_detail(df_class3, 'Catheter, Intravascular, Therapeutic')\n",
    "    \"\"\"\n",
    "    device_data = df.filter(pl.col(device_column) == device_name).collect()\n",
    "    \n",
    "    total = len(device_data)\n",
    "    death = device_data.filter(pl.col('event_type') == 'Death').shape[0]\n",
    "    injury = device_data.filter(pl.col('event_type') == 'Injury').shape[0]\n",
    "    mal = device_data.filter(pl.col('event_type') == 'Malfunction').shape[0]\n",
    "    \n",
    "    cfr = (death / total * 100) if total > 0 else 0\n",
    "    injury_rate = (injury / total * 100) if total > 0 else 0\n",
    "    mal_rate = (mal / total * 100) if total > 0 else 0\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"기기 상세 분석: {device_name}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\n◼️ 기초 통계:\")\n",
    "    print(f\"  총 보고 건수: {total:,}건\")\n",
    "    print(f\"\\n◼️ 사건 유형별 분포:\")\n",
    "    print(f\"  • 사망 (Death):        {death:>8,}건 ({cfr:>5.2f}%) ⚠️ CFR\")\n",
    "    print(f\"  • 부상 (Injury):       {injury:>8,}건 ({injury_rate:>5.2f}%)\")\n",
    "    print(f\"  • 오작동 (Malfunction): {mal:>8,}건 ({mal_rate:>5.2f}%)\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617dc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 기기 상세 분석\n",
    "analyze_device_detail(df_class3, 'Ventricular (assist) bypass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db7f5a",
   "metadata": {},
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94e029",
   "metadata": {},
   "source": [
    "* 환자 피해 patient_harm\n",
    "* 문제 기기 problem_components\n",
    "* 당시 상황 incident_summary\n",
    "* 결함 여부 defect_confirmed\n",
    "* 결함 종류 defect_type\n",
    "* 기기 실험 요약 inspection_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e8aca",
   "metadata": {},
   "source": [
    "### 기기 결함 종류 분포 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_defect_types(df, top_n=20, min_cases=5):\n",
    "    \"\"\"\n",
    "    기기 결함 종류 분포를 분석하는 함수\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    top_n : int, default=20\n",
    "        상위 N개 결함 종류 표시\n",
    "    min_cases : int, default=5\n",
    "        최소 발생 건수 (이보다 적은 결함은 제외)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    polars.DataFrame\n",
    "        결함 종류별 분포 결과\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # 전체 결함 종류 분포\n",
    "    >>> defect_dist = analyze_defect_types(df_class3)\n",
    "    \n",
    "    >>> # 상위 30개만\n",
    "    >>> defect_top30 = analyze_defect_types(df_class3, top_n=30)\n",
    "    \"\"\"\n",
    "    # 전체 개수\n",
    "    total = df.select(pl.len()).collect().item()\n",
    "    \n",
    "    # 결함 종류 분포\n",
    "    defect_dist = df.group_by('defect_type').agg([\n",
    "        pl.len().alias('count')\n",
    "    ]).filter(\n",
    "        pl.col('count') >= min_cases\n",
    "    ).with_columns([\n",
    "        (pl.col('count') / total * 100).round(2).alias('percentage')\n",
    "    ]).sort('count', descending=True).head(top_n).collect()\n",
    "    \n",
    "    # 결함 확인 여부\n",
    "    defect_confirmed = df.group_by('defect_confirmed').len().collect()\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(f\"기기 결함 종류 분석 (전체: {total:,}건)\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # 결함 확인 여부 먼저 출력\n",
    "    print(\"\\n◼️ 결함 확인 여부:\")\n",
    "    print(\"-\" * 100)\n",
    "    for row in defect_confirmed.iter_rows(named=True):\n",
    "        confirmed = row['defect_confirmed']\n",
    "        count = row['len']\n",
    "        pct = (count / total * 100)\n",
    "        confirmed_display = confirmed if confirmed else \"(NULL)\"\n",
    "        print(f\"  {confirmed_display:<20} {count:>10,}건 ({pct:>5.2f}%)\")\n",
    "    \n",
    "    # 결함 종류 분포\n",
    "    print(f\"\\n◼️ 결함 종류 Top {top_n} (최소 {min_cases}건 이상):\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'순위':>4} {'결함 종류':<60} {'건수':>12} {'비율':>12}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for i, row in enumerate(defect_dist.iter_rows(named=True), 1):\n",
    "        defect_type = row['defect_type']\n",
    "        count = row['count']\n",
    "        pct = row['percentage']\n",
    "        \n",
    "        defect_display = defect_type[:58] if defect_type and len(defect_type) > 58 else (defect_type or \"(NULL)\")\n",
    "        print(f\"{i:4d} {defect_display:<60} {count:>12,} {pct:>11.2f}%\")\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    return defect_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf17ae",
   "metadata": {},
   "source": [
    "### 결함 종류별 환자 피해/사건 유형 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccdab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_defect_impact(df, top_defects=10):\n",
    "    \"\"\"\n",
    "    주요 결함 종류별 환자 피해 및 사건 유형 분석\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    top_defects : int, default=10\n",
    "        분석할 상위 결함 종류 개수\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        결함 종류별 분석 결과\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # 상위 10개 결함의 영향 분석\n",
    "    >>> impact_result = analyze_defect_impact(df_class3, top_defects=10)\n",
    "    \n",
    "    >>> # 상위 5개만\n",
    "    >>> impact_top5 = analyze_defect_impact(df_class3, top_defects=5)\n",
    "    \"\"\"\n",
    "    # 상위 결함 종류 추출\n",
    "    top_defects_list = df.group_by('defect_type').len()\\\n",
    "        .sort('len', descending=True).head(top_defects).collect()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"=\" * 110)\n",
    "    print(f\"상위 {top_defects}개 결함 종류별 영향 분석\")\n",
    "    print(\"=\" * 110)\n",
    "    \n",
    "    for rank, row in enumerate(top_defects_list.iter_rows(named=True), 1):\n",
    "        defect_type = row['defect_type']\n",
    "        total_count = row['len']\n",
    "        \n",
    "        if not defect_type:\n",
    "            defect_type = \"(NULL)\"\n",
    "        \n",
    "        # 해당 결함의 데이터 필터링\n",
    "        defect_data = df.filter(\n",
    "            pl.col('defect_type') == defect_type if defect_type != \"(NULL)\" \n",
    "            else pl.col('defect_type').is_null()\n",
    "        )\n",
    "        \n",
    "        # Event Type 분포\n",
    "        event_dist = defect_data.group_by('event_type').agg([\n",
    "            pl.len().alias('count')\n",
    "        ]).with_columns([\n",
    "            (pl.col('count') / total_count * 100).round(2).alias('percentage')\n",
    "        ]).sort('count', descending=True).collect()\n",
    "        \n",
    "        # 환자 피해 여부 (NULL이 아닌 경우)\n",
    "        harm_count = defect_data.filter(\n",
    "            pl.col('patient_harm').is_not_null()\n",
    "        ).select(pl.len()).collect().item()\n",
    "        \n",
    "        # CFR 계산\n",
    "        death_count = defect_data.filter(pl.col('event_type') == 'Death').select(pl.len()).collect().item()\n",
    "        cfr = (death_count / total_count * 100) if total_count > 0 else 0\n",
    "        \n",
    "        results[defect_type] = {\n",
    "            'total': total_count,\n",
    "            'event_dist': event_dist,\n",
    "            'harm_count': harm_count,\n",
    "            'cfr': cfr\n",
    "        }\n",
    "        \n",
    "        # 출력\n",
    "        print(f\"\\n[{rank}위] {defect_type}\")\n",
    "        print(f\"총 {total_count:,}건 | 환자 피해 기록: {harm_count:,}건 | CFR: {cfr:.2f}%\")\n",
    "        print(\"-\" * 110)\n",
    "        print(f\"{'사건 유형':<20} {'건수':>15} {'비율':>15}\")\n",
    "        print(\"-\" * 110)\n",
    "        \n",
    "        for event_row in event_dist.iter_rows(named=True):\n",
    "            event = event_row['event_type'] if event_row['event_type'] else \"(NULL)\"\n",
    "            count = event_row['count']\n",
    "            pct = event_row['percentage']\n",
    "            print(f\"{event:<20} {count:>15,} {pct:>14.2f}%\")\n",
    "    \n",
    "    print(\"=\" * 110)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8600c4",
   "metadata": {},
   "source": [
    "### 결함 종류별 문제 기기 부품 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_defect_components(df, defect_type, top_n=10):\n",
    "    \"\"\"\n",
    "    특정 결함 종류의 문제 기기 부품 분석\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    defect_type : str\n",
    "        분석할 결함 종류\n",
    "    top_n : int, default=10\n",
    "        상위 N개 문제 부품 표시\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    polars.DataFrame\n",
    "        문제 부품 분포\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # 특정 결함의 문제 부품\n",
    "    >>> analyze_defect_components(df_class3, 'Software Failure', top_n=15)\n",
    "    \"\"\"\n",
    "    # 해당 결함 필터링\n",
    "    defect_data = df.filter(\n",
    "        pl.col('defect_type') == defect_type\n",
    "    )\n",
    "    \n",
    "    total = defect_data.select(pl.len()).collect().item()\n",
    "    \n",
    "    # 문제 부품 분포\n",
    "    component_dist = defect_data.group_by('problem_components').agg([\n",
    "        pl.len().alias('count')\n",
    "    ]).with_columns([\n",
    "        (pl.col('count') / total * 100).round(2).alias('percentage')\n",
    "    ]).sort('count', descending=True).head(top_n).collect()\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(f\"결함 종류: {defect_type}\")\n",
    "    print(f\"문제 기기 부품 분석 (전체: {total:,}건)\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"{'순위':>4} {'문제 부품':<60} {'건수':>12} {'비율':>12}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for i, row in enumerate(component_dist.iter_rows(named=True), 1):\n",
    "        component = row['problem_components']\n",
    "        count = row['count']\n",
    "        pct = row['percentage']\n",
    "        \n",
    "        component_display = component[:58] if component and len(component) > 58 else (component or \"(NULL)\")\n",
    "        print(f\"{i:4d} {component_display:<60} {count:>12,} {pct:>11.2f}%\")\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    return component_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8e588",
   "metadata": {},
   "source": [
    "### 종합 결함 분석 대시보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05574a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_defect_analysis(df):\n",
    "    \"\"\"\n",
    "    결함에 대한 종합적인 분석을 수행하는 함수\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : polars.LazyFrame or polars.DataFrame\n",
    "        분석할 데이터프레임\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> comprehensive_defect_analysis(df_class3)\n",
    "    \"\"\"\n",
    "    total = df.select(pl.len()).collect().item()\n",
    "    \n",
    "    print(\"=\" * 120)\n",
    "    print(\"◼️ Class 3 기기 결함 종합 분석 대시보드\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    # 1. 결함 확인 여부\n",
    "    print(\"\\n◼️ 1. 제조사 검사 - 결함 확인 여부\")\n",
    "    print(\"-\" * 120)\n",
    "    defect_confirmed = df.group_by('defect_confirmed').agg([\n",
    "        pl.len().alias('count')\n",
    "    ]).with_columns([\n",
    "        (pl.col('count') / total * 100).round(2).alias('percentage')\n",
    "    ]).sort('count', descending=True).collect()\n",
    "    \n",
    "    for row in defect_confirmed.iter_rows(named=True):\n",
    "        confirmed = row['defect_confirmed'] or \"(NULL)\"\n",
    "        count = row['count']\n",
    "        pct = row['percentage']\n",
    "        print(f\"  {confirmed:<30} {count:>15,}건 ({pct:>5.2f}%)\")\n",
    "    \n",
    "    # 2. 결함 종류 Top 10\n",
    "    print(\"\\n◼️ 2. 결함 종류 Top 10\")\n",
    "    print(\"-\" * 120)\n",
    "    defect_types = df.filter(\n",
    "        pl.col('defect_type').is_not_null()\n",
    "    ).group_by('defect_type').agg([\n",
    "        pl.len().alias('count')\n",
    "    ]).with_columns([\n",
    "        (pl.col('count') / total * 100).round(2).alias('percentage')\n",
    "    ]).sort('count', descending=True).head(10).collect()\n",
    "    \n",
    "    for i, row in enumerate(defect_types.iter_rows(named=True), 1):\n",
    "        defect = row['defect_type'][:50]\n",
    "        count = row['count']\n",
    "        pct = row['percentage']\n",
    "        print(f\"  {i:2d}. {defect:<50} {count:>10,}건 ({pct:>5.2f}%)\")\n",
    "    \n",
    "    # 3. 문제 부품 Top 10\n",
    "    print(\"\\n◼️ 3. 문제 기기 부품 Top 10\")\n",
    "    print(\"-\" * 120)\n",
    "    components = df.filter(\n",
    "        pl.col('problem_components').is_not_null()\n",
    "    ).group_by('problem_components').agg([\n",
    "        pl.len().alias('count')\n",
    "    ]).sort('count', descending=True).head(10).collect()\n",
    "    \n",
    "    for i, row in enumerate(components.iter_rows(named=True), 1):\n",
    "        component = row['problem_components'][:50]\n",
    "        count = row['count']\n",
    "        print(f\"  {i:2d}. {component:<50} {count:>10,}건\")\n",
    "    \n",
    "    # 4. 환자 피해 요약\n",
    "    print(\"\\n◼️  4. 환자 피해 기록\")\n",
    "    print(\"-\" * 120)\n",
    "    harm_count = df.filter(\n",
    "        pl.col('patient_harm').is_not_null()\n",
    "    ).select(pl.len()).collect().item()\n",
    "    harm_pct = (harm_count / total * 100)\n",
    "    \n",
    "    print(f\"  환자 피해 기록 있음: {harm_count:>10,}건 ({harm_pct:>5.2f}%)\")\n",
    "    print(f\"  환자 피해 기록 없음: {total - harm_count:>10,}건 ({100 - harm_pct:>5.2f}%)\")\n",
    "    \n",
    "    # 5. 검사 조치 요약\n",
    "    print(\"\\n◼️ 5. 제조사 검사 조치\")\n",
    "    print(\"-\" * 120)\n",
    "    inspection_count = df.filter(\n",
    "        pl.col('inspection_actions').is_not_null()\n",
    "    ).select(pl.len()).collect().item()\n",
    "    inspection_pct = (inspection_count / total * 100)\n",
    "    \n",
    "    print(f\"  검사 조치 기록 있음: {inspection_count:>10,}건 ({inspection_pct:>5.2f}%)\")\n",
    "    print(f\"  검사 조치 기록 없음: {total - inspection_count:>10,}건 ({100 - inspection_pct:>5.2f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7130a",
   "metadata": {},
   "source": [
    "# 1000건 샘플.v2 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b13166",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name2 = \"maude_extracted_sample2.csv\"\n",
    "\n",
    "# CSV 파일을 Polars LazyFrame으로 불러오기\n",
    "extracted_sample2 = pl.read_csv(file_name2, ignore_errors=True)\n",
    "\n",
    "# 데이터 확인\n",
    "print(extracted_sample2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame을 LazyFrame으로 변환\n",
    "extracted_sample2_lazy = extracted_sample2.lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b6ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cleaned_2 = remove_na_values(extracted_sample2_lazy, dedup_cols, na_patterns)\n",
    "total, unique, dup = analyze_duplicates(sample_cleaned_2, dedup_cols)\n",
    "sample_final_2 = remove_duplicates(sample_cleaned_2, dedup_cols, keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e76965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"데이터 타입 통일 및 Class 3 필터링\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. device_class 컬럼 찾기\n",
    "device_class_cols = [\n",
    "    col for col in sample_final_2.collect_schema().names()\n",
    "    if 'device_' in col and 'openfda_device_class' in col\n",
    "]\n",
    "\n",
    "print(f\"\\n찾은 컬럼: {device_class_cols}\")\n",
    "\n",
    "# 2. 현재 타입 확인\n",
    "print(f\"\\n변환 전 타입:\")\n",
    "for col in device_class_cols:\n",
    "    dtype = sample_final_2.select(pl.col(col)).collect_schema()[col]\n",
    "    print(f\"  {col}: {dtype}\")\n",
    "\n",
    "# 3. String으로 통일\n",
    "print(f\"\\nString 타입으로 통일 중...\")\n",
    "sample_final_2 = sample_final_2.with_columns([\n",
    "    pl.col(col).cast(pl.Utf8).alias(col) for col in device_class_cols\n",
    "])\n",
    "\n",
    "print(f\"\\n변환 후 타입:\")\n",
    "for col in device_class_cols:\n",
    "    dtype = sample_final_2.select(pl.col(col)).collect_schema()[col]\n",
    "    print(f\"  {col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad4852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_2 = sample_final_2.filter(condition)\n",
    "row_count = sample_2.select(pl.len()).collect().item()\n",
    "print(f\"{row_count:,}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00afc1",
   "metadata": {},
   "source": [
    "### 결함 종류 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결함 종류 Top 20\n",
    "defect_distribution = analyze_defect_types(sample_2, top_n=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27cc55b",
   "metadata": {},
   "source": [
    "### 결함별 영향 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 10개 결함의 환자 피해/사건 유형\n",
    "impact_analysis = analyze_defect_impact(sample_2, top_defects=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2bec1e",
   "metadata": {},
   "source": [
    "### 특정 결함의 문제 부품"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Sensor/Accuracy\" 결함의 문제 부품\n",
    "components = analyze_defect_components(sample_2, 'Sensor/Accuracy', top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a8ffa",
   "metadata": {},
   "source": [
    "### 종합 대시보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 결함 분석 한눈에 보기\n",
    "comprehensive_defect_analysis(sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b1436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
