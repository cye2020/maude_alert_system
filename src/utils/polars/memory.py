"""Polars ë©”ëª¨ë¦¬ ì•ˆì „ ì—°ì‚° ìœ í‹¸ë¦¬í‹°

ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì˜¤ë²„í”Œë¡œìš°ë¥¼ ë°©ì§€í•˜ëŠ” í•¨ìˆ˜ë“¤
"""

import sys
import psutil
from typing import List, Dict
import polars as pl
from tqdm import tqdm


def estimate_string_size_stats(lf: pl.LazyFrame, cols: List[str], sample_size: int = 10000) -> Dict[str, float]:
    """ì»¬ëŸ¼ë“¤ì˜ ë¬¸ìì—´ ê¸¸ì´ í†µê³„ë¥¼ ìƒ˜í”Œ ë°ì´í„°ë¡œ ì¶”ì •

    Parameters:
    -----------
    lf : pl.LazyFrame
        ìƒ˜í”Œë§í•  LazyFrame
    cols : List[str]
        ì¸¡ì •í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    sample_size : int, default=10000
        ìƒ˜í”Œë§í•  í–‰ ìˆ˜

    Returns:
    --------
    Dict[str, float]
        ë¬¸ìì—´ ê¸¸ì´ í†µê³„
        - 'mean': í‰ê· 
        - 'median': ì¤‘ì•™ê°’ (50th percentile)
        - 'p75': 75th percentile
        - 'p90': 90th percentile
        - 'max': ìµœëŒ“ê°’

    Examples:
    ---------
    >>> stats = estimate_string_size_stats(lf, ['device_0_name', 'device_1_name'])
    >>> print(f"í‰ê· : {stats['mean']:.1f}ì")
    >>> print(f"ì¤‘ì•™ê°’: {stats['median']:.1f}ì")
    >>> print(f"75%: {stats['p75']:.1f}ì")
    """
    try:
        # ìƒ˜í”Œ ë°ì´í„° ì¶”ì¶œ
        sample = (
            lf.select(cols)
            .head(sample_size)
            .collect(engine='streaming')
        )

        # ëª¨ë“  ê°’ì˜ ê¸¸ì´ ìˆ˜ì§‘
        lengths = []
        for col in cols:
            values = sample[col].drop_nulls().to_list()
            lengths.extend([len(str(v)) for v in values])

        if not lengths:
            return {
                'mean': 50.0,
                'median': 50.0,
                'p75': 50.0,
                'p90': 50.0,
                'max': 50.0
            }

        # Polarsë¡œ í†µê³„ ê³„ì‚°
        lengths_series = pl.Series(lengths)

        stats = {
            'mean': lengths_series.mean(),
            'median': lengths_series.median(),
            'p75': lengths_series.quantile(0.75),
            'p90': lengths_series.quantile(0.90),
            'max': lengths_series.max()
        }

        return stats

    except Exception as e:
        print(f"  âš ï¸ ë¬¸ìì—´ ê¸¸ì´ í†µê³„ ì¶”ì • ì‹¤íŒ¨: {e}")
        return {
            'mean': 50.0,
            'median': 50.0,
            'p75': 50.0,
            'p90': 50.0,
            'max': 50.0
        }


def get_unique(lf: pl.LazyFrame, cols: List[str]) -> set:
    """ì—¬ëŸ¬ ì»¬ëŸ¼ì˜ ëª¨ë“  ê³ ìœ ê°’ì„ í•˜ë‚˜ì˜ setìœ¼ë¡œ ë°˜í™˜

    ì—¬ëŸ¬ ì»¬ëŸ¼ì— ê±¸ì³ ë‚˜íƒ€ë‚˜ëŠ” ëª¨ë“  ê³ ìœ í•œ ê°’ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì˜ˆë¥¼ ë“¤ì–´, device_0_name, device_1_name, device_2_name ì»¬ëŸ¼ë“¤ì˜
    ëª¨ë“  ê³ ìœ í•œ ë””ë°”ì´ìŠ¤ ì´ë¦„ì„ í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

    Parameters:
    -----------
    lf : pl.LazyFrame
        ë°ì´í„°ë¥¼ ì¶”ì¶œí•  LazyFrame
    cols : List[str]
        ê³ ìœ ê°’ì„ ì¶”ì¶œí•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸

    Returns:
    --------
    set
        ëª¨ë“  ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ì„ í•©ì¹œ set (ì¤‘ë³µ ì œê±°ë¨)

    Examples:
    ---------
    >>> # ì—¬ëŸ¬ device ì»¬ëŸ¼ì˜ ëª¨ë“  ê³ ìœ í•œ ë””ë°”ì´ìŠ¤ ì´ë¦„
    >>> device_cols = ['device_0_name', 'device_1_name', 'device_2_name']
    >>> all_devices = get_unique(lf, device_cols)
    >>> print(f"ì´ ê³ ìœ  ë””ë°”ì´ìŠ¤: {len(all_devices)}ê°œ")

    >>> # ì—¬ëŸ¬ ë‚ ì§œ ì»¬ëŸ¼ì˜ ëª¨ë“  ê³ ìœ  ë‚ ì§œ
    >>> date_cols = ['event_date', 'report_date', 'received_date']
    >>> all_dates = get_unique(lf, date_cols)

    Notes:
    ------
    - unpivotìœ¼ë¡œ ëª¨ë“  ì»¬ëŸ¼ì„ í•˜ë‚˜ì˜ ì»¬ëŸ¼ìœ¼ë¡œ í•©ì¹œ í›„ unique ì¶”ì¶œ
    - streaming ì—”ì§„ ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
    - null ê°’ë„ setì— í¬í•¨ë¨ (Noneìœ¼ë¡œ í‘œì‹œ)
    - ê²°ê³¼ê°€ ë©”ëª¨ë¦¬ì— ì™„ì „íˆ ë¡œë“œë˜ë¯€ë¡œ ê³ ìœ ê°’ì´ ë§¤ìš° ë§ìœ¼ë©´ ì£¼ì˜ í•„ìš”
    """
    unique_set = set(
        lf.select(cols)  # ì§€ì •ëœ ì»¬ëŸ¼ë§Œ ì„ íƒ
        .unpivot(on=cols)  # ëª¨ë“  ì»¬ëŸ¼ì„ 'value' ì»¬ëŸ¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        .select('value')  # value ì»¬ëŸ¼ë§Œ ì„ íƒ
        .unique()  # ì¤‘ë³µ ì œê±°
        .drop_nulls()  # ê²°ì¸¡ì¹˜ ì œê±°
        .collect(engine='streaming')  # streaming ì—”ì§„ìœ¼ë¡œ ì‹¤í–‰ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
        ['value']  # value ì»¬ëŸ¼ ì¶”ì¶œ
    )
    return unique_set


def get_unique_by_cols(lf: pl.LazyFrame, cols_group: Dict[str, List[str]]) -> Dict[str, set]:
    """ì»¬ëŸ¼ ê·¸ë£¹ë³„ë¡œ ê³ ìœ ê°’ì„ ì¶”ì¶œí•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜

    ì—¬ëŸ¬ ì»¬ëŸ¼ ê·¸ë£¹ì— ëŒ€í•´ ê°ê° ê³ ìœ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì˜ˆë¥¼ ë“¤ì–´, device ê´€ë ¨ ì»¬ëŸ¼ë“¤, patient ê´€ë ¨ ì»¬ëŸ¼ë“¤ì˜ ê³ ìœ ê°’ì„
    ê°ê° ë³„ë„ë¡œ ì¶”ì¶œí•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

    Parameters:
    -----------
    lf : pl.LazyFrame
        ë°ì´í„°ë¥¼ ì¶”ì¶œí•  LazyFrame
    cols_group : Dict[str, List[str]]
        ê·¸ë£¹ëª…ì„ í‚¤ë¡œ, ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
        ì˜ˆ: {
            'devices': ['device_0_name', 'device_1_name'],
            'manufacturers': ['device_0_manufacturer', 'device_1_manufacturer']
        }

    Returns:
    --------
    Dict[str, set]
        ê° ê·¸ë£¹ì˜ ê³ ìœ ê°’ setì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
        ì˜ˆ: {
            'devices': {'Device A', 'Device B', ...},
            'manufacturers': {'Company X', 'Company Y', ...}
        }

    Examples:
    ---------
    >>> # ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ë³„ ê³ ìœ ê°’ ì¶”ì¶œ
    >>> cols_group = {
    ...     'devices': ['device_0_name', 'device_1_name', 'device_2_name'],
    ...     'manufacturers': ['device_0_manufacturer', 'device_1_manufacturer'],
    ...     'models': ['device_0_model', 'device_1_model']
    ... }
    >>> unique_values = get_unique_by_cols(lf, cols_group)
    >>>
    >>> # ê²°ê³¼ í™•ì¸
    >>> for group, values in unique_values.items():
    ...     print(f"{group}: {len(values)}ê°œì˜ ê³ ìœ ê°’")

    >>> # íŠ¹ì • ê·¸ë£¹ì˜ ê°’ ì ‘ê·¼
    >>> all_devices = unique_values['devices']
    >>> all_manufacturers = unique_values['manufacturers']

    WARNINGS:
    ---------
    âš ï¸ **ë©”ëª¨ë¦¬ ì‚¬ìš© ì£¼ì˜ì‚¬í•­**:
    - ì´ í•¨ìˆ˜ëŠ” ê° ê·¸ë£¹ë³„ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ê³ ìœ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤
    - ê° ê·¸ë£¹ì˜ ê³ ìœ ê°’ì´ ë©”ëª¨ë¦¬ì— ì™„ì „íˆ ë¡œë“œë©ë‹ˆë‹¤
    - ê³ ìœ ê°’ì´ ë§¤ìš° ë§ì€ ê²½ìš°(ìˆ˜ì‹­ë§Œ~ìˆ˜ë°±ë§Œ ê°œ) ë©”ëª¨ë¦¬ ë¶€ì¡± ë°œìƒ ê°€ëŠ¥

    **ë©”ëª¨ë¦¬ ì ˆì•½ ëŒ€ì•ˆ**:
    - ê³ ìœ ê°’ ê°œìˆ˜ë§Œ í•„ìš”í•œ ê²½ìš°: n_unique() ì‚¬ìš©
    - ìƒ˜í”Œë§Œ í•„ìš”í•œ ê²½ìš°: .unique().limit(n) ì‚¬ìš©
    - ë§¤ìš° í° ë°ì´í„°: ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ ë””ìŠ¤í¬ ê¸°ë°˜ ì²˜ë¦¬ ê³ ë ¤

    Example (ì•ˆì „í•œ ì‚¬ìš©):
    >>> # ê³ ìœ ê°’ ê°œìˆ˜ë§Œ í™•ì¸ (ë©”ëª¨ë¦¬ ì•ˆì „)
    >>> for group, cols in cols_group.items():
    ...     n_unique = lf.select(cols).unpivot(on=cols).select('value').n_unique().collect().item()
    ...     print(f"{group}: {n_unique}ê°œ")
    ...     if n_unique > 100000:  # ì„ê³„ê°’ ì²´í¬
    ...         print(f"âš ï¸ {group}ì€ ê³ ìœ ê°’ì´ ë„ˆë¬´ ë§ì•„ ê±´ë„ˆëœë‹ˆë‹¤")
    """
    unique_by_cols = {}

    # ê° ê·¸ë£¹ë³„ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ê³ ìœ ê°’ ì¶”ì¶œ
    for group, cols in cols_group.items():
        unique_by_cols[group] = get_unique(lf, cols)

    return unique_by_cols


def get_unique_by_cols_safe(
    lf: pl.LazyFrame,
    cols_group: Dict[str, List[str]],
    max_unique: int = None,
    memory_safety_ratio: float = 0.1,
    check_first: bool = True,
    estimate_string_size: bool = True,
    sample_size: int = 10000,
    size_metric: str = 'p75',
    calibration_factor: float = 1.0
) -> Dict[str, set]:
    """ë©”ëª¨ë¦¬ ì•ˆì „í•˜ê²Œ ì»¬ëŸ¼ ê·¸ë£¹ë³„ ê³ ìœ ê°’ ì¶”ì¶œ (ìë™ ì„ê³„ê°’ ê³„ì‚°)

    ì‹œìŠ¤í…œì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ì™€ ì‹¤ì œ ë°ì´í„°ì˜ ë¬¸ìì—´ ê¸¸ì´ í†µê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    ì•ˆì „í•œ ìµœëŒ€ ê³ ìœ ê°’ ê°œìˆ˜ë¥¼ ìë™ ê³„ì‚°í•©ë‹ˆë‹¤.

    Parameters:
    -----------
    lf : pl.LazyFrame
        ë°ì´í„°ë¥¼ ì¶”ì¶œí•  LazyFrame
    cols_group : Dict[str, List[str]]
        ê·¸ë£¹ëª…: ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬
        ì˜ˆ: {'devices': ['device_0_name', 'device_1_name']}
    max_unique : int, optional
        ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•  ìµœëŒ€ ê³ ìœ ê°’ ê°œìˆ˜. Noneì´ë©´ ìë™ ê³„ì‚°. Defaults to None.
    memory_safety_ratio : float, default=0.1
        ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ì˜ ëª‡ %ê¹Œì§€ ì‚¬ìš©í• ì§€ (0.1 = 10%)
        ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì • ê¶Œì¥ (0.05 ~ 0.15)
    check_first : bool, default=True
        ì¶”ì¶œ ì „ì— ê³ ìœ ê°’ ê°œìˆ˜ë¥¼ ë¨¼ì € ì²´í¬í• ì§€ ì—¬ë¶€
    estimate_string_size : bool, default=True
        ì‹¤ì œ ë°ì´í„°ë¡œë¶€í„° ë¬¸ìì—´ ê¸¸ì´ë¥¼ ì¶”ì •í• ì§€ ì—¬ë¶€
        True ê¶Œì¥ (ë” ì •í™•í•œ ì˜ˆì¸¡)
    sample_size : int, default=10000
        ë¬¸ìì—´ ê¸¸ì´ ì¶”ì • ì‹œ ìƒ˜í”Œë§í•  í–‰ ìˆ˜
    size_metric : str, default='p75'
        ì‚¬ìš©í•  í¬ê¸° ì¸¡ì • ê¸°ì¤€
        - 'mean': í‰ê·  (ê·¹ë‹¨ê°’ì— ë¯¼ê°, ë¹„ì¶”ì²œ)
        - 'median': ì¤‘ì•™ê°’ (50th percentile, ì•ˆì •ì )
        - 'p75': 75th percentile (ê¶Œì¥, ëŒ€ë¶€ë¶„ ì»¤ë²„í•˜ë©´ì„œ ì•ˆì „)
        - 'p90': 90th percentile (ë§¤ìš° ë³´ìˆ˜ì )
    calibration_factor : float, default=1.0
        ë©”ëª¨ë¦¬ ì¶”ì • ë³´ì • ê³„ìˆ˜
        - 1.0ë³´ë‹¤ í¬ë©´ ë” ë³´ìˆ˜ì  (ë©”ëª¨ë¦¬ë¥¼ ë” ë§ì´ ì˜ˆìƒ)
        - 1.0ë³´ë‹¤ ì‘ìœ¼ë©´ ëœ ë³´ìˆ˜ì 
        í•¨ìˆ˜ ì‹¤í–‰ í›„ í”¼ë“œë°±ì„ ë³´ê³  ì¡°ì • ê°€ëŠ¥

    Returns:
    --------
    Dict[str, set or None]
        ì•ˆì „í•˜ê²Œ ì¶”ì¶œëœ ê³ ìœ ê°’ ë”•ì…”ë„ˆë¦¬
        - ì„±ê³µ: set of unique values
        - ì‹¤íŒ¨ ë˜ëŠ” ìŠ¤í‚µ: None

    Examples:
    ---------
    >>> # ê¸°ë³¸ ì„¤ì • (75th percentile ì‚¬ìš©)
    >>> cols_group = {
    ...     'devices': ['device_0_name', 'device_1_name'],
    ...     'manufacturers': ['device_0_manufacturer', 'device_1_manufacturer']
    ... }
    >>> unique_values = get_unique_by_cols_safe(lf, cols_group)

    >>> # ì¤‘ì•™ê°’ ì‚¬ìš© (ëœ ë³´ìˆ˜ì )
    >>> unique_values = get_unique_by_cols_safe(
    ...     lf,
    ...     cols_group,
    ...     size_metric='median',
    ...     memory_safety_ratio=0.15
    ... )

    >>> # 90th percentile ì‚¬ìš© (ë” ë³´ìˆ˜ì )
    >>> unique_values = get_unique_by_cols_safe(
    ...     lf,
    ...     cols_group,
    ...     size_metric='p90',
    ...     memory_safety_ratio=0.05
    ... )

    >>> # ë³´ì • ê³„ìˆ˜ ì ìš© (ì´ì „ ì‹¤í–‰ì—ì„œ í”¼ë“œë°± ë°›ì€ ê²½ìš°)
    >>> unique_values = get_unique_by_cols_safe(
    ...     lf,
    ...     cols_group,
    ...     calibration_factor=0.8  # ë©”ëª¨ë¦¬ë¥¼ ê³¼ëŒ€í‰ê°€í–ˆë‹¤ë©´
    ... )

    Notes:
    ------
    - **ê¶Œì¥ ì„¤ì •**: size_metric='p75', memory_safety_ratio=0.1 (ê¸°ë³¸ê°’)
    - í‰ê· (mean)ì€ ê·¹ë‹¨ê°’ì— ë¯¼ê°í•˜ë¯€ë¡œ ë¹„ì¶”ì²œ
    - ì¤‘ì•™ê°’(median)ì€ ì•ˆì •ì ì´ì§€ë§Œ í° ê°’ë“¤ì„ ê³¼ì†Œí‰ê°€í•  ìˆ˜ ìˆìŒ
    - calibration_factorëŠ” ì‹¤í–‰ í›„ í”¼ë“œë°±ì„ ë³´ê³  ì¡°ì •
    - ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì€ ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
    """
    # max_uniqueê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìë™ ê³„ì‚°
    if max_unique is None:
        # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (bytes) í™•ì¸
        available_memory = psutil.virtual_memory().available

        # 2. ì•ˆì „ ë§ˆì§„ì„ ê³ ë ¤í•œ ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬
        safe_memory = available_memory * memory_safety_ratio

        # 3. ë¬¸ìì—´ ê¸¸ì´ í†µê³„ ì¶”ì •
        if estimate_string_size:
            print("ë¬¸ìì—´ ê¸¸ì´ í†µê³„ë¥¼ ì‹¤ì œ ë°ì´í„°ë¡œë¶€í„° ì¶”ì • ì¤‘...")
            # ëª¨ë“  ì»¬ëŸ¼ ìˆ˜ì§‘
            all_cols = [col for cols in cols_group.values() for col in cols]
            # í†µê³„ ê³„ì‚°
            stats = estimate_string_size_stats(lf, all_cols, sample_size)

            # ì„ íƒëœ ë©”íŠ¸ë¦­ ì‚¬ìš©
            avg_string_size = stats[size_metric]

            # í†µê³„ ì¶œë ¥
            print(f"  ë¬¸ìì—´ ê¸¸ì´ í†µê³„:")
            print(f"    - í‰ê· (mean): {stats['mean']:.1f}ì")
            print(f"    - ì¤‘ì•™ê°’(median): {stats['median']:.1f}ì")
            print(f"    - 75%ile: {stats['p75']:.1f}ì")
            print(f"    - 90%ile: {stats['p90']:.1f}ì")
            print(f"    - ìµœëŒ“ê°’: {stats['max']:.0f}ì")
            print(f"  â†’ ì‚¬ìš©í•  í¬ê¸°({size_metric}): {avg_string_size:.1f}ì\n")
        else:
            # ì¶”ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            avg_string_size = 50  # ê¸°ë³¸ê°’: 50ì

        # 4. Python stringì˜ ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
        # Python 3.3+ì—ì„œ:
        # - ASCIIëŠ” 1byte/char
        # - UnicodeëŠ” 2-4bytes/char
        # - í‰ê· ì ìœ¼ë¡œ 2bytes/charë¡œ ê°€ì • (ì˜ë¬¸+ìˆ«ì í˜¼í•©)
        bytes_per_char = 2

        # 5. Python ê°ì²´ ì˜¤ë²„í—¤ë“œ
        str_overhead = 50   # str ê°ì²´ í—¤ë”: ~50 bytes
        set_overhead = 28   # set entry ì˜¤ë²„í—¤ë“œ: ~28 bytes (hash table)

        # 6. ì´ ì˜ˆìƒ ë°”ì´íŠ¸ ìˆ˜ ê³„ì‚°
        estimated_bytes_per_unique = (
            (avg_string_size * bytes_per_char) +  # ì‹¤ì œ ë¬¸ìì—´ ë°ì´í„°
            str_overhead +                         # str ê°ì²´ ì˜¤ë²„í—¤ë“œ
            set_overhead                           # set ìë£Œêµ¬ì¡° ì˜¤ë²„í—¤ë“œ
        ) * calibration_factor  # ë³´ì • ê³„ìˆ˜ ì ìš©

        # 7. ì•ˆì „í•œ ìµœëŒ€ ê³ ìœ ê°’ ê°œìˆ˜ ê³„ì‚°
        max_unique = int(safe_memory / estimated_bytes_per_unique)

        # 8. ê³„ì‚° ê²°ê³¼ ì¶œë ¥
        print(f"=== ë©”ëª¨ë¦¬ ê¸°ë°˜ ìë™ ì„ê³„ê°’ ê³„ì‚° ===")
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {available_memory / (1024**3):.2f} GB")
        print(f"ì•ˆì „ ì‚¬ìš© ë©”ëª¨ë¦¬ ({memory_safety_ratio*100:.0f}%): {safe_memory / (1024**3):.2f} GB")
        print(f"ì˜ˆìƒ ë°”ì´íŠ¸/ê³ ìœ ê°’: {estimated_bytes_per_unique:.0f} bytes")
        print(f"  - ë¬¸ìì—´ ë°ì´í„°: {avg_string_size * bytes_per_char:.0f} bytes")
        print(f"  - str ì˜¤ë²„í—¤ë“œ: {str_overhead} bytes")
        print(f"  - set ì˜¤ë²„í—¤ë“œ: {set_overhead} bytes")
        if calibration_factor != 1.0:
            print(f"  - ë³´ì • ê³„ìˆ˜: {calibration_factor}x")
        print(f"ê³„ì‚°ëœ ìµœëŒ€ ê³ ìœ ê°’: {max_unique:,}ê°œ")
        print(f"{'='*40}\n")
    else:
        # ìˆ˜ë™ ì§€ì •ëœ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì˜ˆìƒ ë©”ëª¨ë¦¬ ê³„ì‚°
        avg_string_size = 50
        bytes_per_char = 2
        str_overhead = 50
        set_overhead = 28
        estimated_bytes_per_unique = (
            (avg_string_size * bytes_per_char) + str_overhead + set_overhead
        ) * calibration_factor

    # ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    unique_by_cols = {}

    # ê° ê·¸ë£¹ë³„ë¡œ ì²˜ë¦¬
    for group, cols in tqdm(cols_group.items(), desc="Extracting unique values"):
        # ì‚¬ì „ ì²´í¬: ê³ ìœ ê°’ ê°œìˆ˜ í™•ì¸
        if check_first:
            # ê³ ìœ ê°’ ê°œìˆ˜ ê³„ì‚° (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
            n_unique = (
                lf.select(cols)
                .unpivot(on=cols)  # ëª¨ë“  ì»¬ëŸ¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
                .select(pl.col('value').n_unique())  # ê³ ìœ ê°’ ê°œìˆ˜ë§Œ ê³„ì‚°
                .collect(engine='streaming')  # streaming ì—”ì§„ ì‚¬ìš©
                .item()  # ë‹¨ì¼ ê°’ ì¶”ì¶œ
            )

            # ì˜ˆìƒ ë©”ëª¨ë¦¬ ê³„ì‚°
            estimated_mem_mb = (n_unique * estimated_bytes_per_unique) / (1024**2)
            print(f"{group}: {n_unique:,}ê°œì˜ ê³ ìœ ê°’ (ì˜ˆìƒ ë©”ëª¨ë¦¬: {estimated_mem_mb:.1f} MB)")

            # ì„ê³„ê°’ ì´ˆê³¼ ì²´í¬
            if n_unique > max_unique:
                print(f"  âš ï¸ {group}ì€ ê³ ìœ ê°’ì´ {max_unique:,}ê°œë¥¼ ì´ˆê³¼í•˜ì—¬ ê±´ë„ˆëœë‹ˆë‹¤\n")
                unique_by_cols[group] = None
                continue

        # ì•ˆì „í•˜ë©´ ì‹¤ì œ ì¶”ì¶œ ì‹œë„
        try:
            # get_unique í•¨ìˆ˜ë¡œ ê³ ìœ ê°’ ì¶”ì¶œ
            unique_by_cols[group] = get_unique(lf, cols)

            # ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • (ë” ì •í™•í•œ ë°©ë²•)
            # ê° ë¬¸ìì—´ì˜ í¬ê¸° í•©ê³„
            actual_bytes = sum(sys.getsizeof(s) for s in unique_by_cols[group])
            # set ê°ì²´ ìì²´ì˜ í¬ê¸° ì¶”ê°€
            actual_bytes += sys.getsizeof(unique_by_cols[group])
            actual_mb = actual_bytes / (1024**2)

            # ì˜ˆì¸¡ ì •í™•ë„ ê³„ì‚°
            accuracy_pct = (estimated_mem_mb / actual_mb) * 100 if actual_mb > 0 else 0

            # ê²°ê³¼ ì¶œë ¥
            print(f"  âœ“ {group} ì¶”ì¶œ ì™„ë£Œ (ì‹¤ì œ ë©”ëª¨ë¦¬: {actual_mb:.2f} MB)")
            print(f"    â†’ ì˜ˆìƒì¹˜ ì •í™•ë„: {accuracy_pct:.1f}% (ì˜ˆìƒ/ì‹¤ì œ ë¹„ìœ¨)")

            # ë³´ì • ê³„ìˆ˜ í”¼ë“œë°±
            # ì˜ˆì¸¡ê°’ì´ ì‹¤ì œê°’ì˜ 150% ì´ìƒì´ë©´ (ê³¼ëŒ€í‰ê°€)
            if accuracy_pct > 150:
                suggested_factor = calibration_factor * 0.8
                print(f"    ğŸ’¡ Tip: calibration_factorë¥¼ {suggested_factor:.2f}ë¡œ ë‚®ì¶”ë©´ ë” ì •í™•í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤")
            # ì˜ˆì¸¡ê°’ì´ ì‹¤ì œê°’ì˜ 80% ë¯¸ë§Œì´ë©´ (ê³¼ì†Œí‰ê°€)
            elif accuracy_pct < 80:
                suggested_factor = calibration_factor * 1.2
                print(f"    ğŸ’¡ Tip: calibration_factorë¥¼ {suggested_factor:.2f}ë¡œ ë†’ì´ë©´ ë” ì •í™•í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤")
            print()

        except MemoryError:
            # ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì‹¤íŒ¨
            print(f"  âŒ {group} ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì‹¤íŒ¨\n")
            unique_by_cols[group] = None

    # 2. ê²°ê³¼ ìš”ì•½
    print("\n=== ì¶”ì¶œ ìš”ì•½ ===")
    success = sum(1 for v in unique_by_cols.values() if v is not None)
    print(f"ì„±ê³µ: {success}/{len(cols_group)}")
    print(f"ì‹¤íŒ¨/ìŠ¤í‚µ: {len(cols_group) - success}/{len(cols_group)}")
    return unique_by_cols


def groupby_nunique_safe(
    lf: pl.LazyFrame,
    group_cols: List[str],
    agg_cols: List[str] = None,
    top_n: int = 100,
    streaming: bool = True
) -> pl.DataFrame:
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ group by í›„ ê° ê·¸ë£¹ì˜ í–‰ ê°œìˆ˜ì™€ unique ê°œìˆ˜ ê³„ì‚°

    ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ë©”ëª¨ë¦¬ ì˜¤ë²„í”Œë¡œìš° ì—†ì´ ê·¸ë£¹ë³„ ì§‘ê³„ë¥¼ ìˆ˜í–‰
    streaming ì˜µì…˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì†Œí™”

    Parameters:
    -----------
    lf : pl.LazyFrame
        ë¶„ì„í•  LazyFrame
    group_cols : List[str]
        ê·¸ë£¹í™”í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
    agg_cols : List[str], optional
        unique ê°œìˆ˜ë¥¼ ì…€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸. Noneì´ë©´ countë§Œ ê³„ì‚°. Defaults to None.
    top_n : int, optional
        ìƒìœ„ ëª‡ ê°œ ê·¸ë£¹ë§Œ ë°˜í™˜í• ì§€. Defaults to 100.
    streaming : bool, optional
        streaming ì—”ì§„ ì‚¬ìš© ì—¬ë¶€ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ). Defaults to True.

    Returns:
    --------
    pl.DataFrame: ê·¸ë£¹ë³„ ì§‘ê³„ ê²°ê³¼ DataFrame
        - group_cols: ê·¸ë£¹í™” ì»¬ëŸ¼ë“¤
        - count: ê° ê·¸ë£¹ì˜ í–‰ ê°œìˆ˜
        - {col}_unique: ê° ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ê°œìˆ˜ (agg_cols ì§€ì • ì‹œ)

    Examples:
    ---------
    >>> # ë‹¨ìˆœ ì¹´ìš´íŠ¸ë§Œ
    >>> result = groupby_nunique_safe(
    ...     lf,
    ...     group_cols=['device_model', 'brand_name'],
    ...     top_n=50
    ... )

    >>> # unique ê°œìˆ˜ë„ í•¨ê»˜ ê³„ì‚°
    >>> result = groupby_nunique_safe(
    ...     lf,
    ...     group_cols=['device_model', 'brand_name'],
    ...     agg_cols=['report_id', 'event_type'],
    ...     top_n=100,
    ...     streaming=True
    ... )
    """
    # ì§‘ê³„ í‘œí˜„ì‹ êµ¬ì„±
    if agg_cols is None:
        # countë§Œ ê³„ì‚°
        agg_exprs = [pl.len().alias('count')]
    else:
        # count + ê° ì»¬ëŸ¼ì˜ unique ê°œìˆ˜ ê³„ì‚°
        agg_exprs = [
            pl.len().alias('count')
        ] + [
            pl.col(col).n_unique().alias(f'{col}_unique')
            for col in agg_cols
        ]

    # streaming ì—¬ë¶€ì— ë”°ë¼ ì—”ì§„ ì„ íƒ
    engine = 'streaming' if streaming else 'auto'

    # group by í›„ ì§‘ê³„, ì •ë ¬, ìƒìœ„ Nê°œë§Œ ë°˜í™˜
    return (
        lf.group_by(group_cols)
        .agg(agg_exprs)
        .sort('count', descending=True)  # count ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
        .head(top_n)  # ìƒìœ„ Nê°œë§Œ
        .collect(engine=engine)  # ì§€ì •ëœ ì—”ì§„ìœ¼ë¡œ ì‹¤í–‰
        .to_pandas()  # pandas DataFrameìœ¼ë¡œ ë³€í™˜
    )
