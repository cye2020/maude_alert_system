# === 모델 설정 ===
model:
  model_path: "nvidia/Qwen3-8B-FP8"
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.90
  max_model_len: 16384
  max_num_batched_tokens: 32768
  max_num_seqs: 256
  max_retries: 2
  enable_prefix_caching: true

# === 샘플링 파라미터 ===
sampling:
  temperature: 0.1
  max_tokens: 256
  top_p: 0.95

# === 프롬프트 모드 (텍스트는 prompt.py에 유지) ===
prompt_mode: "general"   # general | sample

# === 체크포인트 ===
checkpoint:
  dir: "./checkpoints"
  interval: 5000
  prefix: "checkpoint"

# === 추출 대상 ===
source:
  category: "event"
  suffix: _CURRENT
  columns:
    - "MDR_TEXT"
    - "PRODUCT_PROBLEMS"
  where: "MDR_TEXT IS NOT NULL"

# === 추출 결과 테이블 스키마 ===
extracted:
  suffix: "_EXTRACTED"
  join_suffix: "_LLM_EXTRACTED"
  columns:
    - name: "MDR_TEXT"
      type: "VARCHAR(16777216)"
      primary_key: true
    - name: "PATIENT_HARM"
      type: "VARCHAR(50)"
    - name: "PROBLEM_COMPONENTS"
      type: "VARCHAR(16777216)"
    - name: "DEFECT_CONFIRMED"
      type: "BOOLEAN"
    - name: "DEFECT_TYPE"
      type: "VARCHAR(50)"
