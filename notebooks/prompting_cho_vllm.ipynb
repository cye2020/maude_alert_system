{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a11b725",
   "metadata": {},
   "source": [
    "# mdr_text 프롬프팅 과정 (vLLM 버전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Tuple,\n",
    "    List,\n",
    "    Dict,\n",
    "    Any,\n",
    "    Sequence,\n",
    "    Union,\n",
    "    Optional,\n",
    ")\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import psutil\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from pprint import pprint, pformat\n",
    "\n",
    "# pydantic\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "# vLLM\n",
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "from vllm.sampling_params import StructuredOutputsParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bae3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 상대 경로 사용\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "# 맨 앞에 추가\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# 이제 import\n",
    "from src.loading import DataLoader\n",
    "from src.utils import increment_path\n",
    "\n",
    "loader = DataLoader(\n",
    "    output_file= DATA_DIR / 'gold' / 'maude.parquet',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ab848",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = 'polars'\n",
    "polars_kwargs = {\n",
    "    'use_statistics': True,\n",
    "    'parallel': 'auto',\n",
    "    'low_memory': False,\n",
    "    'rechunk': False,\n",
    "    'cache': True,\n",
    "}\n",
    "maude_lf = loader.load(adapter=adapter, **polars_kwargs)\n",
    "maude_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3bbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enum 정의\n",
    "class PatientHarm(str, Enum):\n",
    "    NO_HARM = \"No Harm\"\n",
    "    MINOR_INJURY = \"Minor Injury\"\n",
    "    SERIOUS_INJURY = \"Serious Injury\"\n",
    "    DEATH = \"Death\"\n",
    "    UNKNOWN = \"Unknown\"\n",
    "\n",
    "class DefectType(str, Enum):\n",
    "    FUNCTIONAL_FAILURE = \"Functional Failure\"\n",
    "    MECHANICAL_STRUCTURAL = \"Mechanical/Structural\"\n",
    "    ELECTRICAL_POWER = \"Electrical/Power\"\n",
    "    SOFTWARE_INTERFACE = \"Software/Interface\"\n",
    "    ALARM_ALERT = \"Alarm/Alert\"\n",
    "    SENSOR_ACCURACY = \"Sensor/Accuracy\"\n",
    "    COMMUNICATION_CONNECTIVITY = \"Communication/Connectivity\"\n",
    "    LABELING_PACKAGING = \"Labeling/Packaging\"\n",
    "    STERILITY_CONTAMINATION = \"Sterility/Contamination\"\n",
    "    USER_HUMAN_FACTOR = \"User/Human Factor\"\n",
    "    ENVIRONMENTAL_COMPATIBILITY = \"Environmental/Compatibility\"\n",
    "    OTHER = \"Other\"\n",
    "    UNKNOWN = \"Unknown\"\n",
    "\n",
    "# BaseModel 정의\n",
    "class IncidentDetails(BaseModel):\n",
    "    patient_harm: PatientHarm = Field(description=\"Level of patient harm associated with the incident\")\n",
    "    problem_components: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of problematic component keywords found in the text\",\n",
    "        min_length=0,\n",
    "        max_length=5\n",
    "    )\n",
    "    incident_summary: str = Field(max_length=200, description=\"Concise summary of the incident\")\n",
    "\n",
    "class ManufacturerInspection(BaseModel):\n",
    "    defect_confirmed: bool | None = Field(None, description=\"Whether the defect was confirmed\")\n",
    "    defect_type: DefectType | None = Field(None, description=\"Type of defect identified during inspection\")\n",
    "    inspection_actions: str | None = Field(None, max_length=200)\n",
    "\n",
    "class MAUDEExtraction(BaseModel):\n",
    "    incident_details: IncidentDetails\n",
    "    manufacturer_inspection: ManufacturerInspection\n",
    "\n",
    "SYSTEM_INSTRUCTION = SYSTEM_INSTRUCTION = \"\"\"\n",
    "You are an expert analyst of FDA MAUDE medical device adverse event reports.\n",
    "\n",
    "Your mission is to extract high-quality structured variables from MDR text\n",
    "by performing multi-dimensional decomposition and inference.\n",
    "\n",
    "PRIMARY OBJECTIVE\n",
    "- Produce exactly 6 derived variables with high semantic quality.\n",
    "- Minimize the use of \"Unknown\" AND minimize defect_confirmed = null.\n",
    "- If ANY symptom or contextual clue exists, you MUST infer the closest valid category.\n",
    "- Express uncertainty via confidence_score, NOT via \"Unknown\" or null.\n",
    "\n",
    "CORE PRINCIPLES\n",
    "1. Symptom-driven inference over explicit statements.\n",
    "2. Root-cause classification over surface wording.\n",
    "3. UNKNOWN is a last resort, not a safe choice.\n",
    "4. Regulatory / disclaimer boilerplate is background noise unless it contains incident facts.\n",
    "5. Evidence-based outputs: every key value must be defensible from the text.\n",
    "6. Operational usefulness: defect_confirmed should rarely be null.\n",
    "\n",
    "UNKNOWN MINIMIZATION RULES\n",
    "- patient_harm:\n",
    "  * Use \"Unknown\" ONLY if the report gives absolutely no patient outcome information.\n",
    "- defect_type:\n",
    "  * Use \"Unknown\" ONLY if the MDR text provides virtually no describable symptom\n",
    "    (e.g., only “device malfunctioned” with no further detail).\n",
    "  * If symptoms exist but are ambiguous, choose the closest category and lower confidence_score.\n",
    "\n",
    "DERIVED VARIABLES (MUST PRODUCE ALL 6)\n",
    "A. patient_harm\n",
    "   [\"No Harm\",\"Minor Injury\",\"Serious Injury\",\"Death\",\"Unknown\"]\n",
    "\n",
    "B. defect_type\n",
    "   One of:\n",
    "   [\"Functional Failure\",\"Mechanical/Structural\",\"Electrical/Power\",\"Software/Interface\",\n",
    "    \"Alarm/Alert\",\"Sensor/Accuracy\",\"Communication/Connectivity\",\"Labeling/Packaging\",\n",
    "    \"Sterility/Contamination\",\"User/Human Factor\",\"Environmental/Compatibility\",\n",
    "    \"Other\",\"Unknown\"]\n",
    "\n",
    "C. defect_confirmed (STRICT DECISION POLICY; null should be <5%)\n",
    "Definition:\n",
    "- \"confirmed\" means either:\n",
    "  (1) Manufacturer/inspection explicitly confirmed the defect/cause, OR\n",
    "  (2) The MDR provides symptom evidence that strongly supports the inferred defect_type\n",
    "      (symptom-supported inference), even if manufacturer did not confirm.\n",
    "\n",
    "You MUST assign one of: true / false / null using the rules below:\n",
    "\n",
    "C1) Set defect_confirmed = true if ANY of the following is present:\n",
    "- Explicit confirmation language:\n",
    "  \"confirmed\", \"found\", \"verified\", \"analysis determined\", \"root cause identified\", \"testing revealed\"\n",
    "- Corrective action that implies defect reality:\n",
    "  \"replaced\", \"removed\", \"repaired\", \"capped and replaced\", \"component exchanged\", \"device returned and found ...\"\n",
    "  AND the described symptoms are specific (not purely vague).\n",
    "- Strong symptom specificity:\n",
    "  Measurable/technical indicators (e.g., impedance high, threshold high, error code, fracture/leak, overheating,\n",
    "  no power, calibration drift, lost connection) that map clearly to a defect_type.\n",
    "Guideline:\n",
    "- If defect_type is NOT \"Unknown\" and confidence_score >= 70, defect_confirmed should almost always be true.\n",
    "\n",
    "C2) Set defect_confirmed = false if ANY of the following is present:\n",
    "- Explicit non-confirmation / inconclusive language:\n",
    "  \"could not be confirmed\", \"no problem found\", \"no defect found\", \"unable to reproduce\",\n",
    "  \"no anomalies detected\", \"no malfunction observed\", \"device met specifications\"\n",
    "- The report indicates suspicion only with weak support:\n",
    "  phrases like \"it was alleged\", \"it was suspected\", \"possibly\", with no concrete symptom evidence,\n",
    "  and confidence_score < 70.\n",
    "- The report explicitly states investigation pending/under investigation AND provides no specific symptoms.\n",
    "\n",
    "C3) Set defect_confirmed = null ONLY if ALL of the following are true (rare):\n",
    "- No inspection/investigation status is mentioned (neither confirmed nor inconclusive nor pending), AND\n",
    "- Symptom detail is too thin to support a strong inference (confidence_score < 40), AND\n",
    "- defect_type must be \"Unknown\" or \"Other\" due to lack of describable symptom mapping.\n",
    "In all other cases, you MUST choose true or false.\n",
    "\n",
    "D. problem_components\n",
    "   - Up to 5 concrete component keywords\n",
    "   - Prefer physical or functional components (e.g., lead, battery, sensor, connector)\n",
    "   - Avoid abstract or vague terms\n",
    "\n",
    "E. incident_summary\n",
    "   - ≤ 200 characters\n",
    "   - Factual, concise\n",
    "   - Include key symptom + action + patient outcome if available\n",
    "   - No speculation or regulatory language\n",
    "\n",
    "F. confidence_score\n",
    "   Integer 0–100 indicating confidence in defect_type inference:\n",
    "   - 90–100: explicit or highly specific symptom evidence\n",
    "   - 70–89 : strong symptom evidence, no explicit confirmation\n",
    "   - 40–69 : partial evidence, notable ambiguity\n",
    "   - 0–39  : very thin evidence (if this low, reconsider whether Unknown is unavoidable)\n",
    "\n",
    "EVIDENCE REQUIREMENT\n",
    "- For each of A–E, provide one short evidence snippet (≤ 25 words).\n",
    "- Prefer direct quotes from the MDR text.\n",
    "- If inference is indirect, state:\n",
    "  \"No direct snippet; inferred from overall text\" and lower confidence_score.\n",
    "\n",
    "SELF-CHECK (MANDATORY)\n",
    "Before finalizing the answer, perform the following internally:\n",
    "\n",
    "[Step 1: Accuracy Check]\n",
    "- Exactly 6 derived variables produced?\n",
    "- UNKNOWN used only under strict rules?\n",
    "- defect_type matches primary/root failure mode?\n",
    "- defect_confirmed is null only under the strict C3 rule?\n",
    "- Length limits respected?\n",
    "\n",
    "[Step 2: Revision & Refinement]\n",
    "- Fix any ambiguity, rule violations, or missing evidence.\n",
    "- Improve conciseness and consistency.\n",
    "\n",
    "Only after self-check, produce the final output.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "Analyze this FDA MAUDE report and extract structured data:\n",
    "\n",
    "[MDR TEXT]\n",
    "{text}\n",
    "\n",
    "[ORIGINAL PRODUCT PROBLEM]\n",
    "{product_problem}\n",
    "\n",
    "[OUTPUT REQUIREMENTS]\n",
    "Return JSON with incident_details and manufacturer_inspection.\n",
    "\n",
    "[FINAL REMINDER]\n",
    "- UNKNOWN should appear in only exceptional cases.\n",
    "- If symptoms exist, infer.\n",
    "- Confidence belongs in confidence_score, not in UNKNOWN.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9463dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchMAUDEExtractor:\n",
    "    def __init__(self, \n",
    "                 model_path='Qwen/Qwen2.5-7B-Instruct',\n",
    "                 tensor_parallel_size=1,\n",
    "                 gpu_memory_utilization=0.9,\n",
    "                 max_model_len=8192,\n",
    "                 batch_size=32,\n",
    "                 max_retries=2):\n",
    "        \"\"\"\n",
    "        vLLM 최적화 배치 추출기\n",
    "        \n",
    "        Args:\n",
    "            model_path: 모델 경로 (HuggingFace 또는 로컬)\n",
    "            tensor_parallel_size: 사용할 GPU 수\n",
    "            gpu_memory_utilization: GPU 메모리 사용률\n",
    "            max_model_len: 최대 시퀀스 길이\n",
    "            batch_size: 배치 크기\n",
    "            max_retries: 재시도 횟수\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.max_retries = max_retries\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        print(f\"Loading vLLM model: {model_path}...\")\n",
    "        \n",
    "        # vLLM 모델 초기화\n",
    "        self.llm = LLM(\n",
    "            model=model_path,\n",
    "            tensor_parallel_size=tensor_parallel_size,\n",
    "            gpu_memory_utilization=gpu_memory_utilization,\n",
    "            max_model_len=max_model_len,\n",
    "            trust_remote_code=True,\n",
    "            enforce_eager=False,  # CUDA graph 사용\n",
    "        )\n",
    "        \n",
    "        # Tokenizer 로드 (chat template 적용용)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_path,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "        \n",
    "        self.json_schema = MAUDEExtraction.model_json_schema()\n",
    "        # Sampling parameters with guided JSON\n",
    "        self.sampling_params = SamplingParams(\n",
    "            temperature=0.1,\n",
    "            max_tokens=512,\n",
    "            top_p=0.95,\n",
    "            # Guided JSON decoding - 스키마에 맞는 JSON만 생성\n",
    "            structured_outputs=StructuredOutputsParams(\n",
    "                json=self.json_schema,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _create_prompts(self, rows: List[pd.Series]) -> List[str]:\n",
    "        \"\"\"Chat template을 적용한 프롬프트 생성\"\"\"\n",
    "        prompts = []\n",
    "        \n",
    "        for row in rows:\n",
    "            text = row['mdr_text']\n",
    "            product_problem = row['product_problems']\n",
    "            \n",
    "            user_content = USER_PROMPT_TEMPLATE.format(\n",
    "                text=text,\n",
    "                product_problem=product_problem\n",
    "            )\n",
    "            \n",
    "            # Chat template 적용\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTION},\n",
    "                {\"role\": \"user\", \"content\": user_content}\n",
    "            ]\n",
    "            \n",
    "            # Tokenizer의 chat template 사용\n",
    "            formatted_prompt = self.tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "            \n",
    "            prompts.append(formatted_prompt)\n",
    "        \n",
    "        return prompts\n",
    "\n",
    "    def _parse_and_validate(self, response_text: str) -> dict:\n",
    "        \"\"\"응답 파싱 및 검증\"\"\"\n",
    "        # Guided JSON이므로 이미 JSON 형태\n",
    "        data = json.loads(response_text)\n",
    "        validated = MAUDEExtraction(**data)\n",
    "        return validated.model_dump()\n",
    "\n",
    "    def extract_batch(self, rows: List[pd.Series]) -> List[dict]:\n",
    "        \"\"\"\n",
    "        vLLM 배치 추론\n",
    "        - 순수 vLLM 배치 처리만 사용\n",
    "        - Guided JSON으로 파싱 에러 최소화\n",
    "        \"\"\"\n",
    "        # 프롬프트 생성\n",
    "        prompts = self._create_prompts(rows)\n",
    "        \n",
    "        # vLLM 배치 추론 (여기서 자동으로 최적화됨)\n",
    "        outputs = self.llm.generate(prompts, self.sampling_params, use_tqdm=False)\n",
    "        \n",
    "        # 결과 파싱\n",
    "        results = []\n",
    "        for i, output in enumerate(outputs):\n",
    "            try:\n",
    "                response_text = output.outputs[0].text\n",
    "                validated_data = self._parse_and_validate(response_text)\n",
    "                \n",
    "                result = {\n",
    "                    **validated_data,\n",
    "                    '_row_id': rows[i].name,\n",
    "                    '_success': True,\n",
    "                    '_input_tokens': len(output.prompt_token_ids),      # 추가\n",
    "                    '_output_tokens': len(output.outputs[0].token_ids),  # 기존\n",
    "                    '_total_tokens': len(output.prompt_token_ids) + len(output.outputs[0].token_ids)  # 추가\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    '_row_id': rows[i].name,\n",
    "                    '_success': False,\n",
    "                    '_error': str(e)[:200],\n",
    "                    '_raw_response': output.outputs[0].text[:200]\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def process_with_retry(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        재시도 로직 포함 배치 처리\n",
    "        - 실패한 항목들을 모아서 재배치 처리\n",
    "        \"\"\"\n",
    "        all_results = []\n",
    "        pending_rows = [(i, row) for i, row in df.iterrows()]\n",
    "        attempt = 1\n",
    "        \n",
    "        while pending_rows and attempt <= self.max_retries:\n",
    "            # print(f\"\\nAttempt {attempt}: Processing {len(pending_rows)} rows\")\n",
    "            \n",
    "            # 배치 단위로 처리\n",
    "            num_batches = (len(pending_rows) - 1) // self.batch_size + 1\n",
    "            batch_results = []\n",
    "            \n",
    "            for batch_idx in range(num_batches):\n",
    "                start_idx = batch_idx * self.batch_size\n",
    "                end_idx = min((batch_idx + 1) * self.batch_size, len(pending_rows))\n",
    "                \n",
    "                batch_items = pending_rows[start_idx:end_idx]\n",
    "                batch_rows = [row for _, row in batch_items]\n",
    "                \n",
    "                # vLLM 배치 추론\n",
    "                results = self.extract_batch(batch_rows)\n",
    "                \n",
    "                for j, result in enumerate(results):\n",
    "                    result['_attempts'] = attempt\n",
    "                    batch_results.append((batch_items[j][0], result))\n",
    "            \n",
    "            # 성공/실패 분리\n",
    "            success_results = [(idx, r) for idx, r in batch_results if r['_success']]\n",
    "            failed_items = [(idx, df.loc[idx]) for idx, r in batch_results if not r['_success']]\n",
    "            \n",
    "            # 성공한 결과 저장\n",
    "            all_results.extend([r for _, r in success_results])\n",
    "            \n",
    "            # 통계\n",
    "            success_count = len(success_results)\n",
    "            failed_count = len(failed_items)\n",
    "            print(f\"Success: {success_count}, Failed: {failed_count}\")\n",
    "            \n",
    "            # 다음 시도를 위해 실패한 항목 설정\n",
    "            pending_rows = failed_items\n",
    "            attempt += 1\n",
    "        \n",
    "        # 최종 실패 항목 처리\n",
    "        for idx, row in pending_rows:\n",
    "            all_results.append({\n",
    "                '_row_id': idx,\n",
    "                '_success': False,\n",
    "                '_error': 'Max retries exceeded',\n",
    "                '_attempts': self.max_retries\n",
    "            })\n",
    "        \n",
    "        # row_id 순서대로 정렬\n",
    "        all_results.sort(key=lambda x: x['_row_id'])\n",
    "        \n",
    "        return pd.json_normalize(all_results)\n",
    "\n",
    "    def process_batch(self, \n",
    "                     df: pd.DataFrame, \n",
    "                     checkpoint_dir: Union[str|Path], \n",
    "                     checkpoint_interval: int = 1000,\n",
    "                     checkpoint_prefix: str = 'checkpoint',\n",
    "        ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        전체 데이터프레임 처리 with 체크포인트\n",
    "        \"\"\"\n",
    "        print(f\"=\"*60)\n",
    "        print(f\"vLLM Batch Processing\")\n",
    "        print(f\"=\"*60)\n",
    "        print(f\"Total records: {len(df):,}\")\n",
    "        print(f\"Batch size: {self.batch_size}\")\n",
    "        print(f\"Max retries: {self.max_retries}\")\n",
    "        print(f\"Checkpoint every: {checkpoint_interval} records\\n\")\n",
    "        \n",
    "        overall_start = time.time()\n",
    "        all_results = []\n",
    "        \n",
    "        # 체크포인트 단위로 처리\n",
    "        try:\n",
    "            num_chunks = (len(df) - 1) // checkpoint_interval + 1\n",
    "            \n",
    "            for chunk_idx in tqdm(range(num_chunks), desc=\"Processing chunks\"):\n",
    "                start_idx = chunk_idx * checkpoint_interval\n",
    "                end_idx = min((chunk_idx + 1) * checkpoint_interval, len(df))\n",
    "                chunk_df = df.iloc[start_idx:end_idx]\n",
    "                \n",
    "                # print(f\"\\n{'='*60}\")\n",
    "                # print(f\"Chunk {chunk_idx + 1}/{num_chunks}: Rows {start_idx:,}-{end_idx-1:,}\")\n",
    "                # print(f\"{'='*60}\")\n",
    "                \n",
    "                chunk_start = time.time()\n",
    "                \n",
    "                # 재시도 포함 처리\n",
    "                chunk_result_df = self.process_with_retry(chunk_df)\n",
    "                all_results.append(chunk_result_df)\n",
    "                \n",
    "                # 청크 통계\n",
    "                elapsed = time.time() - chunk_start\n",
    "                success = chunk_result_df['_success'].sum()\n",
    "                throughput = len(chunk_df) / elapsed\n",
    "                \n",
    "                # print(f\"\\nChunk completed:\")\n",
    "                # print(f\"  Success: {success}/{len(chunk_df)} ({100*success/len(chunk_df):.1f}%)\")\n",
    "                # print(f\"  Time: {elapsed:.1f}s\")\n",
    "                # print(f\"  Throughput: {throughput:.2f} samples/s\")\n",
    "                \n",
    "                # 체크포인트 저장\n",
    "                checkpoint_file = f'{checkpoint_prefix}_chunk{chunk_idx+1}.csv'\n",
    "                checkpoint_path = Path(checkpoint_dir) / checkpoint_file\n",
    "                chunk_result_df.to_csv(checkpoint_path, index=False)\n",
    "                # print(f\"  Checkpoint: {checkpoint_file}\")\n",
    "            \n",
    "            # 최종 결과 합치기\n",
    "            final_df = pd.concat(all_results, ignore_index=True)\n",
    "            \n",
    "            # 최종 통계\n",
    "            total_time = time.time() - overall_start\n",
    "            total_success = final_df['_success'].sum()\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"FINAL RESULTS\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"Total processed: {len(final_df):,}\")\n",
    "            print(f\"Success: {total_success:,} ({100*total_success/len(final_df):.1f}%)\")\n",
    "            print(f\"Failed: {len(final_df)-total_success:,}\")\n",
    "            print(f\"Total time: {total_time/60:.1f} min\")\n",
    "            print(f\"Throughput: {len(final_df)/total_time:.2f} samples/s\")\n",
    "            print(f\"Total tokens: {final_df['_total_tokens'].sum():,}\")\n",
    "            print(f\"Avg input: {final_df['_input_tokens'].mean():.1f}\")\n",
    "            print(f\"Avg output: {final_df['_output_tokens'].mean():.1f}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            return final_df\n",
    "        \n",
    "        finally:\n",
    "            # 5. 임시 파일 정리\n",
    "            if checkpoint_dir.exists():\n",
    "                shutil.rmtree(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ce15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = maude_lf.select(\n",
    "    pl.all().sample(\n",
    "        n=1000,\n",
    "        with_replacement=False,\n",
    "        shuffle=True, # Shuffle the order of sampled rows\n",
    "        seed=4242\n",
    "    )\n",
    ").collect().to_pandas()\n",
    "\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51c9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "extractor = BatchMAUDEExtractor(\n",
    "    model_path='Qwen/Qwen3-8B',  # 또는 로컬 경로\n",
    "    tensor_parallel_size=1,  # GPU 개수\n",
    "    batch_size=32,  # 배치 크기\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "checkpoint_dir = DATA_DIR / 'temp'\n",
    "# 처리\n",
    "result_df = extractor.process_batch(sampled_df, checkpoint_interval=100, checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Elapsed time: {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total processed: {len(result_df):,}\")\n",
    "print(f\"Total tokens: {result_df['_total_tokens'].sum():,}\")\n",
    "print(f\"Avg input: {result_df['_input_tokens'].mean():.1f}\")\n",
    "print(f\"Avg output: {result_df['_output_tokens'].mean():.1f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열만 선택 후 열 이름 변경\n",
    "result_df2 = result_df[[\n",
    "    'incident_details.patient_harm',\n",
    "    'incident_details.problem_components',\n",
    "    'incident_details.incident_summary',\n",
    "    'manufacturer_inspection.defect_confirmed',\n",
    "    'manufacturer_inspection.defect_type',\n",
    "    'manufacturer_inspection.inspection_actions'\n",
    "    ]]\n",
    "\n",
    "result_df2 = result_df2.rename(columns={\n",
    "    'incident_details.patient_harm': 'patient_harm',\n",
    "    'incident_details.problem_components': 'problem_components',\n",
    "    'incident_details.incident_summary': 'incident_summary',\n",
    "    'manufacturer_inspection.defect_confirmed': 'defect_confirmed',\n",
    "    'manufacturer_inspection.defect_type': 'defect_type',\n",
    "    'manufacturer_inspection.inspection_actions': 'inspection_actions'\n",
    "})\n",
    "\n",
    "result_df2.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186111ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df2['defect_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639cfd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df2['defect_confirmed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e95287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([sampled_df, result_df2], axis=1)\n",
    "df_concat[['mdr_text', 'patient_harm', 'defect_type']]\n",
    "\n",
    "save_path = DATA_DIR / 'adhoc' / 'maude_extracted_sample.csv'\n",
    "save_path = increment_path(save_path)\n",
    "df_concat.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improvements",
   "metadata": {},
   "source": [
    "## vLLM 버전의 주요 개선사항\n",
    "\n",
    "### 1. 성능 향상\n",
    "- **배치 추론**: vLLM의 네이티브 배치 처리로 처리 속도 대폭 향상\n",
    "- **PagedAttention**: 메모리 효율적인 attention 메커니즘\n",
    "- **Continuous Batching**: 동적 배치 스케줄링으로 처리량 최적화\n",
    "\n",
    "### 2. GPU 활용 최적화\n",
    "- Tensor Parallelism 지원 (다중 GPU)\n",
    "- 높은 GPU 메모리 활용률 (기본 0.9)\n",
    "- 효율적인 KV 캐시 관리\n",
    "\n",
    "### 3. 처리 속도 비교 (예상)\n",
    "- **Ollama 버전**: ~1-2 samples/s (CPU 또는 단일 GPU)\n",
    "- **vLLM 버전**: ~10-50 samples/s (GPU, 배치 크기에 따라)\n",
    "- **속도 향상**: 10-30배 빠름\n",
    "\n",
    "### 4. 사용법\n",
    "```python\n",
    "# 설치\n",
    "# pip install vllm\n",
    "\n",
    "# 단일 GPU\n",
    "extractor = BatchMAUDEExtractor(\n",
    "    model_path='Qwen/Qwen2.5-7B-Instruct',\n",
    "    tensor_parallel_size=1,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# 다중 GPU (4개 사용)\n",
    "extractor = BatchMAUDEExtractor(\n",
    "    model_path='meta-llama/Llama-3.1-70B-Instruct',\n",
    "    tensor_parallel_size=4,\n",
    "    batch_size=64\n",
    ")\n",
    "```\n",
    "\n",
    "### 5. 추가 최적화 옵션\n",
    "- `max_model_len`: 시퀀스 길이 제한 (메모리 절약)\n",
    "- `gpu_memory_utilization`: GPU 메모리 사용률 조절\n",
    "- `quantization`: 양자화 (AWQ, GPTQ 등) 지원\n",
    "\n",
    "### 6. 주의사항\n",
    "- Chat 템플릿은 모델에 따라 조정 필요 (Qwen, Llama 등)\n",
    "- GPU 메모리가 부족하면 `batch_size` 또는 `max_model_len` 줄이기\n",
    "- `tensor_parallel_size`는 사용 가능한 GPU 수와 일치해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b455e82",
   "metadata": {},
   "source": [
    "# 프롬프팅 관련 문제 (원본)\n",
    "1. 예외 처리가 없어서 llm 다차원분리에 실패하더라도 그대로 그 행이 빈 채로 넘어감 <- 개선 필요\n",
    "2. 드는 시간이 너무 많이 걸려서 프롬프트를 좀 크기를 단축시켜야 됨.\n",
    "    * 실제로는 여기서 더 단축시키기가 힘듦.\n",
    "3. system prompt는 더 길어져도 한번만 들어가기 때문에 부담 없이 길게 할 수 있음\n",
    "    * 여기가 주로 만져야 되는 부분(퀄리티 상승을 위해서)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vllm_improvements",
   "metadata": {},
   "source": [
    "# vLLM 버전에서의 개선사항\n",
    "\n",
    "## 1. 예외 처리 강화 ✓\n",
    "- 개별 샘플 실패시에도 다른 샘플은 정상 처리\n",
    "- `_success`, `_error`, `_raw_response` 필드로 실패 원인 추적\n",
    "- 실패한 항목 자동 재시도 (최대 2회)\n",
    "\n",
    "## 2. 처리 시간 대폭 단축 ✓\n",
    "- **10-30배 빠른 처리 속도**\n",
    "- 배치 추론으로 GPU 효율 극대화\n",
    "- 1000개 샘플 기준: Ollama 15-20분 → vLLM 1-2분\n",
    "\n",
    "## 3. System Prompt 활용\n",
    "- System prompt에 상세한 가이드라인 추가 가능\n",
    "- 품질 향상을 위한 예시 및 설명 포함\n",
    "- 한 번만 인코딩되므로 성능 영향 최소화\n",
    "\n",
    "## 4. 추가 개선사항\n",
    "- 실시간 처리 진행률 표시\n",
    "- 자동 체크포인트 저장\n",
    "- 상세한 통계 정보 제공\n",
    "- 메모리 효율적인 처리"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
